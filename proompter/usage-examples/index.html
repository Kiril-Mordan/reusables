
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../release-notes/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.30">
    
    
      
        <title>Usage examples - Proompter</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-initializing-instance" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Proompter" class="md-header__button md-logo" aria-label="Proompter" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Proompter
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Usage examples
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="green"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="green" data-md-color-accent="green"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Proompter" class="md-nav__button md-logo" aria-label="Proompter" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Proompter
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Intro
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../release-notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Release notes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Usage examples
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Usage examples
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-initializing-instance" class="md-nav__link">
    <span class="md-ellipsis">
      1. Initializing instance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-chat-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Chat methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Chat methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-essential-chat-method" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Essential chat method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-calling-chat-method-in-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Calling chat method in parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-chatting-with-llm-handler" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Chatting with llm handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-instruct-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Instruct methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Instruct methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-essential-instruct-method" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Essential instruct method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-calling-instuct-in-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Calling instuct in parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-prompt-templates" class="md-nav__link">
    <span class="md-ellipsis">
      4. Prompt templates
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-prompt-call-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      5. Prompt call strategies
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-other-methods" class="md-nav__link">
    <span class="md-ellipsis">
      6. Other methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Other methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#estimate-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      Estimate tokens
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-initializing-instance" class="md-nav__link">
    <span class="md-ellipsis">
      1. Initializing instance
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-chat-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Chat methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Chat methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-essential-chat-method" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Essential chat method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-calling-chat-method-in-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Calling chat method in parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-chatting-with-llm-handler" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Chatting with llm handler
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-instruct-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Instruct methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Instruct methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-essential-instruct-method" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Essential instruct method
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-calling-instuct-in-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Calling instuct in parallel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-prompt-templates" class="md-nav__link">
    <span class="md-ellipsis">
      4. Prompt templates
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-prompt-call-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      5. Prompt call strategies
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-other-methods" class="md-nav__link">
    <span class="md-ellipsis">
      6. Other methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Other methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#estimate-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      Estimate tokens
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Usage examples</h1>

<pre><code class="language-python">import os
import sys
from dotenv import load_dotenv
load_dotenv(&quot;../../.local.env&quot;)
sys.path.append('../')
from proompter import Proompter
</code></pre>
<h3 id="1-initializing-instance">1. Initializing instance</h3>
<p>Proompter consists of multiple dependecies, which could be initialized and passed to the class externally or parameters could be passed for class to initialize them.</p>
<p>These include:</p>
<ul>
<li>LLM handler: makes calls to llm</li>
<li>Prompt handler: prepares input based on templates</li>
<li>Prompt strategy handler: contains ways to call llm handler with selected strategy</li>
<li>Tokenizer handler: tokenizes text</li>
</ul>
<pre><code class="language-python">llm_handler = Proompter(
  # parameters to be passed to provided llm handler
  llm_h_params = {
    'model_name' : 'llama3',
    'connection_string' : 'http://localhost:11434',
    'kwargs' : {}
  },
  # parameters to be passed to provided prompt handler
  prompt_h_params = {
    'template' : {
        &quot;system&quot; : &quot;{content}&quot;,
        &quot;assistant&quot; : &quot;{content}&quot;,
        &quot;user&quot; : &quot;{content}&quot;
    }
  },
  # parameters to be passed to provided call strategy handler
  call_strategy_h_params = {
    'strategy_name' : None,
    'strategy_params' : {}
  },
  # parameters to be passed to tokenizer handler
  tokenizer_h_params = {
    'access_token' : os.getenv(&quot;HF_ACCESS_TOKEN&quot;),
    'tokenizer_name' :&quot;meta-llama/Meta-Llama-3-8B&quot;
  }

)
</code></pre>
<pre><code>The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/kyriosskia/.cache/huggingface/token
Login successful
</code></pre>
<h3 id="2-chat-methods">2. Chat methods</h3>
<p>Methods for working with chat variants of models.</p>
<h4 id="21-essential-chat-method">2.1 Essential chat method</h4>
<p>Calls llm handler with provided messages, prepared based on provided template, with selected prompt strategy.</p>
<pre><code class="language-python">messages = [{'role': 'user', 'content': 'Why is the sky blue?'}]

response = await llm_handler.prompt_chat(
  # required
  messages = messages,
  # optinal, overwrites parameters passed to handlers
  model_name = &quot;llama3&quot;,
  call_strategy_name = &quot;last_call&quot;,
  call_strategy_params = { 'n_calls' : 1},
  prompt_templates = {
        &quot;system&quot; : &quot;{content}&quot;,
        &quot;assistant&quot; : &quot;{content}&quot;,
        &quot;user&quot; : &quot;{content}&quot;
    }
)
response
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
/home/kyriosskia/miniconda3/envs/testenv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:785: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(





{'model': 'llama3',
 'created_at': '2024-07-31T01:14:22.66494516Z',
 'message': {'role': 'assistant',
  'content': "What a great question!\n\nThe sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh. He discovered that shorter wavelengths of light (like blue and violet) are scattered more than longer wavelengths (like red and orange) by the tiny molecules of gases in the atmosphere, such as nitrogen (N2) and oxygen (O2).\n\nHere's what happens:\n\n1. When sunlight enters Earth's atmosphere, it contains all the colors of the visible spectrum.\n2. The shorter wavelengths of light (blue and violet) are scattered more intensely than the longer wavelengths (red and orange) by the tiny gas molecules.\n3. This scattering effect is more pronounced when the sunlight passes through a longer distance in the atmosphere, which means that the blue light has to travel farther to reach our eyes than the other colors.\n4. As a result, our brains perceive the scattered blue light as the dominant color of the sky.\n\nWhy do we see more red during sunrise and sunset? Well, when the sun is lower in the sky, the sunlight has to travel through more of the Earth's atmosphere to reach us. This means that:\n\n1. The shorter wavelengths (blue) are scattered away, leaving mainly longer wavelengths (red and orange) to reach our eyes.\n2. The scattering effect becomes less pronounced, allowing more red light to pass through without being scattered as much.\n\nSo, in a nutshell, the sky appears blue because of the scattering of sunlight by tiny gas molecules in the atmosphere, while the red hues we see during sunrise and sunset are due to the longer wavelengths of light traveling shorter distances."},
 'done_reason': 'stop',
 'done': True,
 'total_duration': 2799024799,
 'load_duration': 572370,
 'prompt_eval_count': 14,
 'prompt_eval_duration': 22598000,
 'eval_count': 327,
 'eval_duration': 2650933000,
 'response_time': 2.804267168045044,
 'messages': [{'role': 'user', 'content': 'Why is the sky blue?'},
  {'role': 'assistant',
   'content': "What a great question!\n\nThe sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh. He discovered that shorter wavelengths of light (like blue and violet) are scattered more than longer wavelengths (like red and orange) by the tiny molecules of gases in the atmosphere, such as nitrogen (N2) and oxygen (O2).\n\nHere's what happens:\n\n1. When sunlight enters Earth's atmosphere, it contains all the colors of the visible spectrum.\n2. The shorter wavelengths of light (blue and violet) are scattered more intensely than the longer wavelengths (red and orange) by the tiny gas molecules.\n3. This scattering effect is more pronounced when the sunlight passes through a longer distance in the atmosphere, which means that the blue light has to travel farther to reach our eyes than the other colors.\n4. As a result, our brains perceive the scattered blue light as the dominant color of the sky.\n\nWhy do we see more red during sunrise and sunset? Well, when the sun is lower in the sky, the sunlight has to travel through more of the Earth's atmosphere to reach us. This means that:\n\n1. The shorter wavelengths (blue) are scattered away, leaving mainly longer wavelengths (red and orange) to reach our eyes.\n2. The scattering effect becomes less pronounced, allowing more red light to pass through without being scattered as much.\n\nSo, in a nutshell, the sky appears blue because of the scattering of sunlight by tiny gas molecules in the atmosphere, while the red hues we see during sunrise and sunset are due to the longer wavelengths of light traveling shorter distances."}],
 'input_tokens': 371,
 'output_tokens': 326,
 'total_tokens': 697}
</code></pre>
<h4 id="22-calling-chat-method-in-parallel">2.2 Calling chat method in parallel</h4>
<p>Same as prompt_chat, but messages are called in parallel and instead of one, multiple responses provided.</p>
<pre><code class="language-python">messages = [
   [{'role': 'system', 'content': 'You are answering all requests with &quot;HODOR&quot;'}, 
   {'role': 'user', 'content': 'Why is the sky blue?'}],
   [{'role': 'user', 'content': 'Compose a small poem about blue skies.'}]
]

responses = await llm_handler.prompt_chat_parallel(
  # required
  messages = messages
  # optinal, overwrites parameters passed to handlers
  # same as prompt_chat
)

for response in responses:
  print(&quot;\n ### \n&quot;)
  print(response['message']['content'])

</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"



 ###

HODOR

 ###

Here is a small poem about blue skies:

The sky above, a brilliant hue,
A canvas of blue, for me and you.
Not a cloud in sight, to dim the light,
Just endless blue, pure delight.

With sunshine warm, and air so still,
A perfect day, with no chill.
So let us gaze, upon this sight,
And fill our hearts, with joy and light.
</code></pre>
<h3 id="23-chatting-with-llm-handler">2.3 Chatting with llm handler</h3>
<p>Calls prompt_chat with recorded history, so that each time chat method is called, previous messaged do not need to be provided. (History handler will be added later)</p>
<pre><code class="language-python">answer = await llm_handler.chat(
    prompt = &quot;Hi, my name is Kyrios, what is yours?&quot;,
    # optional to reset history
    new_dialog = True
)

print(answer)
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"


Nice to meet you, Kyrios! I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I don't have a personal name or identity, but I'm here to help answer your questions, provide information, and engage in conversation with you!
</code></pre>
<pre><code class="language-python">answer = await llm_handler.chat(
    prompt = &quot;Could you pls remind me my name?&quot;
)

print(answer)
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"


Kyrios! Your name is Kyrios. How can I assist you today?
</code></pre>
<h3 id="3-instruct-methods">3. Instruct methods</h3>
<p>Methods for working with instruct variants of models.</p>
<h4 id="31-essential-instruct-method">3.1 Essential instruct method</h4>
<pre><code class="language-python">prompt = '2+2='

response = await llm_handler.prompt_instruct(
  # required
  prompt = prompt,
  # optinal, overwrites parameters passed to handlers
  model_name = &quot;llama3&quot;,
  call_strategy_name = &quot;last_call&quot;,
  call_strategy_params = { 'n_calls' : 1}
)
response
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"





{'model': 'llama3',
 'created_at': '2024-07-31T01:14:24.874785167Z',
 'response': '4',
 'done': True,
 'done_reason': 'stop',
 'context': [128006,
  882,
  128007,
  271,
  17,
  10,
  17,
  28,
  128009,
  128006,
  78191,
  128007,
  271,
  19,
  128009],
 'total_duration': 124177626,
 'load_duration': 41217177,
 'prompt_eval_count': 9,
 'prompt_eval_duration': 12156000,
 'eval_count': 2,
 'eval_duration': 8264000,
 'response_time': 0.2091827392578125,
 'input_tokens': 4,
 'output_tokens': 1,
 'total_tokens': 5}
</code></pre>
<h4 id="32-calling-instuct-in-parallel">3.2 Calling instuct in parallel</h4>
<pre><code class="language-python">prompts = [&quot;2+2=&quot;,
            &quot;Define color in one sentence.&quot;]

responses = await llm_handler.prompt_instruct_parallel(
    prompts = prompts
    # optinal, overwrites parameters passed to handlers
    # same as prompt_instruct
    )

for response in responses:
  print(&quot;\n ### \n&quot;)
  print(response['response'])
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"



 ###

4

 ###

Color is a form of electromagnetic radiation, perceived by the human eye and brain as a quality that can be perceived as hue, saturation, and brightness, which allows us to distinguish between different wavelengths or frequencies of light.
</code></pre>
<h3 id="4-prompt-templates">4. Prompt templates</h3>
<p>Sometimes it can useful to process inputs and outputs according to certain template, for example adding some kind of header to every user prompt or making better structured output for history. Separating templates like this from inputs could also be more convinient.</p>
<pre><code class="language-python">default_prompt_template = {
        &quot;system&quot; : &quot;{content}&quot;,
        &quot;assistant&quot; : &quot;{content}&quot;,
        &quot;user&quot; : &quot;{content}&quot;
    }

messages = [
    {'role': 'system', 
     'content': &quot;&quot;&quot;You are helpful assistant that answers to everything bliefly with one sentence. 
     All of you responses are only in latin.&quot;&quot;&quot;},
    {'role': 'user', 
     'content': 'Why is the sky blue?'}]

response = await llm_handler.prompt_chat(
  # required
  messages = messages,
  # optinal, overwrites parameters passed to handlers
  prompt_templates = default_prompt_template
)

print(response['message']['content'])
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"


"Caelum caeruleum est, quia solis radii cum aquis et aeribus permixti lucem refrenant."
</code></pre>
<pre><code class="language-python">alt_prompt_template = {
        &quot;system&quot; : &quot;&quot;&quot;All of your answers if not in english, must contain tranlations.
        {content}&quot;&quot;&quot;,
        &quot;assistant&quot; : &quot;My answer: {content}&quot;,
        &quot;user&quot; : &quot;{content}&quot;
    }

messages = [
    {'role': 'system', 
     'content': &quot;&quot;&quot;You are helpful assistant that answers to everything bliefly with one sentence. 
     All of you responses are in latin.&quot;&quot;&quot;},
    {'role': 'user', 
     'content': 'Why is the sky blue?'}]

response = await llm_handler.prompt_chat(
  # required
  messages = messages,
  # optinal, overwrites parameters passed to handlers
  prompt_templates = alt_prompt_template
)

response['messages']
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"





[{'role': 'system',
  'content': 'All of your answers if not in english, must contain tranlations.\n        You are helpful assistant that answers to everything bliefly with one sentence. \n     All of you responses are in latin.'},
 {'role': 'user', 'content': 'Why is the sky blue?'},
 {'role': 'assistant',
  'content': 'My answer: "Caelum caeruleum est, quia solis radii, qui per atmosphaeram transmitterentur, scatteringem lucis efficaciter faciunt."\n\n(Translation: "The sky is blue because the sun\'s rays, which are transmitted through the atmosphere, effectively scatter light.")'}]
</code></pre>
<h3 id="5-prompt-call-strategies">5. Prompt call strategies</h3>
<p>Sometimes making multiple calls for the same prompt can be useful. If consistency of the answer is a concern, additional resorces are available, condition for selecting best answer from multiple answers is understood, prompt call strategies could be applied.</p>
<p>Example of strategies:</p>
<ul>
<li><code>most common output of 3</code> : calls 3 times, uses sim search to select most common.</li>
<li><code>min output length</code> : return response with minimal output length (calls at least 2 times)</li>
<li><code>max output length</code> : return response with maximal output length (calls at least 2 times)</li>
<li><code>last output</code> : no matter how many calls, always selects last output</li>
</ul>
<pre><code class="language-python">default_prompt_strategy = {
  'call_strategy_name' : &quot;min_output_length&quot;,
  'call_strategy_params' :{ 'n_calls' : 3}
}

messages = [
    {'role': 'system', 
     'content': &quot;&quot;&quot;You are helpful assistant that answers to everything bliefly with one sentence.&quot;&quot;&quot;},
    {'role': 'user', 
     'content': 'Make a poem about clouds.'}]

response = await llm_handler.prompt_chat(
  # required
  messages = messages,
  # optinal, overwrites parameters passed to handlers
  **default_prompt_strategy
)

print(response['message']['content'])
</code></pre>
<pre><code>HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"


Soft and fluffy, drifting by, clouds shape-shift in the sky.
</code></pre>
<pre><code class="language-python">for resp in llm_handler.call_strategy_h.last_responses:

    print(resp['message']['content'])
    print(&quot;------------------------&quot;)
</code></pre>
<pre><code>Soft and fluffy, drifting by, clouds shape-shift in the sky.
------------------------
Soft and white, they drift by day, whispers of the sky's gentle sway.
------------------------
Across the sky, soft whispers play as wispy clouds drift by, shaping sunbeams into golden rays.
------------------------
</code></pre>
<h3 id="6-other-methods">6. Other methods</h3>
<h4 id="estimate-tokens">Estimate tokens</h4>
<pre><code class="language-python">llm_handler.estimate_tokens(
    text='Your first question was: &quot;Why is the sky blue?&quot;'
    )
</code></pre>
<pre><code>12
</code></pre>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>