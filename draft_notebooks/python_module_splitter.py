{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import ast\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class PythonModuleSplitter:\n",
    "    \n",
    "    module_path = attr.ib(default=None, type = str)\n",
    "    include_docstrings = attr.ib(default = True, type = bool)\n",
    "    \n",
    "    module_content = attr.ib(init=False)\n",
    "    module_content_no_docstring = attr.ib(init=False)\n",
    "    \n",
    "    def __attrs_post_init__(self):\n",
    "        if self.module_path:\n",
    "            self.get_module_code()\n",
    "    \n",
    "    def get_module_code(self, module_path : str = None):\n",
    "        \n",
    "        if module_path is None:\n",
    "            module_path = self.module_path\n",
    "            return_content = False\n",
    "        else:\n",
    "            return_content = True\n",
    "           \n",
    "        if module_path is None:\n",
    "            raise ValueError(\"Module was not provided!\")\n",
    "        \n",
    "        with open(module_path, 'r') as file:\n",
    "            module_content = file.read() \n",
    "            \n",
    "        self._remove_docstrings(module_content = module_content)\n",
    "        \n",
    "        self.module_content = module_content        \n",
    "        \n",
    "        if return_content:\n",
    "            return module_content\n",
    "        \n",
    "    def _remove_docstrings(self, module_content : str = None):\n",
    "        \n",
    "        if module_content is None:\n",
    "            module_content = self.module_content\n",
    "        \n",
    "        class DocstringRemover(ast.NodeTransformer):\n",
    "            def visit_FunctionDef(self, node):\n",
    "                \"\"\"Strip docstring from a function definition.\"\"\"\n",
    "                self.generic_visit(node)\n",
    "                if ast.get_docstring(node):\n",
    "                    node.body = node.body[1:]\n",
    "                return node\n",
    "\n",
    "            def visit_ClassDef(self, node):\n",
    "                \"\"\"Strip docstring from a class definition.\"\"\"\n",
    "                self.generic_visit(node)\n",
    "                if ast.get_docstring(node):\n",
    "                    node.body = node.body[1:]\n",
    "                return node\n",
    "\n",
    "        parsed_tree = ast.parse(module_content)\n",
    "        docstring_remover = DocstringRemover()\n",
    "        modified_tree = docstring_remover.visit(parsed_tree)\n",
    "        self.module_content_no_docstring =  ast.unparse(modified_tree)\n",
    "        \n",
    "    def split_text(self, text : str = None, include_docstrings: bool = None):\n",
    "        \n",
    "        if include_docstrings is None:\n",
    "            include_docstrings = self.include_docstrings\n",
    "        \n",
    "        if text is None:\n",
    "            \n",
    "            if include_docstrings: \n",
    "                module_content = self.module_content\n",
    "            else:\n",
    "                module_content = self.module_content_no_docstring\n",
    "        else:\n",
    "            module_content = text\n",
    "\n",
    "\n",
    "        tree = ast.parse(module_content)\n",
    "        class_definitions = [node for node in tree.body if isinstance(node, ast.ClassDef)]\n",
    "\n",
    "        segments = []\n",
    "        for class_def in class_definitions:\n",
    "            for method in [n for n in class_def.body if isinstance(n, ast.FunctionDef)]:\n",
    "                class_copy = ast.ClassDef(name=class_def.name, \n",
    "                                        bases=class_def.bases, \n",
    "                                        keywords=class_def.keywords, \n",
    "                                        body=[method], \n",
    "                                        decorator_list=class_def.decorator_list)\n",
    "                class_code = ast.unparse(class_copy)\n",
    "                segments.append(class_code)\n",
    "\n",
    "        return segments\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PythonModuleSplitter(module_path = './python_modules/mock_vector_database.py',\n",
    "                          include_docstrings = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ps.split_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed(self, text, model_type: str=None):\n",
      "        if model_type is None:\n",
      "            model_type = self.model_type\n",
      "        if model_type == 'openAI':\n",
      "            return self.embed_openAI(text=text)\n",
      "        if model_type == 'sentence_transformer':\n",
      "            return self.embed_sentence_transformer(text=text)\n"
     ]
    }
   ],
   "source": [
    "print(splits[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def __attrs_post_init__(self):\n",
      "        self._initialize_logger()\n",
      "        if self.model_type != 'openAI':\n",
      "            self.st_model = SentenceTransformer(self.st_model_name)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def _initialize_logger(self):\n",
      "        \"\"\"\n",
      "        Initialize a logger for the class instance based on the specified logging level and logger name.\n",
      "        \"\"\"\n",
      "        if self.logger is None:\n",
      "            logging.basicConfig(level=self.loggerLvl, format=self.logger_format)\n",
      "            logger = logging.getLogger(self.logger_name)\n",
      "            logger.setLevel(self.loggerLvl)\n",
      "            self.logger = logger\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def hnsw_search(self, search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200):\n",
      "        \"\"\"\n",
      "        Perform Hierarchical Navigable Small World search.\n",
      "\n",
      "        Args:\n",
      "        - search_emb (numpy array): The query embedding. Shape (1, dim).\n",
      "        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\n",
      "        - k (int): Number of nearest neighbors to return.\n",
      "        - space (str): Space type for the index ('cosine' or 'l2').\n",
      "        - ef_search (int): Search parameter. Higher means more accurate but slower.\n",
      "        - M (int): Index parameter.\n",
      "        - ef_construction (int): Index construction parameter.\n",
      "\n",
      "        Returns:\n",
      "        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\n",
      "        - distances (numpy array): Distances of the k nearest embeddings.\n",
      "        \"\"\"\n",
      "        dim = len(search_emb)\n",
      "        p = hnswlib.Index(space=space, dim=dim)\n",
      "        p.init_index(max_elements=len(doc_embs), ef_construction=ef_construction, M=M)\n",
      "        p.add_items(doc_embs)\n",
      "        p.set_ef(ef_search)\n",
      "        labels, distances = p.knn_query(search_emb, k=k)\n",
      "        return (labels[0], distances[0])\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def linear_search(self, search_emb, doc_embs, k=1, space='cosine'):\n",
      "        \"\"\"\n",
      "        Perform a linear (brute force) search.\n",
      "\n",
      "        Args:\n",
      "        - search_emb (numpy array): The query embedding. Shape (1, dim).\n",
      "        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\n",
      "        - k (int): Number of nearest neighbors to return.\n",
      "        - space (str): Space type for the distance calculation ('cosine' or 'l2').\n",
      "\n",
      "        Returns:\n",
      "        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\n",
      "        - distances (numpy array): Distances of the k nearest embeddings.\n",
      "        \"\"\"\n",
      "        if space == 'cosine':\n",
      "            search_emb_norm = search_emb / np.linalg.norm(search_emb)\n",
      "            doc_embs_norm = doc_embs / np.linalg.norm(doc_embs, axis=1)[:, np.newaxis]\n",
      "            distances = np.dot(doc_embs_norm, search_emb_norm.T).flatten()\n",
      "        elif space == 'l2':\n",
      "            distances = np.linalg.norm(doc_embs - search_emb, axis=1)\n",
      "        if space == 'cosine':\n",
      "            labels = np.argsort(-distances)[:k]\n",
      "        else:\n",
      "            labels = np.argsort(distances)[:k]\n",
      "        top_distances = distances[labels]\n",
      "        return (labels, top_distances)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def establish_connection(self, file_path: str=None):\n",
      "        \"\"\"\n",
      "        Simulates establishing a connection by loading data from a local file into the 'data' attribute.\n",
      "        \"\"\"\n",
      "        if file_path is None:\n",
      "            file_path = self.file_path\n",
      "        try:\n",
      "            with open(file_path, 'rb') as file:\n",
      "                self.data = dill.load(file)\n",
      "        except FileNotFoundError:\n",
      "            self.data = {}\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error loading data from file: ', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def save_data(self):\n",
      "        \"\"\"\n",
      "        Saves the current state of 'data' back into a local file.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            with open(self.file_path, 'wb') as file:\n",
      "                dill.dump(self.data, file)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error saving data to file: ', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed(self, text, model_type: str=None):\n",
      "        \"\"\"\n",
      "        Embeds single query with sentence with selected embedder.\n",
      "        \"\"\"\n",
      "        if model_type is None:\n",
      "            model_type = self.model_type\n",
      "        if model_type == 'openAI':\n",
      "            return self.embed_openAI(text=text)\n",
      "        if model_type == 'sentence_transformer':\n",
      "            return self.embed_sentence_transformer(text=text)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed_sentence_transformer(self, text):\n",
      "        \"\"\"\n",
      "        Embeds single query with sentence tranformer embedder.\n",
      "        \"\"\"\n",
      "        return self.st_model.encode(text)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed_openAI(self, text):\n",
      "        \"\"\"\n",
      "        Embeds single query with openAI embedder.\n",
      "        \"\"\"\n",
      "        api_url = self.embeddings_url\n",
      "        payload = json.dumps({'user': self.godID, 'input': text})\n",
      "        try:\n",
      "            response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code == 429:\n",
      "                time.sleep(1)\n",
      "                response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code > 200:\n",
      "                print(f\"Request to '{api_url}' failed: {response}\")\n",
      "                print(response.text)\n",
      "                return None\n",
      "            embedding = response.json()['data'][0]['embedding']\n",
      "        except:\n",
      "            error_mess = 'An exception has occurred during embedding!'\n",
      "            if self.embedder_error_tolerance == 0.0:\n",
      "                raise ValueError(error_mess)\n",
      "            else:\n",
      "                print(error_mess)\n",
      "                return None\n",
      "        return embedding\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def _prepare_for_redis(self, data_dict, var_for_embedding_name):\n",
      "        \"\"\"\n",
      "        Prepare a dictionary for storage in Redis by serializing all its values to strings.\n",
      "        \"\"\"\n",
      "        for key, _ in data_dict.items():\n",
      "            embedding = self.embed(data_dict[key][var_for_embedding_name])\n",
      "            data_dict[key]['embedding'] = embedding\n",
      "        return data_dict\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def insert_values_dict(self, values_dict, var_for_embedding_name):\n",
      "        \"\"\"\n",
      "        Simulates inserting key-value pairs into the mock Redis database.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            values_dict = self._prepare_for_redis(data_dict=values_dict, var_for_embedding_name=var_for_embedding_name)\n",
      "            self.data.update(values_dict)\n",
      "            self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during inserting list of key-values dictionaries into mock database!', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def flush_database(self):\n",
      "        \"\"\"\n",
      "        Clears all data in the mock database.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            self.data = {}\n",
      "            if self.persist:\n",
      "                self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during flushing mock database', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def filter_keys(self, subkey=None, subvalue=None):\n",
      "        \"\"\"\n",
      "        Filters data entries based on a specific subkey and subvalue.\n",
      "        \"\"\"\n",
      "        if subkey is not None and subvalue is not None:\n",
      "            self.keys_list = [d for d in self.data if self.data[d][subkey] == subvalue]\n",
      "        else:\n",
      "            self.keys_list = self.data\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def filter_database(self, filter_criteria: dict=None):\n",
      "        \"\"\"\n",
      "        Filters a dictionary based on multiple field criteria.\n",
      "        \"\"\"\n",
      "        self.filtered_data = {key: value for key, value in self.data.items() if all((value.get(k) == v for k, v in filter_criteria.items()))}\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def remove_from_database(self, filter_criteria: dict=None):\n",
      "        \"\"\"\n",
      "        Removes key-value pairs from a dictionary based on filter criteria.\n",
      "        \"\"\"\n",
      "        self.data = {key: value for key, value in self.data.items() if not all((value.get(k) == v for k, v in filter_criteria.items()))}\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def search_database_keys(self, query: str, search_results_n: int=None, similarity_search_type: str=None, similarity_params: dict=None):\n",
      "        \"\"\"\n",
      "        Searches the mock database using embeddings and saves a list of entries that match the query.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            query_embedding = self.embed(query)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during embedding search query!', e)\n",
      "        if search_results_n is None:\n",
      "            search_results_n = self.search_results_n\n",
      "        if similarity_search_type is None:\n",
      "            similarity_search_type = self.similarity_search_type\n",
      "        if similarity_params is None:\n",
      "            similarity_params = self.similarity_params\n",
      "        if self.filtered_data is None:\n",
      "            self.filtered_data = self.data\n",
      "        if self.keys_list is None:\n",
      "            self.keys_list = [key for key in self.filtered_data]\n",
      "        try:\n",
      "            data_embeddings = np.array([self.filtered_data[d]['embedding'] for d in self.keys_list])\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting search pool embeddings!', e)\n",
      "        try:\n",
      "            if similarity_search_type == 'linear':\n",
      "                labels, _ = self.linear_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            else:\n",
      "                labels, _ = self.hnsw_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            self.results_keys = [self.keys_list[i] for i in labels]\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting results from the mock database!', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def get_dict_results(self, return_keys_list: list=None) -> list:\n",
      "        \"\"\"\n",
      "        Retrieves specified fields from the search results in the mock database.\n",
      "        \"\"\"\n",
      "        if return_keys_list is None:\n",
      "            return_keys_list = self.return_keys_list\n",
      "        results = []\n",
      "        for searched_doc in self.results_keys:\n",
      "            result = {key: self.data[searched_doc].get(key) for key in return_keys_list}\n",
      "            results.append(result)\n",
      "        return results\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def search_database(self, query: str, search_results_n: int=None, filter_criteria: dict=None, similarity_search_type: str=None, similarity_params: dict=None, return_keys_list: list=None) -> list:\n",
      "        \"\"\"\n",
      "        Searches through keys and retrieves specified fields from the search results\n",
      "        in the mock database for a given filter.\n",
      "        \"\"\"\n",
      "        if filter_criteria:\n",
      "            self.filter_database(filter_criteria=filter_criteria)\n",
      "        self.search_database_keys(query=query, search_results_n=search_results_n, similarity_search_type=similarity_search_type, similarity_params=similarity_params)\n",
      "        results = self.get_dict_results(return_keys_list=return_keys_list)\n",
      "        self.filtered_data = None\n",
      "        self.keys_list = None\n",
      "        return results\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def split_class_methods(module_path):\n",
    "    with open(module_path, 'r') as file:\n",
    "        module_content = file.read()\n",
    "\n",
    "    tree = ast.parse(module_content)\n",
    "    class_definitions = [node for node in tree.body if isinstance(node, ast.ClassDef)]\n",
    "\n",
    "    segments = []\n",
    "    for class_def in class_definitions:\n",
    "        for method in [n for n in class_def.body if isinstance(n, ast.FunctionDef)]:\n",
    "            class_copy = ast.ClassDef(name=class_def.name, \n",
    "                                      bases=class_def.bases, \n",
    "                                      keywords=class_def.keywords, \n",
    "                                      body=[method], \n",
    "                                      decorator_list=class_def.decorator_list)\n",
    "            class_code = ast.unparse(class_copy)\n",
    "            segments.append(class_code)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "module_segments = split_class_methods('./python_modules/mock_vector_database.py')\n",
    "for segment in module_segments:\n",
    "    print(segment)\n",
    "    print(\"------\")\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def __attrs_post_init__(self):\n",
      "        self._initialize_logger()\n",
      "        if self.model_type != 'openAI':\n",
      "            self.st_model = SentenceTransformer(self.st_model_name)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def _initialize_logger(self):\n",
      "        \"\"\"\n",
      "        Initialize a logger for the class instance based on the specified logging level and logger name.\n",
      "        \"\"\"\n",
      "        if self.logger is None:\n",
      "            logging.basicConfig(level=self.loggerLvl, format=self.logger_format)\n",
      "            logger = logging.getLogger(self.logger_name)\n",
      "            logger.setLevel(self.loggerLvl)\n",
      "            self.logger = logger\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def hnsw_search(self, search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200):\n",
      "        \"\"\"\n",
      "        Perform Hierarchical Navigable Small World search.\n",
      "\n",
      "        Args:\n",
      "        - search_emb (numpy array): The query embedding. Shape (1, dim).\n",
      "        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\n",
      "        - k (int): Number of nearest neighbors to return.\n",
      "        - space (str): Space type for the index ('cosine' or 'l2').\n",
      "        - ef_search (int): Search parameter. Higher means more accurate but slower.\n",
      "        - M (int): Index parameter.\n",
      "        - ef_construction (int): Index construction parameter.\n",
      "\n",
      "        Returns:\n",
      "        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\n",
      "        - distances (numpy array): Distances of the k nearest embeddings.\n",
      "        \"\"\"\n",
      "        dim = len(search_emb)\n",
      "        p = hnswlib.Index(space=space, dim=dim)\n",
      "        p.init_index(max_elements=len(doc_embs), ef_construction=ef_construction, M=M)\n",
      "        p.add_items(doc_embs)\n",
      "        p.set_ef(ef_search)\n",
      "        (labels, distances) = p.knn_query(search_emb, k=k)\n",
      "        return (labels[0], distances[0])\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def linear_search(self, search_emb, doc_embs, k=1, space='cosine'):\n",
      "        \"\"\"\n",
      "        Perform a linear (brute force) search.\n",
      "\n",
      "        Args:\n",
      "        - search_emb (numpy array): The query embedding. Shape (1, dim).\n",
      "        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\n",
      "        - k (int): Number of nearest neighbors to return.\n",
      "        - space (str): Space type for the distance calculation ('cosine' or 'l2').\n",
      "\n",
      "        Returns:\n",
      "        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\n",
      "        - distances (numpy array): Distances of the k nearest embeddings.\n",
      "        \"\"\"\n",
      "        if space == 'cosine':\n",
      "            search_emb_norm = search_emb / np.linalg.norm(search_emb)\n",
      "            doc_embs_norm = doc_embs / np.linalg.norm(doc_embs, axis=1)[:, np.newaxis]\n",
      "            distances = np.dot(doc_embs_norm, search_emb_norm.T).flatten()\n",
      "        elif space == 'l2':\n",
      "            distances = np.linalg.norm(doc_embs - search_emb, axis=1)\n",
      "        if space == 'cosine':\n",
      "            labels = np.argsort(-distances)[:k]\n",
      "        else:\n",
      "            labels = np.argsort(distances)[:k]\n",
      "        top_distances = distances[labels]\n",
      "        return (labels, top_distances)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def establish_connection(self, file_path: str=None):\n",
      "        \"\"\"\n",
      "        Simulates establishing a connection by loading data from a local file into the 'data' attribute.\n",
      "        \"\"\"\n",
      "        if file_path is None:\n",
      "            file_path = self.file_path\n",
      "        try:\n",
      "            with open(file_path, 'rb') as file:\n",
      "                self.data = dill.load(file)\n",
      "        except FileNotFoundError:\n",
      "            self.data = {}\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error loading data from file: ', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def save_data(self):\n",
      "        \"\"\"\n",
      "        Saves the current state of 'data' back into a local file.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            with open(self.file_path, 'wb') as file:\n",
      "                dill.dump(self.data, file)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error saving data to file: ', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def embed(self, text, model_type: str=None):\n",
      "        \"\"\"\n",
      "        Embeds single query with sentence with selected embedder.\n",
      "        \"\"\"\n",
      "        if model_type is None:\n",
      "            model_type = self.model_type\n",
      "        if model_type == 'openAI':\n",
      "            return self.embed_openAI(text=text)\n",
      "        if model_type == 'sentence_transformer':\n",
      "            return self.embed_sentence_transformer(text=text)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def embed_sentence_transformer(self, text):\n",
      "        \"\"\"\n",
      "        Embeds single query with sentence tranformer embedder.\n",
      "        \"\"\"\n",
      "        return self.st_model.encode(text)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def embed_openAI(self, text):\n",
      "        \"\"\"\n",
      "        Embeds single query with openAI embedder.\n",
      "        \"\"\"\n",
      "        api_url = self.embeddings_url\n",
      "        payload = json.dumps({'user': self.godID, 'input': text})\n",
      "        try:\n",
      "            response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code == 429:\n",
      "                time.sleep(1)\n",
      "                response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code > 200:\n",
      "                print(f\"Request to '{api_url}' failed: {response}\")\n",
      "                print(response.text)\n",
      "                return None\n",
      "            embedding = response.json()['data'][0]['embedding']\n",
      "        except:\n",
      "            error_mess = 'An exception has occurred during embedding!'\n",
      "            if self.embedder_error_tolerance == 0.0:\n",
      "                raise ValueError(error_mess)\n",
      "            else:\n",
      "                print(error_mess)\n",
      "                return None\n",
      "        return embedding\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def _prepare_for_redis(self, data_dict, var_for_embedding_name):\n",
      "        \"\"\"\n",
      "        Prepare a dictionary for storage in Redis by serializing all its values to strings.\n",
      "        \"\"\"\n",
      "        for (key, _) in data_dict.items():\n",
      "            embedding = self.embed(data_dict[key][var_for_embedding_name])\n",
      "            data_dict[key]['embedding'] = embedding\n",
      "        return data_dict\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def insert_values_dict(self, values_dict, var_for_embedding_name):\n",
      "        \"\"\"\n",
      "        Simulates inserting key-value pairs into the mock Redis database.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            values_dict = self._prepare_for_redis(data_dict=values_dict, var_for_embedding_name=var_for_embedding_name)\n",
      "            self.data.update(values_dict)\n",
      "            self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during inserting list of key-values dictionaries into mock database!', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def flush_database(self):\n",
      "        \"\"\"\n",
      "        Clears all data in the mock database.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            self.data = {}\n",
      "            if self.persist:\n",
      "                self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during flushing mock database', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def filter_keys(self, subkey=None, subvalue=None):\n",
      "        \"\"\"\n",
      "        Filters data entries based on a specific subkey and subvalue.\n",
      "        \"\"\"\n",
      "        if subkey is not None and subvalue is not None:\n",
      "            self.keys_list = [d for d in self.data if self.data[d][subkey] == subvalue]\n",
      "        else:\n",
      "            self.keys_list = self.data\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def filter_database(self, filter_criteria: dict=None):\n",
      "        \"\"\"\n",
      "        Filters a dictionary based on multiple field criteria.\n",
      "        \"\"\"\n",
      "        self.filtered_data = {key: value for (key, value) in self.data.items() if all((value.get(k) == v for (k, v) in filter_criteria.items()))}\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def remove_from_database(self, filter_criteria: dict=None):\n",
      "        \"\"\"\n",
      "        Removes key-value pairs from a dictionary based on filter criteria.\n",
      "        \"\"\"\n",
      "        self.data = {key: value for (key, value) in self.data.items() if not all((value.get(k) == v for (k, v) in filter_criteria.items()))}\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def search_database_keys(self, query: str, search_results_n: int=None, similarity_search_type: str=None, similarity_params: dict=None):\n",
      "        \"\"\"\n",
      "        Searches the mock database using embeddings and saves a list of entries that match the query.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            query_embedding = self.embed(query)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during embedding search query!', e)\n",
      "        if search_results_n is None:\n",
      "            search_results_n = self.search_results_n\n",
      "        if similarity_search_type is None:\n",
      "            similarity_search_type = self.similarity_search_type\n",
      "        if similarity_params is None:\n",
      "            similarity_params = self.similarity_params\n",
      "        if self.filtered_data is None:\n",
      "            self.filtered_data = self.data\n",
      "        if self.keys_list is None:\n",
      "            self.keys_list = [key for key in self.filtered_data]\n",
      "        try:\n",
      "            data_embeddings = np.array([self.filtered_data[d]['embedding'] for d in self.keys_list])\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting search pool embeddings!', e)\n",
      "        try:\n",
      "            if similarity_search_type == 'linear':\n",
      "                (labels, _) = self.linear_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            else:\n",
      "                (labels, _) = self.hnsw_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            self.results_keys = [self.keys_list[i] for i in labels]\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting results from the mock database!', e)\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def get_dict_results(self, return_keys_list: list=None) -> list:\n",
      "        \"\"\"\n",
      "        Retrieves specified fields from the search results in the mock database.\n",
      "        \"\"\"\n",
      "        if return_keys_list is None:\n",
      "            return_keys_list = self.return_keys_list\n",
      "        results = []\n",
      "        for searched_doc in self.results_keys:\n",
      "            result = {key: self.data[searched_doc].get(key) for key in return_keys_list}\n",
      "            results.append(result)\n",
      "        return results\n",
      "------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "    \"\"\"\n",
      "    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\n",
      "    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\n",
      "    and basic data management, mimicking operations in a real vector database.\n",
      "\n",
      "    Parameters:\n",
      "        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\n",
      "        godID (str): Unique identifier for authentication with the embedding service.\n",
      "        headers (dict): HTTP headers for API interactions with the embedding service.\n",
      "        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\n",
      "        persist (bool): Flag to persist data changes; defaults to False.\n",
      "        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\n",
      "        logger (logging.Logger): Logger instance for activity logging.\n",
      "        logger_name (str): Name for the logger; defaults to 'Mock handler'.\n",
      "        loggerLvl (int): Logging level, set to logging.INFO by default.\n",
      "        return_keys_list (list): Fields to return in search results; defaults to an empty list.\n",
      "        search_results_n (int): Number of results to return in searches; defaults to 3.\n",
      "        similarity_search_type (str): Type of similarity search to use; defaults to 'hnsw'.\n",
      "        similarity_params (dict): Parameters for similarity search; defaults to {'space':'cosine'}.\n",
      "\n",
      "    Attributes:\n",
      "        data (dict): In-memory representation of database contents.\n",
      "        filtered_data (dict): Stores filtered database entries based on criteria.\n",
      "        keys_list (list): List of keys in the database.\n",
      "        results_keys (list): Keys matching specific search criteria.\n",
      "\n",
      "    Methods:\n",
      "        initialize_logger()\n",
      "            Sets up logging for the class instance.\n",
      "\n",
      "        hnsw_search(search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200)\n",
      "            Performs HNSW algorithm-based search.\n",
      "\n",
      "        linear_search(search_emb, doc_embs, k=1, space='cosine')\n",
      "            Conducts a linear search.\n",
      "\n",
      "        establish_connection(file_path=None)\n",
      "            Simulates establishing a database connection.\n",
      "\n",
      "        save_data()\n",
      "            Saves the current state of the 'data' attribute to a file.\n",
      "\n",
      "        embed(text)\n",
      "            Generates embeddings for text inputs.\n",
      "\n",
      "        _prepare_for_redis(data_dict, var_for_embedding_name)\n",
      "            Prepares data for storage in Redis.\n",
      "\n",
      "        insert_values_dict(values_dict, var_for_embedding_name)\n",
      "            Simulates insertion of key-value pairs into the database.\n",
      "\n",
      "        flush_database()\n",
      "            Clears all data in the mock database.\n",
      "\n",
      "        filter_keys(subkey=None, subvalue=None)\n",
      "            Filters data entries based on a specific subkey and subvalue.\n",
      "\n",
      "        filter_database(filter_criteria=None)\n",
      "            Filters a dictionary based on multiple field criteria.\n",
      "\n",
      "        remove_from_database(filter_criteria=None)\n",
      "            Removes key-value pairs from a dictionary based on filter criteria.\n",
      "\n",
      "        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\n",
      "            Searches the database using embeddings and saves a list of entries that match the query.\n",
      "\n",
      "        get_dict_results(return_keys_list=None)\n",
      "            Retrieves specified fields from the search results.\n",
      "\n",
      "        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\n",
      "                        similarity_params=None, return_keys_list=None)\n",
      "            Searches and retrieves fields from the database for a given filter.\n",
      "    \"\"\"\n",
      "    embeddings_url = attr.ib(default=None)\n",
      "    godID = attr.ib(default=None)\n",
      "    headers = attr.ib(default=None)\n",
      "    model_type = attr.ib(default='sentence_transformer', type=str)\n",
      "    st_model_name = attr.ib(default='all-MiniLM-L6-v2', type=str)\n",
      "    st_model = attr.ib(default=None, init=False)\n",
      "    return_keys_list = attr.ib(default=[], type=list)\n",
      "    search_results_n = attr.ib(default=3, type=int)\n",
      "    similarity_search_type = attr.ib(default='linear', type=str)\n",
      "    similarity_params = attr.ib(default={'space': 'cosine'}, type=dict)\n",
      "    file_path = attr.ib(default='../redis_mock', type=str)\n",
      "    persist = attr.ib(default=False, type=bool)\n",
      "    embedder_error_tolerance = attr.ib(default=0.0, type=float)\n",
      "    logger = attr.ib(default=None)\n",
      "    logger_name = attr.ib(default='Mock handler')\n",
      "    loggerLvl = attr.ib(default=logging.INFO)\n",
      "    logger_format = attr.ib(default=None)\n",
      "    data = attr.ib(default=None, init=False)\n",
      "    filtered_data = attr.ib(default=None, init=False)\n",
      "    keys_list = attr.ib(default=None, init=False)\n",
      "    results_keys = attr.ib(default=None, init=False)\n",
      "\n",
      "    def search_database(self, query: str, search_results_n: int=None, filter_criteria: dict=None, similarity_search_type: str=None, similarity_params: dict=None, return_keys_list: list=None) -> list:\n",
      "        \"\"\"\n",
      "        Searches through keys and retrieves specified fields from the search results\n",
      "        in the mock database for a given filter.\n",
      "        \"\"\"\n",
      "        if filter_criteria:\n",
      "            self.filter_database(filter_criteria=filter_criteria)\n",
      "        self.search_database_keys(query=query, search_results_n=search_results_n, similarity_search_type=similarity_search_type, similarity_params=similarity_params)\n",
      "        results = self.get_dict_results(return_keys_list=return_keys_list)\n",
      "        self.filtered_data = None\n",
      "        self.keys_list = None\n",
      "        return results\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def split_class_methods(module_path):\n",
    "    with open(module_path, 'r') as file:\n",
    "        module_content = file.read()\n",
    "\n",
    "    tree = ast.parse(module_content)\n",
    "    class_definitions = [node for node in tree.body if isinstance(node, ast.ClassDef)]\n",
    "\n",
    "    segments = []\n",
    "    for class_def in class_definitions:\n",
    "        # Find the first method\n",
    "        first_method_index = next((i for i, n in enumerate(class_def.body) if isinstance(n, ast.FunctionDef)), None)\n",
    "        \n",
    "        # If there's no method, continue to next class\n",
    "        if first_method_index is None:\n",
    "            continue\n",
    "\n",
    "        # Everything before the first method\n",
    "        pre_method_body = class_def.body[:first_method_index]\n",
    "\n",
    "        for method in [n for n in class_def.body if isinstance(n, ast.FunctionDef)]:\n",
    "            # Class body consists of pre-method part and the current method\n",
    "            class_body = pre_method_body + [method]\n",
    "\n",
    "            class_copy = ast.ClassDef(name=class_def.name, \n",
    "                                      bases=class_def.bases, \n",
    "                                      keywords=class_def.keywords, \n",
    "                                      body=class_body, \n",
    "                                      decorator_list=class_def.decorator_list)\n",
    "            class_code = ast.unparse(class_copy)\n",
    "            segments.append(class_code)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "module_segments = split_class_methods('./python_modules/mock_vector_database.py')\n",
    "for segment in module_segments:\n",
    "    print(segment)\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.choppers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchoppers\u001b[39;00m \u001b[39mimport\u001b[39;00m code_to_chunks\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit_python_module\u001b[39m(module_path):\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Read the Python module\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(module_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.choppers'"
     ]
    }
   ],
   "source": [
    "from langchain.choppers import code_to_chunks\n",
    "\n",
    "def split_python_module(module_path):\n",
    "    # Read the Python module\n",
    "    with open(module_path, 'r') as file:\n",
    "        code = file.read()\n",
    "\n",
    "    # Split the code into chunks\n",
    "    chunks = code_to_chunks(code, language='python')\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "module_path = 'path_to_your_module.py'\n",
    "chunks = split_python_module(module_path)\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = './python_modules/mock_vector_database.py'\n",
    "with open(module_path, 'r') as file:\n",
    "        module_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"\\nMock Vector Db Handler\\n\\nThis class is a mock handler for simulating a vector database, designed primarily for testing and development scenarios.\\nIt offers functionalities such as text embedding, hierarchical navigable small world (HNSW) search,\\nand basic data management within a simulated environment resembling a vector database.\\n\"\"\"\\n\\n# Imports\\n## essential\\nimport logging\\nimport json\\nimport time\\nimport numpy as np #==1.26.0\\nimport dill #==0.3.7\\nimport attr #>=22.2.0\\n## for search\\nimport requests #==2.31.0\\nimport hnswlib #0.7.0\\nfrom sentence_transformers import SentenceTransformer #==2.2.2\\n\\n# Metadata for package creation\\n__package_metadata__ = {\\n    \"author\": \"Kyrylo Mordan\",\\n    \"author_email\": \"parachute.repo@gmail.com\",\\n    \"version\": \"0.0.1\",\\n    \"description\": \"A mock handler for simulating a vector database.\",\\n    \"keywords\" : [\\'python\\', \\'vector database\\', \\'similarity search\\']\\n    # Add other metadata as needed\\n}\\n\\n\\n@attr.s\\nclass MockVecDbHandler:\\n    # pylint: disable=too-many-instance-attributes\\n\\n    \"\"\"\\n    The MockVecDbHandler class simulates a vector database environment, primarily for testing and development purposes.\\n    It integrates various functionalities such as text embedding, Hierarchical Navigable Small World (HNSW) search,\\n    and basic data management, mimicking operations in a real vector database.\\n\\n    Parameters:\\n        embeddings_url (str): URL to access OpenAI models for generating embeddings, crucial for text analysis.\\n        godID (str): Unique identifier for authentication with the embedding service.\\n        headers (dict): HTTP headers for API interactions with the embedding service.\\n        file_path (str): Local file path for storing and simulating the database; defaults to \"../redis_mock\".\\n        persist (bool): Flag to persist data changes; defaults to False.\\n        embedder_error_tolerance (float): Tolerance level for embedding errors; defaults to 0.0.\\n        logger (logging.Logger): Logger instance for activity logging.\\n        logger_name (str): Name for the logger; defaults to \\'Mock handler\\'.\\n        loggerLvl (int): Logging level, set to logging.INFO by default.\\n        return_keys_list (list): Fields to return in search results; defaults to an empty list.\\n        search_results_n (int): Number of results to return in searches; defaults to 3.\\n        similarity_search_type (str): Type of similarity search to use; defaults to \\'hnsw\\'.\\n        similarity_params (dict): Parameters for similarity search; defaults to {\\'space\\':\\'cosine\\'}.\\n\\n    Attributes:\\n        data (dict): In-memory representation of database contents.\\n        filtered_data (dict): Stores filtered database entries based on criteria.\\n        keys_list (list): List of keys in the database.\\n        results_keys (list): Keys matching specific search criteria.\\n\\n    Methods:\\n        initialize_logger()\\n            Sets up logging for the class instance.\\n\\n        hnsw_search(search_emb, doc_embs, k=1, space=\\'cosine\\', ef_search=50, M=16, ef_construction=200)\\n            Performs HNSW algorithm-based search.\\n\\n        linear_search(search_emb, doc_embs, k=1, space=\\'cosine\\')\\n            Conducts a linear search.\\n\\n        establish_connection(file_path=None)\\n            Simulates establishing a database connection.\\n\\n        save_data()\\n            Saves the current state of the \\'data\\' attribute to a file.\\n\\n        embed(text)\\n            Generates embeddings for text inputs.\\n\\n        _prepare_for_redis(data_dict, var_for_embedding_name)\\n            Prepares data for storage in Redis.\\n\\n        insert_values_dict(values_dict, var_for_embedding_name)\\n            Simulates insertion of key-value pairs into the database.\\n\\n        flush_database()\\n            Clears all data in the mock database.\\n\\n        filter_keys(subkey=None, subvalue=None)\\n            Filters data entries based on a specific subkey and subvalue.\\n\\n        filter_database(filter_criteria=None)\\n            Filters a dictionary based on multiple field criteria.\\n\\n        remove_from_database(filter_criteria=None)\\n            Removes key-value pairs from a dictionary based on filter criteria.\\n\\n        search_database_keys(query, search_results_n=None, similarity_search_type=None, similarity_params=None)\\n            Searches the database using embeddings and saves a list of entries that match the query.\\n\\n        get_dict_results(return_keys_list=None)\\n            Retrieves specified fields from the search results.\\n\\n        search_database(query, search_results_n=None, filter_criteria=None, similarity_search_type=None,\\n                        similarity_params=None, return_keys_list=None)\\n            Searches and retrieves fields from the database for a given filter.\\n    \"\"\"\\n\\n    ## for accessing openAI models\\n    embeddings_url = attr.ib(default=None)\\n    godID = attr.ib(default=None)\\n    headers = attr.ib(default=None)\\n\\n    ## for embeddings\\n    model_type = attr.ib(default=\\'sentence_transformer\\', type=str)\\n    st_model_name = attr.ib(default=\\'all-MiniLM-L6-v2\\', type=str)\\n    st_model = attr.ib(default=None, init=False)\\n\\n\\n    ## for similarity search\\n    return_keys_list = attr.ib(default=[], type = list)\\n    search_results_n = attr.ib(default=3, type = int)\\n    similarity_search_type = attr.ib(default=\\'linear\\', type = str)\\n    similarity_params = attr.ib(default={\\'space\\':\\'cosine\\'}, type = dict)\\n\\n    ## inputs with defaults\\n    file_path = attr.ib(default=\"../redis_mock\", type=str)\\n    persist = attr.ib(default=False, type=bool)\\n\\n    embedder_error_tolerance = attr.ib(default=0.0, type=float)\\n\\n    logger = attr.ib(default=None)\\n    logger_name = attr.ib(default=\\'Mock handler\\')\\n    loggerLvl = attr.ib(default=logging.INFO)\\n    logger_format = attr.ib(default=None)\\n\\n    ## outputs\\n    data = attr.ib(default=None, init=False)\\n    filtered_data = attr.ib(default=None, init=False)\\n    keys_list = attr.ib(default=None, init = False)\\n    results_keys = attr.ib(default=None, init = False)\\n\\n    def __attrs_post_init__(self):\\n        self._initialize_logger()\\n        if self.model_type != \\'openAI\\':\\n            self.st_model = SentenceTransformer(self.st_model_name)\\n\\n    def _initialize_logger(self):\\n\\n        \"\"\"\\n        Initialize a logger for the class instance based on the specified logging level and logger name.\\n        \"\"\"\\n\\n        if self.logger is None:\\n            logging.basicConfig(level=self.loggerLvl, format=self.logger_format)\\n            logger = logging.getLogger(self.logger_name)\\n            logger.setLevel(self.loggerLvl)\\n\\n            self.logger = logger\\n\\n    def hnsw_search(self, search_emb, doc_embs, k=1, space=\\'cosine\\', ef_search=50, M=16, ef_construction=200):\\n        \"\"\"\\n        Perform Hierarchical Navigable Small World search.\\n\\n        Args:\\n        - search_emb (numpy array): The query embedding. Shape (1, dim).\\n        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\\n        - k (int): Number of nearest neighbors to return.\\n        - space (str): Space type for the index (\\'cosine\\' or \\'l2\\').\\n        - ef_search (int): Search parameter. Higher means more accurate but slower.\\n        - M (int): Index parameter.\\n        - ef_construction (int): Index construction parameter.\\n\\n        Returns:\\n        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\\n        - distances (numpy array): Distances of the k nearest embeddings.\\n        \"\"\"\\n\\n        # Declare index\\n        dim = len(search_emb)#.shape[1]\\n        p = hnswlib.Index(space=space, dim=dim)\\n\\n        # Initialize the index using the data\\n        p.init_index(max_elements=len(doc_embs), ef_construction=ef_construction, M=M)\\n\\n        # Add data to index\\n        p.add_items(doc_embs)\\n\\n        # Set the query ef parameter\\n        p.set_ef(ef_search)\\n\\n        # Query the index\\n        labels, distances = p.knn_query(search_emb, k=k)\\n\\n        return labels[0], distances[0]\\n\\n    def linear_search(self, search_emb, doc_embs, k=1, space=\\'cosine\\'):\\n\\n        \"\"\"\\n        Perform a linear (brute force) search.\\n\\n        Args:\\n        - search_emb (numpy array): The query embedding. Shape (1, dim).\\n        - doc_embs (numpy array): Array of reference embeddings. Shape (num_elements, dim).\\n        - k (int): Number of nearest neighbors to return.\\n        - space (str): Space type for the distance calculation (\\'cosine\\' or \\'l2\\').\\n\\n        Returns:\\n        - labels (numpy array): Indices of the k nearest embeddings from doc_embs to search_emb.\\n        - distances (numpy array): Distances of the k nearest embeddings.\\n        \"\"\"\\n\\n        # Calculate distances from the query to all document embeddings\\n        if space == \\'cosine\\':\\n            # Normalize embeddings for cosine similarity\\n            search_emb_norm = search_emb / np.linalg.norm(search_emb)\\n            doc_embs_norm = doc_embs / np.linalg.norm(doc_embs, axis=1)[:, np.newaxis]\\n\\n            # Compute cosine distances\\n            distances = np.dot(doc_embs_norm, search_emb_norm.T).flatten()\\n        elif space == \\'l2\\':\\n            # Compute L2 distances\\n            distances = np.linalg.norm(doc_embs - search_emb, axis=1)\\n\\n        # Get the indices of the top k closest embeddings\\n        if space == \\'cosine\\':\\n            # For cosine, larger values mean closer distance\\n            labels = np.argsort(-distances)[:k]\\n        else:\\n            # For L2, smaller values mean closer distance\\n            labels = np.argsort(distances)[:k]\\n\\n        # Get the distances of the top k closest embeddings\\n        top_distances = distances[labels]\\n\\n        return labels, top_distances\\n\\n    def establish_connection(self, file_path : str = None):\\n\\n        \"\"\"\\n        Simulates establishing a connection by loading data from a local file into the \\'data\\' attribute.\\n        \"\"\"\\n\\n        if file_path is None:\\n            file_path = self.file_path\\n\\n        try:\\n            with open(file_path, \\'rb\\') as file:\\n                self.data = dill.load(file)\\n        except FileNotFoundError:\\n            self.data = {}\\n        except Exception as e:\\n            self.logger.error(\"Error loading data from file: \", e)\\n\\n    def save_data(self):\\n\\n        \"\"\"\\n        Saves the current state of \\'data\\' back into a local file.\\n        \"\"\"\\n\\n        try:\\n            with open(self.file_path, \\'wb\\') as file:\\n                dill.dump(self.data, file)\\n        except Exception as e:\\n            self.logger.error(\"Error saving data to file: \", e)\\n\\n    def embed(self, text, model_type : str =  None ):\\n\\n        \"\"\"\\n        Embeds single query with sentence with selected embedder.\\n        \"\"\"\\n\\n        if model_type is None:\\n            model_type = self.model_type\\n\\n        if model_type == \\'openAI\\':\\n            return self.embed_openAI(text = text)\\n\\n        if model_type == \\'sentence_transformer\\':\\n            return self.embed_sentence_transformer(text = text)\\n\\n\\n    def embed_sentence_transformer(self, text):\\n\\n        \"\"\"\\n        Embeds single query with sentence tranformer embedder.\\n        \"\"\"\\n\\n        return self.st_model.encode(text)\\n\\n    def embed_openAI(self, text):\\n\\n        \"\"\"\\n        Embeds single query with openAI embedder.\\n        \"\"\"\\n\\n        api_url = self.embeddings_url\\n\\n        payload = json.dumps({\\n            \"user\": self.godID,\\n            \"input\": text\\n        })\\n\\n        try:\\n            response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\\n\\n            if response.status_code == 429:\\n                time.sleep(1)\\n                response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\\n\\n            if response.status_code > 200:\\n                print(f\"Request to \\'{api_url}\\' failed: {response}\")\\n                print(response.text)\\n                return None\\n\\n            embedding = response.json()[\\'data\\'][0][\\'embedding\\']\\n\\n        except:\\n            error_mess = \"An exception has occurred during embedding!\"\\n            if self.embedder_error_tolerance == 0.0:\\n                raise ValueError(error_mess)\\n            else:\\n                print(error_mess)\\n                return None\\n\\n        return embedding\\n\\n    def _prepare_for_redis(self, data_dict, var_for_embedding_name):\\n\\n        \"\"\"\\n        Prepare a dictionary for storage in Redis by serializing all its values to strings.\\n        \"\"\"\\n\\n        for key, _ in data_dict.items():\\n\\n            embedding = self.embed(data_dict[key][var_for_embedding_name])\\n            data_dict[key][\\'embedding\\'] = embedding\\n\\n        return data_dict\\n\\n\\n    def insert_values_dict(self, values_dict, var_for_embedding_name):\\n\\n        \"\"\"\\n        Simulates inserting key-value pairs into the mock Redis database.\\n        \"\"\"\\n\\n        try:\\n\\n            values_dict = self._prepare_for_redis(data_dict = values_dict,\\n                                                  var_for_embedding_name = var_for_embedding_name)\\n\\n            self.data.update(values_dict)\\n            self.save_data()\\n        except Exception as e:\\n            self.logger.error(\"Problem during inserting list of key-values dictionaries into mock database!\", e)\\n\\n    def flush_database(self):\\n\\n        \"\"\"\\n        Clears all data in the mock database.\\n        \"\"\"\\n\\n        try:\\n            self.data = {}\\n            if self.persist:\\n                self.save_data()\\n        except Exception as e:\\n            self.logger.error(\"Problem during flushing mock database\", e)\\n\\n    def filter_keys(self, subkey=None, subvalue=None):\\n\\n        \"\"\"\\n        Filters data entries based on a specific subkey and subvalue.\\n        \"\"\"\\n\\n        if (subkey is not None) and (subvalue is not None):\\n            self.keys_list = [d for d in self.data if self.data[d][subkey] == subvalue]\\n        else:\\n            self.keys_list = self.data\\n\\n    def filter_database(self, filter_criteria : dict = None):\\n\\n        \"\"\"\\n        Filters a dictionary based on multiple field criteria.\\n        \"\"\"\\n\\n        self.filtered_data = {\\n            key: value for key, value in self.data.items()\\n            if all(value.get(k) == v for k, v in filter_criteria.items())\\n        }\\n\\n    def remove_from_database(self, filter_criteria : dict = None):\\n        \"\"\"\\n        Removes key-value pairs from a dictionary based on filter criteria.\\n        \"\"\"\\n\\n        self.data = {\\n            key: value for key, value in self.data.items()\\n            if not all(value.get(k) == v for k, v in filter_criteria.items())\\n        }\\n\\n    def search_database_keys(self,\\n        query: str,\\n        search_results_n: int = None,\\n        similarity_search_type: str = None,\\n        similarity_params: dict = None):\\n\\n        \"\"\"\\n        Searches the mock database using embeddings and saves a list of entries that match the query.\\n        \"\"\"\\n\\n        try:\\n            query_embedding = self.embed(query)\\n        except Exception as e:\\n            self.logger.error(\"Problem during embedding search query!\", e)\\n\\n\\n        if search_results_n is None:\\n            search_results_n = self.search_results_n\\n\\n        if similarity_search_type is None:\\n            similarity_search_type = self.similarity_search_type\\n\\n        if similarity_params is None:\\n            similarity_params = self.similarity_params\\n\\n        if self.filtered_data is None:\\n            self.filtered_data = self.data\\n\\n        if self.keys_list is None:\\n            self.keys_list = [key for key in self.filtered_data]\\n\\n        try:\\n            data_embeddings = np.array([(self.filtered_data[d][\\'embedding\\']) for d in self.keys_list])\\n        except Exception as e:\\n            self.logger.error(\"Problem during extracting search pool embeddings!\", e)\\n\\n        try:\\n            if similarity_search_type == \\'linear\\':\\n                labels, _ = self.linear_search(query_embedding,\\n                data_embeddings,\\n                k=search_results_n,\\n                **similarity_params)\\n            else:\\n                labels, _ = self.hnsw_search(query_embedding,\\n                data_embeddings,\\n                k=search_results_n,\\n                **similarity_params)\\n\\n            self.results_keys = [self.keys_list[i] for i in labels]\\n        except Exception as e:\\n            self.logger.error(\"Problem during extracting results from the mock database!\", e)\\n\\n    def get_dict_results(self, return_keys_list : list = None) -> list:\\n\\n        \"\"\"\\n        Retrieves specified fields from the search results in the mock database.\\n        \"\"\"\\n\\n        if return_keys_list is None:\\n            return_keys_list = self.return_keys_list\\n\\n        # This method mimics the behavior of the original \\'get_dict_results\\' method\\n        results = []\\n        for searched_doc in self.results_keys:\\n            result = {key: self.data[searched_doc].get(key) for key in return_keys_list}\\n            results.append(result)\\n        return results\\n\\n    def search_database(self,\\n        query: str,\\n        search_results_n: int = None,\\n        filter_criteria : dict = None,\\n        similarity_search_type: str = None,\\n        similarity_params: dict = None,\\n        return_keys_list : list = None) ->list:\\n\\n        \"\"\"\\n        Searches through keys and retrieves specified fields from the search results\\n        in the mock database for a given filter.\\n        \"\"\"\\n\\n        if filter_criteria:\\n            self.filter_database(filter_criteria=filter_criteria)\\n\\n        self.search_database_keys(query = query,\\n                                    search_results_n = search_results_n,\\n                                    similarity_search_type = similarity_search_type,\\n                                    similarity_params = similarity_params)\\n\\n        results = self.get_dict_results(return_keys_list = return_keys_list)\\n\\n        # resetting search\\n        self.filtered_data = None\\n        self.keys_list = None\\n\\n        return results\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\"\"\"\\nMock Vector Db Handler'),\n",
       " Document(page_content='This class is a mock handler for simulating a'),\n",
       " Document(page_content='vector database, designed primarily for testing'),\n",
       " Document(page_content='and development scenarios.'),\n",
       " Document(page_content='It offers functionalities such as text embedding,'),\n",
       " Document(page_content='hierarchical navigable small world (HNSW) search,'),\n",
       " Document(page_content='and basic data management within a simulated'),\n",
       " Document(page_content='environment resembling a vector database.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='# Imports\\n## essential\\nimport logging'),\n",
       " Document(page_content='import json\\nimport time'),\n",
       " Document(page_content='import numpy as np #==1.26.0\\nimport dill #==0.3.7'),\n",
       " Document(page_content='import attr #>=22.2.0\\n## for search'),\n",
       " Document(page_content='import requests #==2.31.0\\nimport hnswlib #0.7.0'),\n",
       " Document(page_content='from sentence_transformers import'),\n",
       " Document(page_content='SentenceTransformer #==2.2.2'),\n",
       " Document(page_content='# Metadata for package creation'),\n",
       " Document(page_content='__package_metadata__ = {'),\n",
       " Document(page_content='\"author\": \"Kyrylo Mordan\",'),\n",
       " Document(page_content='\"author_email\": \"parachute.repo@gmail.com\",'),\n",
       " Document(page_content='\"version\": \"0.0.1\",'),\n",
       " Document(page_content='\"description\": \"A mock handler for simulating'),\n",
       " Document(page_content='a vector database.\",'),\n",
       " Document(page_content='\"keywords\" : [\\'python\\', \\'vector database\\','),\n",
       " Document(page_content=\"'similarity search']\"),\n",
       " Document(page_content='# Add other metadata as needed\\n}'),\n",
       " Document(page_content='@attr.s'),\n",
       " Document(page_content='class MockVecDbHandler:'),\n",
       " Document(page_content='# pylint:'),\n",
       " Document(page_content='disable=too-many-instance-attributes'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='The MockVecDbHandler class simulates a vector'),\n",
       " Document(page_content='database environment, primarily for testing and'),\n",
       " Document(page_content='development purposes.'),\n",
       " Document(page_content='It integrates various functionalities such as'),\n",
       " Document(page_content='text embedding, Hierarchical Navigable Small'),\n",
       " Document(page_content='World (HNSW) search,'),\n",
       " Document(page_content='and basic data management, mimicking'),\n",
       " Document(page_content='operations in a real vector database.'),\n",
       " Document(page_content='Parameters:'),\n",
       " Document(page_content='embeddings_url (str): URL to access'),\n",
       " Document(page_content='OpenAI models for generating embeddings, crucial'),\n",
       " Document(page_content='for text analysis.'),\n",
       " Document(page_content='godID (str): Unique identifier for'),\n",
       " Document(page_content='authentication with the embedding service.'),\n",
       " Document(page_content='headers (dict): HTTP headers for API'),\n",
       " Document(page_content='interactions with the embedding service.'),\n",
       " Document(page_content='file_path (str): Local file path for'),\n",
       " Document(page_content='storing and simulating the database; defaults to'),\n",
       " Document(page_content='\"../redis_mock\".'),\n",
       " Document(page_content='persist (bool): Flag to persist data'),\n",
       " Document(page_content='changes; defaults to False.'),\n",
       " Document(page_content='embedder_error_tolerance (float):'),\n",
       " Document(page_content='Tolerance level for embedding errors; defaults to'),\n",
       " Document(page_content='0.0.'),\n",
       " Document(page_content='logger (logging.Logger): Logger instance'),\n",
       " Document(page_content='for activity logging.'),\n",
       " Document(page_content='logger_name (str): Name for the logger;'),\n",
       " Document(page_content=\"defaults to 'Mock handler'.\"),\n",
       " Document(page_content='loggerLvl (int): Logging level, set to'),\n",
       " Document(page_content='logging.INFO by default.'),\n",
       " Document(page_content='return_keys_list (list): Fields to return'),\n",
       " Document(page_content='in search results; defaults to an empty list.'),\n",
       " Document(page_content='search_results_n (int): Number of results'),\n",
       " Document(page_content='to return in searches; defaults to 3.'),\n",
       " Document(page_content='similarity_search_type (str): Type of'),\n",
       " Document(page_content=\"similarity search to use; defaults to 'hnsw'.\"),\n",
       " Document(page_content='similarity_params (dict): Parameters for'),\n",
       " Document(page_content='similarity search; defaults to'),\n",
       " Document(page_content=\"{'space':'cosine'}.\"),\n",
       " Document(page_content='Attributes:'),\n",
       " Document(page_content='data (dict): In-memory representation of'),\n",
       " Document(page_content='database contents.'),\n",
       " Document(page_content='filtered_data (dict): Stores filtered'),\n",
       " Document(page_content='database entries based on criteria.'),\n",
       " Document(page_content='keys_list (list): List of keys in the'),\n",
       " Document(page_content='database.'),\n",
       " Document(page_content='results_keys (list): Keys matching'),\n",
       " Document(page_content='specific search criteria.'),\n",
       " Document(page_content='Methods:\\n        initialize_logger()'),\n",
       " Document(page_content='Sets up logging for the class'),\n",
       " Document(page_content='instance.'),\n",
       " Document(page_content='hnsw_search(search_emb, doc_embs, k=1,'),\n",
       " Document(page_content=\"space='cosine', ef_search=50, M=16,\"),\n",
       " Document(page_content='ef_construction=200)'),\n",
       " Document(page_content='Performs HNSW algorithm-based search.'),\n",
       " Document(page_content='linear_search(search_emb, doc_embs, k=1,'),\n",
       " Document(page_content=\"space='cosine')\"),\n",
       " Document(page_content='Conducts a linear search.'),\n",
       " Document(page_content='establish_connection(file_path=None)'),\n",
       " Document(page_content='Simulates establishing a database'),\n",
       " Document(page_content='connection.'),\n",
       " Document(page_content='save_data()'),\n",
       " Document(page_content=\"Saves the current state of the 'data'\"),\n",
       " Document(page_content='attribute to a file.'),\n",
       " Document(page_content='embed(text)'),\n",
       " Document(page_content='Generates embeddings for text inputs.'),\n",
       " Document(page_content='_prepare_for_redis(data_dict,'),\n",
       " Document(page_content='var_for_embedding_name)'),\n",
       " Document(page_content='Prepares data for storage in Redis.'),\n",
       " Document(page_content='insert_values_dict(values_dict,'),\n",
       " Document(page_content='var_for_embedding_name)'),\n",
       " Document(page_content='Simulates insertion of key-value'),\n",
       " Document(page_content='pairs into the database.'),\n",
       " Document(page_content='flush_database()'),\n",
       " Document(page_content='Clears all data in the mock database.'),\n",
       " Document(page_content='filter_keys(subkey=None, subvalue=None)'),\n",
       " Document(page_content='Filters data entries based on a'),\n",
       " Document(page_content='specific subkey and subvalue.'),\n",
       " Document(page_content='filter_database(filter_criteria=None)'),\n",
       " Document(page_content='Filters a dictionary based on'),\n",
       " Document(page_content='multiple field criteria.'),\n",
       " Document(page_content='remove_from_database(filter_criteria=None)'),\n",
       " Document(page_content='Removes key-value pairs from a'),\n",
       " Document(page_content='dictionary based on filter criteria.'),\n",
       " Document(page_content='search_database_keys(query,'),\n",
       " Document(page_content='search_results_n=None,'),\n",
       " Document(page_content='similarity_search_type=None,'),\n",
       " Document(page_content='similarity_params=None)'),\n",
       " Document(page_content='Searches the database using'),\n",
       " Document(page_content='embeddings and saves a list of entries that match'),\n",
       " Document(page_content='the query.'),\n",
       " Document(page_content='get_dict_results(return_keys_list=None)'),\n",
       " Document(page_content='Retrieves specified fields from the'),\n",
       " Document(page_content='search results.'),\n",
       " Document(page_content='search_database(query,'),\n",
       " Document(page_content='search_results_n=None, filter_criteria=None,'),\n",
       " Document(page_content='similarity_search_type=None,'),\n",
       " Document(page_content='similarity_params=None,'),\n",
       " Document(page_content='return_keys_list=None)'),\n",
       " Document(page_content='Searches and retrieves fields from'),\n",
       " Document(page_content='the database for a given filter.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='## for accessing openAI models'),\n",
       " Document(page_content='embeddings_url = attr.ib(default=None)'),\n",
       " Document(page_content='godID = attr.ib(default=None)'),\n",
       " Document(page_content='headers = attr.ib(default=None)'),\n",
       " Document(page_content='## for embeddings'),\n",
       " Document(page_content='model_type ='),\n",
       " Document(page_content=\"attr.ib(default='sentence_transformer', type=str)\"),\n",
       " Document(page_content='st_model_name ='),\n",
       " Document(page_content=\"attr.ib(default='all-MiniLM-L6-v2', type=str)\"),\n",
       " Document(page_content='st_model = attr.ib(default=None, init=False)'),\n",
       " Document(page_content='## for similarity search'),\n",
       " Document(page_content='return_keys_list = attr.ib(default=[], type ='),\n",
       " Document(page_content='list)'),\n",
       " Document(page_content='search_results_n = attr.ib(default=3, type ='),\n",
       " Document(page_content='int)'),\n",
       " Document(page_content='similarity_search_type ='),\n",
       " Document(page_content=\"attr.ib(default='linear', type = str)\"),\n",
       " Document(page_content='similarity_params ='),\n",
       " Document(page_content=\"attr.ib(default={'space':'cosine'}, type = dict)\"),\n",
       " Document(page_content='## inputs with defaults'),\n",
       " Document(page_content='file_path = attr.ib(default=\"../redis_mock\",'),\n",
       " Document(page_content='type=str)'),\n",
       " Document(page_content='persist = attr.ib(default=False, type=bool)'),\n",
       " Document(page_content='embedder_error_tolerance ='),\n",
       " Document(page_content='attr.ib(default=0.0, type=float)'),\n",
       " Document(page_content='logger = attr.ib(default=None)'),\n",
       " Document(page_content=\"logger_name = attr.ib(default='Mock handler')\"),\n",
       " Document(page_content='loggerLvl = attr.ib(default=logging.INFO)'),\n",
       " Document(page_content='logger_format = attr.ib(default=None)'),\n",
       " Document(page_content='## outputs'),\n",
       " Document(page_content='data = attr.ib(default=None, init=False)'),\n",
       " Document(page_content='filtered_data = attr.ib(default=None,'),\n",
       " Document(page_content='init=False)'),\n",
       " Document(page_content='keys_list = attr.ib(default=None, init ='),\n",
       " Document(page_content='False)'),\n",
       " Document(page_content='results_keys = attr.ib(default=None, init ='),\n",
       " Document(page_content='False)'),\n",
       " Document(page_content='def __attrs_post_init__(self):'),\n",
       " Document(page_content='self._initialize_logger()'),\n",
       " Document(page_content=\"if self.model_type != 'openAI':\"),\n",
       " Document(page_content='self.st_model ='),\n",
       " Document(page_content='SentenceTransformer(self.st_model_name)'),\n",
       " Document(page_content='def _initialize_logger(self):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Initialize a logger for the class'),\n",
       " Document(page_content='instance based on the specified logging level and'),\n",
       " Document(page_content='logger name.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if self.logger is None:'),\n",
       " Document(page_content='logging.basicConfig(level=self.loggerLvl,'),\n",
       " Document(page_content='format=self.logger_format)'),\n",
       " Document(page_content='logger ='),\n",
       " Document(page_content='logging.getLogger(self.logger_name)'),\n",
       " Document(page_content='logger.setLevel(self.loggerLvl)'),\n",
       " Document(page_content='self.logger = logger'),\n",
       " Document(page_content='def hnsw_search(self, search_emb, doc_embs,'),\n",
       " Document(page_content=\"k=1, space='cosine', ef_search=50, M=16,\"),\n",
       " Document(page_content='ef_construction=200):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Perform Hierarchical Navigable Small'),\n",
       " Document(page_content='World search.'),\n",
       " Document(page_content='Args:'),\n",
       " Document(page_content='- search_emb (numpy array): The query'),\n",
       " Document(page_content='embedding. Shape (1, dim).'),\n",
       " Document(page_content='- doc_embs (numpy array): Array of'),\n",
       " Document(page_content='reference embeddings. Shape (num_elements, dim).'),\n",
       " Document(page_content='- k (int): Number of nearest neighbors to'),\n",
       " Document(page_content='return.'),\n",
       " Document(page_content='- space (str): Space type for the index'),\n",
       " Document(page_content=\"('cosine' or 'l2').\"),\n",
       " Document(page_content='- ef_search (int): Search parameter.'),\n",
       " Document(page_content='Higher means more accurate but slower.'),\n",
       " Document(page_content='- M (int): Index parameter.'),\n",
       " Document(page_content='- ef_construction (int): Index'),\n",
       " Document(page_content='construction parameter.'),\n",
       " Document(page_content='Returns:'),\n",
       " Document(page_content='- labels (numpy array): Indices of the k'),\n",
       " Document(page_content='nearest embeddings from doc_embs to search_emb.'),\n",
       " Document(page_content='- distances (numpy array): Distances of'),\n",
       " Document(page_content='the k nearest embeddings.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='# Declare index'),\n",
       " Document(page_content='dim = len(search_emb)#.shape[1]'),\n",
       " Document(page_content='p = hnswlib.Index(space=space, dim=dim)'),\n",
       " Document(page_content='# Initialize the index using the data'),\n",
       " Document(page_content='p.init_index(max_elements=len(doc_embs),'),\n",
       " Document(page_content='ef_construction=ef_construction, M=M)'),\n",
       " Document(page_content='# Add data to index'),\n",
       " Document(page_content='p.add_items(doc_embs)'),\n",
       " Document(page_content='# Set the query ef parameter'),\n",
       " Document(page_content='p.set_ef(ef_search)'),\n",
       " Document(page_content='# Query the index'),\n",
       " Document(page_content='labels, distances ='),\n",
       " Document(page_content='p.knn_query(search_emb, k=k)'),\n",
       " Document(page_content='return labels[0], distances[0]'),\n",
       " Document(page_content='def linear_search(self, search_emb, doc_embs,'),\n",
       " Document(page_content=\"k=1, space='cosine'):\"),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Perform a linear (brute force) search.'),\n",
       " Document(page_content='Args:'),\n",
       " Document(page_content='- search_emb (numpy array): The query'),\n",
       " Document(page_content='embedding. Shape (1, dim).'),\n",
       " Document(page_content='- doc_embs (numpy array): Array of'),\n",
       " Document(page_content='reference embeddings. Shape (num_elements, dim).'),\n",
       " Document(page_content='- k (int): Number of nearest neighbors to'),\n",
       " Document(page_content='return.'),\n",
       " Document(page_content='- space (str): Space type for the'),\n",
       " Document(page_content=\"distance calculation ('cosine' or 'l2').\"),\n",
       " Document(page_content='Returns:'),\n",
       " Document(page_content='- labels (numpy array): Indices of the k'),\n",
       " Document(page_content='nearest embeddings from doc_embs to search_emb.'),\n",
       " Document(page_content='- distances (numpy array): Distances of'),\n",
       " Document(page_content='the k nearest embeddings.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='# Calculate distances from the query to'),\n",
       " Document(page_content='all document embeddings'),\n",
       " Document(page_content=\"if space == 'cosine':\"),\n",
       " Document(page_content='# Normalize embeddings for cosine'),\n",
       " Document(page_content='similarity'),\n",
       " Document(page_content='search_emb_norm = search_emb /'),\n",
       " Document(page_content='np.linalg.norm(search_emb)'),\n",
       " Document(page_content='doc_embs_norm = doc_embs /'),\n",
       " Document(page_content='np.linalg.norm(doc_embs, axis=1)[:, np.newaxis]'),\n",
       " Document(page_content='# Compute cosine distances'),\n",
       " Document(page_content='distances = np.dot(doc_embs_norm,'),\n",
       " Document(page_content='search_emb_norm.T).flatten()'),\n",
       " Document(page_content=\"elif space == 'l2':\"),\n",
       " Document(page_content='# Compute L2 distances'),\n",
       " Document(page_content='distances = np.linalg.norm(doc_embs -'),\n",
       " Document(page_content='search_emb, axis=1)'),\n",
       " Document(page_content='# Get the indices of the top k closest'),\n",
       " Document(page_content='embeddings'),\n",
       " Document(page_content=\"if space == 'cosine':\"),\n",
       " Document(page_content='# For cosine, larger values mean'),\n",
       " Document(page_content='closer distance'),\n",
       " Document(page_content='labels = np.argsort(-distances)[:k]'),\n",
       " Document(page_content='else:'),\n",
       " Document(page_content='# For L2, smaller values mean closer'),\n",
       " Document(page_content='distance'),\n",
       " Document(page_content='labels = np.argsort(distances)[:k]'),\n",
       " Document(page_content='# Get the distances of the top k closest'),\n",
       " Document(page_content='embeddings'),\n",
       " Document(page_content='top_distances = distances[labels]'),\n",
       " Document(page_content='return labels, top_distances'),\n",
       " Document(page_content='def establish_connection(self, file_path :'),\n",
       " Document(page_content='str = None):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Simulates establishing a connection by'),\n",
       " Document(page_content=\"loading data from a local file into the 'data'\"),\n",
       " Document(page_content='attribute.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if file_path is None:'),\n",
       " Document(page_content='file_path = self.file_path'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content=\"with open(file_path, 'rb') as file:\"),\n",
       " Document(page_content='self.data = dill.load(file)'),\n",
       " Document(page_content='except FileNotFoundError:'),\n",
       " Document(page_content='self.data = {}'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Error loading data'),\n",
       " Document(page_content='from file: \", e)'),\n",
       " Document(page_content='def save_data(self):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content=\"Saves the current state of 'data' back\"),\n",
       " Document(page_content='into a local file.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content=\"with open(self.file_path, 'wb') as\"),\n",
       " Document(page_content='file:'),\n",
       " Document(page_content='dill.dump(self.data, file)'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Error saving data'),\n",
       " Document(page_content='to file: \", e)'),\n",
       " Document(page_content='def embed(self, text, model_type : str ='),\n",
       " Document(page_content='None ):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Embeds single query with sentence with'),\n",
       " Document(page_content='selected embedder.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if model_type is None:'),\n",
       " Document(page_content='model_type = self.model_type'),\n",
       " Document(page_content=\"if model_type == 'openAI':\"),\n",
       " Document(page_content='return self.embed_openAI(text = text)'),\n",
       " Document(page_content=\"if model_type == 'sentence_transformer':\"),\n",
       " Document(page_content='return'),\n",
       " Document(page_content='self.embed_sentence_transformer(text = text)'),\n",
       " Document(page_content='def embed_sentence_transformer(self, text):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Embeds single query with sentence'),\n",
       " Document(page_content='tranformer embedder.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='return self.st_model.encode(text)'),\n",
       " Document(page_content='def embed_openAI(self, text):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Embeds single query with openAI embedder.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='api_url = self.embeddings_url'),\n",
       " Document(page_content='payload = json.dumps({'),\n",
       " Document(page_content='\"user\": self.godID,'),\n",
       " Document(page_content='\"input\": text\\n        })'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content='response = requests.post(api_url,'),\n",
       " Document(page_content='headers=self.headers, data=payload, timeout=10)'),\n",
       " Document(page_content='if response.status_code == 429:'),\n",
       " Document(page_content='time.sleep(1)'),\n",
       " Document(page_content='response = requests.post(api_url,'),\n",
       " Document(page_content='headers=self.headers, data=payload, timeout=10)'),\n",
       " Document(page_content='if response.status_code > 200:'),\n",
       " Document(page_content='print(f\"Request to \\'{api_url}\\''),\n",
       " Document(page_content='failed: {response}\")'),\n",
       " Document(page_content='print(response.text)'),\n",
       " Document(page_content='return None'),\n",
       " Document(page_content='embedding ='),\n",
       " Document(page_content=\"response.json()['data'][0]['embedding']\"),\n",
       " Document(page_content='except:'),\n",
       " Document(page_content='error_mess = \"An exception has'),\n",
       " Document(page_content='occurred during embedding!\"'),\n",
       " Document(page_content='if self.embedder_error_tolerance =='),\n",
       " Document(page_content='0.0:'),\n",
       " Document(page_content='raise ValueError(error_mess)'),\n",
       " Document(page_content='else:'),\n",
       " Document(page_content='print(error_mess)'),\n",
       " Document(page_content='return None'),\n",
       " Document(page_content='return embedding'),\n",
       " Document(page_content='def _prepare_for_redis(self, data_dict,'),\n",
       " Document(page_content='var_for_embedding_name):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Prepare a dictionary for storage in Redis'),\n",
       " Document(page_content='by serializing all its values to strings.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='for key, _ in data_dict.items():'),\n",
       " Document(page_content='embedding ='),\n",
       " Document(page_content='self.embed(data_dict[key][var_for_embedding_name]'),\n",
       " Document(page_content=')'),\n",
       " Document(page_content=\"data_dict[key]['embedding'] =\"),\n",
       " Document(page_content='embedding'),\n",
       " Document(page_content='return data_dict'),\n",
       " Document(page_content='def insert_values_dict(self, values_dict,'),\n",
       " Document(page_content='var_for_embedding_name):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Simulates inserting key-value pairs into'),\n",
       " Document(page_content='the mock Redis database.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content='values_dict ='),\n",
       " Document(page_content='self._prepare_for_redis(data_dict = values_dict,'),\n",
       " Document(page_content='var_for_embedding_name = var_for_embedding_name)'),\n",
       " Document(page_content='self.data.update(values_dict)'),\n",
       " Document(page_content='self.save_data()'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Problem during'),\n",
       " Document(page_content='inserting list of key-values dictionaries into'),\n",
       " Document(page_content='mock database!\", e)'),\n",
       " Document(page_content='def flush_database(self):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Clears all data in the mock database.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='try:\\n            self.data = {}'),\n",
       " Document(page_content='if self.persist:'),\n",
       " Document(page_content='self.save_data()'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Problem during'),\n",
       " Document(page_content='flushing mock database\", e)'),\n",
       " Document(page_content='def filter_keys(self, subkey=None,'),\n",
       " Document(page_content='subvalue=None):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Filters data entries based on a specific'),\n",
       " Document(page_content='subkey and subvalue.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if (subkey is not None) and (subvalue is'),\n",
       " Document(page_content='not None):'),\n",
       " Document(page_content='self.keys_list = [d for d in'),\n",
       " Document(page_content='self.data if self.data[d][subkey] == subvalue]'),\n",
       " Document(page_content='else:'),\n",
       " Document(page_content='self.keys_list = self.data'),\n",
       " Document(page_content='def filter_database(self, filter_criteria :'),\n",
       " Document(page_content='dict = None):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Filters a dictionary based on multiple'),\n",
       " Document(page_content='field criteria.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='self.filtered_data = {'),\n",
       " Document(page_content='key: value for key, value in'),\n",
       " Document(page_content='self.data.items()'),\n",
       " Document(page_content='if all(value.get(k) == v for k, v in'),\n",
       " Document(page_content='filter_criteria.items())'),\n",
       " Document(page_content='}'),\n",
       " Document(page_content='def remove_from_database(self,'),\n",
       " Document(page_content='filter_criteria : dict = None):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Removes key-value pairs from a dictionary'),\n",
       " Document(page_content='based on filter criteria.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='self.data = {'),\n",
       " Document(page_content='key: value for key, value in'),\n",
       " Document(page_content='self.data.items()'),\n",
       " Document(page_content='if not all(value.get(k) == v for k, v'),\n",
       " Document(page_content='in filter_criteria.items())'),\n",
       " Document(page_content='}'),\n",
       " Document(page_content='def search_database_keys(self,'),\n",
       " Document(page_content='query: str,'),\n",
       " Document(page_content='search_results_n: int = None,'),\n",
       " Document(page_content='similarity_search_type: str = None,'),\n",
       " Document(page_content='similarity_params: dict = None):'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Searches the mock database using'),\n",
       " Document(page_content='embeddings and saves a list of entries that match'),\n",
       " Document(page_content='the query.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content='query_embedding = self.embed(query)'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Problem during'),\n",
       " Document(page_content='embedding search query!\", e)'),\n",
       " Document(page_content='if search_results_n is None:'),\n",
       " Document(page_content='search_results_n ='),\n",
       " Document(page_content='self.search_results_n'),\n",
       " Document(page_content='if similarity_search_type is None:'),\n",
       " Document(page_content='similarity_search_type ='),\n",
       " Document(page_content='self.similarity_search_type'),\n",
       " Document(page_content='if similarity_params is None:'),\n",
       " Document(page_content='similarity_params ='),\n",
       " Document(page_content='self.similarity_params'),\n",
       " Document(page_content='if self.filtered_data is None:'),\n",
       " Document(page_content='self.filtered_data = self.data'),\n",
       " Document(page_content='if self.keys_list is None:'),\n",
       " Document(page_content='self.keys_list = [key for key in'),\n",
       " Document(page_content='self.filtered_data]'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content='data_embeddings ='),\n",
       " Document(page_content=\"np.array([(self.filtered_data[d]['embedding'])\"),\n",
       " Document(page_content='for d in self.keys_list])'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Problem during'),\n",
       " Document(page_content='extracting search pool embeddings!\", e)'),\n",
       " Document(page_content='try:'),\n",
       " Document(page_content='if similarity_search_type =='),\n",
       " Document(page_content=\"'linear':\"),\n",
       " Document(page_content='labels, _ ='),\n",
       " Document(page_content='self.linear_search(query_embedding,'),\n",
       " Document(page_content='data_embeddings,'),\n",
       " Document(page_content='k=search_results_n,'),\n",
       " Document(page_content='**similarity_params)'),\n",
       " Document(page_content='else:'),\n",
       " Document(page_content='labels, _ ='),\n",
       " Document(page_content='self.hnsw_search(query_embedding,'),\n",
       " Document(page_content='data_embeddings,'),\n",
       " Document(page_content='k=search_results_n,'),\n",
       " Document(page_content='**similarity_params)'),\n",
       " Document(page_content='self.results_keys ='),\n",
       " Document(page_content='[self.keys_list[i] for i in labels]'),\n",
       " Document(page_content='except Exception as e:'),\n",
       " Document(page_content='self.logger.error(\"Problem during'),\n",
       " Document(page_content='extracting results from the mock database!\", e)'),\n",
       " Document(page_content='def get_dict_results(self, return_keys_list :'),\n",
       " Document(page_content='list = None) -> list:'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Retrieves specified fields from the'),\n",
       " Document(page_content='search results in the mock database.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if return_keys_list is None:'),\n",
       " Document(page_content='return_keys_list ='),\n",
       " Document(page_content='self.return_keys_list'),\n",
       " Document(page_content='# This method mimics the behavior of the'),\n",
       " Document(page_content=\"original 'get_dict_results' method\"),\n",
       " Document(page_content='results = []'),\n",
       " Document(page_content='for searched_doc in self.results_keys:'),\n",
       " Document(page_content='result = {key:'),\n",
       " Document(page_content='self.data[searched_doc].get(key) for key in'),\n",
       " Document(page_content='return_keys_list}'),\n",
       " Document(page_content='results.append(result)'),\n",
       " Document(page_content='return results'),\n",
       " Document(page_content='def search_database(self,'),\n",
       " Document(page_content='query: str,'),\n",
       " Document(page_content='search_results_n: int = None,'),\n",
       " Document(page_content='filter_criteria : dict = None,'),\n",
       " Document(page_content='similarity_search_type: str = None,'),\n",
       " Document(page_content='similarity_params: dict = None,'),\n",
       " Document(page_content='return_keys_list : list = None) ->list:'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='Searches through keys and retrieves'),\n",
       " Document(page_content='specified fields from the search results'),\n",
       " Document(page_content='in the mock database for a given filter.'),\n",
       " Document(page_content='\"\"\"'),\n",
       " Document(page_content='if filter_criteria:'),\n",
       " Document(page_content='self.filter_database(filter_criteria=filter_crite'),\n",
       " Document(page_content='ria)'),\n",
       " Document(page_content='self.search_database_keys(query = query,'),\n",
       " Document(page_content='search_results_n = search_results_n,'),\n",
       " Document(page_content='similarity_search_type = similarity_search_type,'),\n",
       " Document(page_content='similarity_params = similarity_params)'),\n",
       " Document(page_content='results ='),\n",
       " Document(page_content='self.get_dict_results(return_keys_list ='),\n",
       " Document(page_content='return_keys_list)'),\n",
       " Document(page_content='# resetting search'),\n",
       " Document(page_content='self.filtered_data = None'),\n",
       " Document(page_content='self.keys_list = None'),\n",
       " Document(page_content='return results')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([module_content])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please provide a docstring for the `hnsw_search` method in the `MockVecDbHandler` class. The docstring should succinctly describe the method's purpose, its parameters, any significant internal processes, and its return values, focusing on details relevant for a state diagram. It is crucial that the response contains only the docstring without including any part of the method's code.\n",
    "\n",
    "Here is the method:\n",
    "\n",
    "@attr.s\n",
    "class MockVecDbHandler:\n",
    "\n",
    "    def hnsw_search(self, search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200):\n",
    "        dim = len(search_emb)\n",
    "        p = hnswlib.Index(space=space, dim=dim)\n",
    "        p.init_index(max_elements=len(doc_embs), ef_construction=ef_construction, M=M)\n",
    "        p.add_items(doc_embs)\n",
    "        p.set_ef(ef_search)\n",
    "        labels, distances = p.knn_query(search_emb, k=k)\n",
    "        return (labels[0], distances[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform a HNSW search to find the nearest neighbors of a search embedding within a set of document embeddings.\n",
      "\n",
      "    Parameters:\n",
      "    - search_emb: The embedding vector to search for nearest neighbors.\n",
      "    - doc_embs: List of document embeddings to search within.\n",
      "    - k: The number of nearest neighbors to retrieve (default is 1).\n",
      "    - space: The distance metric space to use for similarity calculation (default is 'cosine').\n",
      "    - ef_search: The search effort factor for finding nearest neighbors (default is 50).\n",
      "    - M: The degree of the HNSW graph for construction (default is 16).\n",
      "    - ef_construction: The construction effort factor for building the HNSW graph (default is 200).\n",
      "\n",
      "    Returns:\n",
      "    - Tuple containing two lists:\n",
      "        - The labels of the k nearest neighbors.\n",
      "        - The corresponding distances from the search embedding to the neighbors.\n",
      "    \n",
      "    This method initializes a HNSW index, adds document embeddings to it, and then performs a k-nearest neighbors search\n",
      "    for the given search embedding. The search is performed in the specified distance metric space, and the results\n",
      "    include the labels and distances of the nearest neighbors.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Your chat output containing the docstring\n",
    "chat_output = \"\"\"\n",
    "def hnsw_search(self, search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200):\n",
    "    \\\"\\\"\\\"\n",
    "    Perform a HNSW search to find the nearest neighbors of a search embedding within a set of document embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - search_emb: The embedding vector to search for nearest neighbors.\n",
    "    - doc_embs: List of document embeddings to search within.\n",
    "    - k: The number of nearest neighbors to retrieve (default is 1).\n",
    "    - space: The distance metric space to use for similarity calculation (default is 'cosine').\n",
    "    - ef_search: The search effort factor for finding nearest neighbors (default is 50).\n",
    "    - M: The degree of the HNSW graph for construction (default is 16).\n",
    "    - ef_construction: The construction effort factor for building the HNSW graph (default is 200).\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing two lists:\n",
    "        - The labels of the k nearest neighbors.\n",
    "        - The corresponding distances from the search embedding to the neighbors.\n",
    "    \n",
    "    This method initializes a HNSW index, adds document embeddings to it, and then performs a k-nearest neighbors search\n",
    "    for the given search embedding. The search is performed in the specified distance metric space, and the results\n",
    "    include the labels and distances of the nearest neighbors.\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Use regular expressions to extract the docstring\n",
    "docstring_match = re.search(r'\"\"\"(.*?)\"\"\"', chat_output, re.DOTALL)\n",
    "if docstring_match:\n",
    "    extracted_docstring = docstring_match.group(1).strip()\n",
    "    print(extracted_docstring)\n",
    "else:\n",
    "    print(\"Docstring not found in chat output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def __attrs_post_init__(self):\n",
      "        self._initialize_logger()\n",
      "        if self.model_type != 'openAI':\n",
      "            self.st_model = SentenceTransformer(self.st_model_name)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def _initialize_logger(self):\n",
      "        if self.logger is None:\n",
      "            logging.basicConfig(level=self.loggerLvl, format=self.logger_format)\n",
      "            logger = logging.getLogger(self.logger_name)\n",
      "            logger.setLevel(self.loggerLvl)\n",
      "            self.logger = logger\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def hnsw_search(self, search_emb, doc_embs, k=1, space='cosine', ef_search=50, M=16, ef_construction=200):\n",
      "        dim = len(search_emb)\n",
      "        p = hnswlib.Index(space=space, dim=dim)\n",
      "        p.init_index(max_elements=len(doc_embs), ef_construction=ef_construction, M=M)\n",
      "        p.add_items(doc_embs)\n",
      "        p.set_ef(ef_search)\n",
      "        labels, distances = p.knn_query(search_emb, k=k)\n",
      "        return (labels[0], distances[0])\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def linear_search(self, search_emb, doc_embs, k=1, space='cosine'):\n",
      "        if space == 'cosine':\n",
      "            search_emb_norm = search_emb / np.linalg.norm(search_emb)\n",
      "            doc_embs_norm = doc_embs / np.linalg.norm(doc_embs, axis=1)[:, np.newaxis]\n",
      "            distances = np.dot(doc_embs_norm, search_emb_norm.T).flatten()\n",
      "        elif space == 'l2':\n",
      "            distances = np.linalg.norm(doc_embs - search_emb, axis=1)\n",
      "        if space == 'cosine':\n",
      "            labels = np.argsort(-distances)[:k]\n",
      "        else:\n",
      "            labels = np.argsort(distances)[:k]\n",
      "        top_distances = distances[labels]\n",
      "        return (labels, top_distances)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def establish_connection(self, file_path: str=None):\n",
      "        if file_path is None:\n",
      "            file_path = self.file_path\n",
      "        try:\n",
      "            with open(file_path, 'rb') as file:\n",
      "                self.data = dill.load(file)\n",
      "        except FileNotFoundError:\n",
      "            self.data = {}\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error loading data from file: ', e)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def save_data(self):\n",
      "        try:\n",
      "            with open(self.file_path, 'wb') as file:\n",
      "                dill.dump(self.data, file)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Error saving data to file: ', e)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed(self, text, model_type: str=None):\n",
      "        if model_type is None:\n",
      "            model_type = self.model_type\n",
      "        if model_type == 'openAI':\n",
      "            return self.embed_openAI(text=text)\n",
      "        if model_type == 'sentence_transformer':\n",
      "            return self.embed_sentence_transformer(text=text)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed_sentence_transformer(self, text):\n",
      "        return self.st_model.encode(text)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def embed_openAI(self, text):\n",
      "        api_url = self.embeddings_url\n",
      "        payload = json.dumps({'user': self.godID, 'input': text})\n",
      "        try:\n",
      "            response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code == 429:\n",
      "                time.sleep(1)\n",
      "                response = requests.post(api_url, headers=self.headers, data=payload, timeout=10)\n",
      "            if response.status_code > 200:\n",
      "                print(f\"Request to '{api_url}' failed: {response}\")\n",
      "                print(response.text)\n",
      "                return None\n",
      "            embedding = response.json()['data'][0]['embedding']\n",
      "        except:\n",
      "            error_mess = 'An exception has occurred during embedding!'\n",
      "            if self.embedder_error_tolerance == 0.0:\n",
      "                raise ValueError(error_mess)\n",
      "            else:\n",
      "                print(error_mess)\n",
      "                return None\n",
      "        return embedding\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def _prepare_for_redis(self, data_dict, var_for_embedding_name):\n",
      "        for key, _ in data_dict.items():\n",
      "            embedding = self.embed(data_dict[key][var_for_embedding_name])\n",
      "            data_dict[key]['embedding'] = embedding\n",
      "        return data_dict\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def insert_values_dict(self, values_dict, var_for_embedding_name):\n",
      "        try:\n",
      "            values_dict = self._prepare_for_redis(data_dict=values_dict, var_for_embedding_name=var_for_embedding_name)\n",
      "            self.data.update(values_dict)\n",
      "            self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during inserting list of key-values dictionaries into mock database!', e)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def flush_database(self):\n",
      "        try:\n",
      "            self.data = {}\n",
      "            if self.persist:\n",
      "                self.save_data()\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during flushing mock database', e)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def filter_keys(self, subkey=None, subvalue=None):\n",
      "        if subkey is not None and subvalue is not None:\n",
      "            self.keys_list = [d for d in self.data if self.data[d][subkey] == subvalue]\n",
      "        else:\n",
      "            self.keys_list = self.data\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def filter_database(self, filter_criteria: dict=None):\n",
      "        self.filtered_data = {key: value for key, value in self.data.items() if all((value.get(k) == v for k, v in filter_criteria.items()))}\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def remove_from_database(self, filter_criteria: dict=None):\n",
      "        self.data = {key: value for key, value in self.data.items() if not all((value.get(k) == v for k, v in filter_criteria.items()))}\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def search_database_keys(self, query: str, search_results_n: int=None, similarity_search_type: str=None, similarity_params: dict=None):\n",
      "        try:\n",
      "            query_embedding = self.embed(query)\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during embedding search query!', e)\n",
      "        if search_results_n is None:\n",
      "            search_results_n = self.search_results_n\n",
      "        if similarity_search_type is None:\n",
      "            similarity_search_type = self.similarity_search_type\n",
      "        if similarity_params is None:\n",
      "            similarity_params = self.similarity_params\n",
      "        if self.filtered_data is None:\n",
      "            self.filtered_data = self.data\n",
      "        if self.keys_list is None:\n",
      "            self.keys_list = [key for key in self.filtered_data]\n",
      "        try:\n",
      "            data_embeddings = np.array([self.filtered_data[d]['embedding'] for d in self.keys_list])\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting search pool embeddings!', e)\n",
      "        try:\n",
      "            if similarity_search_type == 'linear':\n",
      "                labels, _ = self.linear_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            else:\n",
      "                labels, _ = self.hnsw_search(query_embedding, data_embeddings, k=search_results_n, **similarity_params)\n",
      "            self.results_keys = [self.keys_list[i] for i in labels]\n",
      "        except Exception as e:\n",
      "            self.logger.error('Problem during extracting results from the mock database!', e)\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def get_dict_results(self, return_keys_list: list=None) -> list:\n",
      "        if return_keys_list is None:\n",
      "            return_keys_list = self.return_keys_list\n",
      "        results = []\n",
      "        for searched_doc in self.results_keys:\n",
      "            result = {key: self.data[searched_doc].get(key) for key in return_keys_list}\n",
      "            results.append(result)\n",
      "        return results\n",
      "--------------------\n",
      "@attr.s\n",
      "class MockVecDbHandler:\n",
      "\n",
      "    def search_database(self, query: str, search_results_n: int=None, filter_criteria: dict=None, similarity_search_type: str=None, similarity_params: dict=None, return_keys_list: list=None) -> list:\n",
      "        if filter_criteria:\n",
      "            self.filter_database(filter_criteria=filter_criteria)\n",
      "        self.search_database_keys(query=query, search_results_n=search_results_n, similarity_search_type=similarity_search_type, similarity_params=similarity_params)\n",
      "        results = self.get_dict_results(return_keys_list=return_keys_list)\n",
      "        self.filtered_data = None\n",
      "        self.keys_list = None\n",
      "        return results\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "\n",
    "    print(split)\n",
    "    print(\"--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
