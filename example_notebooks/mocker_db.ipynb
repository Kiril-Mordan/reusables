{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocker DB\n",
    "\n",
    "This class is a mock handler for simulating a vector database, designed primarily for testing and development scenarios.\n",
    "It offers functionalities such as text embedding, hierarchical navigable small world (HNSW) search,\n",
    "and basic data management within a simulated environment resembling a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../')\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from mocker_db import MockerDB, SentenceTransformerEmbedder, MockerSimilaritySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage examples\n",
    "\n",
    "The examples contain:\n",
    "1. Inserting values into the database\n",
    "2. Seaching and retrieving values from the database\n",
    "3. Removing values from the database\n",
    "4. Testing the HNSW Search Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inseting values into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "handler = MockerDB(\n",
    "    # optional\n",
    "    embedder_params = {'model_name_or_path' : 'paraphrase-multilingual-mpnet-base-v2',\n",
    "                        'processing_type' : 'batch',\n",
    "                        'tbatch_size' : 500,\n",
    "                        'SentenceTransformer' : SentenceTransformer},\n",
    "    embedder = SentenceTransformerEmbedder,\n",
    "    ## optional/ for similarity search\n",
    "    similarity_search = MockerSimilaritySearch,\n",
    "    return_keys_list = None,\n",
    "    search_results_n = 3,\n",
    "    similarity_search_type = 'linear',\n",
    "    similarity_params = {'space':'cosine'},\n",
    "    ## optional/ inputs with defaults\n",
    "    file_path = \"./mock_persist\",\n",
    "    persist = True,\n",
    "    embedder_error_tolerance = 0.0\n",
    ")\n",
    "# Initialize empty database\n",
    "handler.establish_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the database 2\n"
     ]
    }
   ],
   "source": [
    "# Insert Data\n",
    "values_list = [\n",
    "    {\"text\": \"Sample text 1\",\n",
    "     \"text2\": \"Sample text 1\"},\n",
    "    {\"text\": \"Sample text 2\",\n",
    "     \"text2\": \"Sample text 2\"}\n",
    "]\n",
    "handler.insert_values(values_list, \"text\")\n",
    "print(f\"Items in the database {len(handler.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Seaching and retrieving values from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\",\n",
    "    }\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys with keywords search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    # when keyword key is provided filter is used to pass keywords\n",
    "    filter_criteria = {\n",
    "        \"text\" : [\"1\"],\n",
    "    },\n",
    "    keyword_check_keys = ['text'],\n",
    "    # percentage of filter keyword allowed to be different\n",
    "    keyword_check_cutoff = 1,\n",
    "    return_keys_list=['text']\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all key - text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\",\n",
    "    },\n",
    "    return_keys_list=[\"-text2\"])\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...', '&distance': '0.6744726...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"+&distance\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'&distance': '0.6744726...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"&distance\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys + embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...', 'embedding': '[-4.94665056e-02 -2.38676026e-...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"+embedding\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'embedding': '[-4.94665056e-02 -2.38676026e-...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"embedding\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get embeddings and embedded field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'&embedded_field': 'text...', 'embedding': '[-4.94665056e-02 -2.38676026e-...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"embedding\", \"+&embedded_field\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing values from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the database 2\n",
      "Items left in the database 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Items in the database {len(handler.data)}\")\n",
    "handler.remove_from_database(filter_criteria = {\"text\": \"Sample text 1\"})\n",
    "print(f\"Items left in the database {len(handler.data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing the HNSW Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mss = MockerSimilaritySearch(\n",
    "    # optional\n",
    "    search_results_n = 3,\n",
    "    similarity_params = {'space':'cosine'},\n",
    "    similarity_search_type ='linear'\n",
    ")\n",
    "\n",
    "ste = SentenceTransformerEmbedder(# optional / adaptor parameters\n",
    "                                  processing_type = '',\n",
    "                                  tbatch_size = 500,\n",
    "                                  max_workers = 2,\n",
    "                                  # sentence transformer parameters\n",
    "                                  model_name_or_path = 'paraphrase-multilingual-mpnet-base-v2',\n",
    "                                  SentenceTransformer = SentenceTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [1.1920929e-07]\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings = [ste.embed(\"example1\"), ste.embed(\"example2\")]\n",
    "\n",
    "\n",
    "# Assuming embeddings are pre-calculated and stored in 'embeddings'\n",
    "data_with_embeddings = {\"record1\": {\"embedding\": embeddings[0]}, \"record2\": {\"embedding\": embeddings[1]}}\n",
    "handler.data = data_with_embeddings\n",
    "\n",
    "# HNSW Search\n",
    "query_embedding = embeddings[0]  # Example query embedding\n",
    "labels, distances = mss.hnsw_search(query_embedding, np.array(embeddings), k=1)\n",
    "print(labels, distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
