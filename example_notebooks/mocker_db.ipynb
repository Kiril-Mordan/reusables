{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocker DB\n",
    "\n",
    "This class is a mock handler for simulating a vector database, designed primarily for testing and development scenarios.\n",
    "It offers functionalities such as text embedding, hierarchical navigable small world (HNSW) search,\n",
    "and basic data management within a simulated environment resembling a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyriosskia/miniconda3/envs/testenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('../')\n",
    "import numpy as np\n",
    "from mocker_db import MockerDB, SentenceTransformerEmbedder, MockerSimilaritySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage examples\n",
    "\n",
    "The examples contain:\n",
    "1. Basic data insertion and retrieval\n",
    "2. Text embedding and searching\n",
    "3. Advanced filtering and removal\n",
    "4. Testing the HNSW search algorithm\n",
    "5. Simulating database connection and persistence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Data Insertion and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the database 4\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "handler = MockerDB(\n",
    "    # optional\n",
    "    embedder_params = {'model_name_or_path' : 'paraphrase-multilingual-mpnet-base-v2',\n",
    "                        'processing_type' : 'batch',\n",
    "                        'tbatch_size' : 500},\n",
    "    embedder = SentenceTransformerEmbedder,\n",
    "    ## optional/ for similarity search\n",
    "    similarity_search_h = MockerSimilaritySearch,\n",
    "    return_keys_list = None,\n",
    "    search_results_n = 3,\n",
    "    similarity_search_type = 'linear',\n",
    "    similarity_params = {'space':'cosine'},\n",
    "    ## optional/ inputs with defaults\n",
    "    file_path = \"./mock_persist\",\n",
    "    persist = True,\n",
    "    embedder_error_tolerance = 0.0\n",
    ")\n",
    "# Initialize empty database\n",
    "handler.establish_connection()\n",
    "\n",
    "# Insert Data\n",
    "values_list = [\n",
    "    {\"text\": \"Sample text 1\",\n",
    "     \"text2\": \"Sample text 1\"},\n",
    "    {\"text\": \"Sample text 2\",\n",
    "     \"text2\": \"Sample text 2\"}\n",
    "]\n",
    "handler.insert_values(values_list, \"text\")\n",
    "print(f\"Items in the database {len(handler.data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Data Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1'}]\n",
      "[0.6744726]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Data\n",
    "handler.filter_keys(subkey=\"text\", subvalue=\"Sample text 1\")\n",
    "handler.search_database_keys(query='text')\n",
    "results = handler.get_dict_results(return_keys_list=[\"text\"])\n",
    "distances = handler.results_dictances\n",
    "print(results)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\",\n",
    "    },\n",
    "    return_keys_list=None\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys with keywords search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    # when keyword key is provided filter is used to pass keywords\n",
    "    filter_criteria = {\n",
    "        \"text\" : [\"1\"],\n",
    "    },\n",
    "    keyword_check_keys = ['text'],\n",
    "    # percentage of filter keyword allowed to be different\n",
    "    keyword_check_cutoff = 1,\n",
    "    return_keys_list=['text']\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all key - text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\",\n",
    "    },\n",
    "    return_keys_list=[\"-text2\"])\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...', '&distance': '0.6744726...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"+&distance\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'&distance': '0.6744726...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"&distance\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all keys + embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1...', 'text2': 'Sample text 1...', 'embedding': '[-4.94665056e-02 -2.38676026e-...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"+embedding\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'embedding': '[-4.94665056e-02 -2.38676026e-...'}]\n"
     ]
    }
   ],
   "source": [
    "results = handler.search_database(\n",
    "    query = \"text\",\n",
    "    filter_criteria = {\n",
    "        \"text\" : \"Sample text 1\"\n",
    "    },\n",
    "    return_keys_list=[\"embedding\"]\n",
    ")\n",
    "print([{k: str(v)[:30] + \"...\" for k, v in result.items()} for result in results])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Embedding and Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ste = SentenceTransformerEmbedder(# optional / adaptor parameters\n",
    "                                  processing_type = '',\n",
    "                                  tbatch_size = 500,\n",
    "                                  max_workers = 2,\n",
    "                                  # sentence transformer parameters\n",
    "                                  model_name_or_path = 'paraphrase-multilingual-mpnet-base-v2',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04973587  0.09520266 -0.01219509  0.09253872 -0.02301828 -0.0272102\n",
      "  0.05683957  0.09710974  0.10683873  0.05812286  0.13227554  0.01142828\n",
      " -0.06957257  0.06980742 -0.05259363 -0.05755996  0.00816178 -0.00836837\n",
      " -0.00861246  0.01442065  0.01188813 -0.09503674  0.07125735 -0.04827795\n",
      "  0.01473159  0.01084172 -0.10482483  0.0701253  -0.0472064   0.10030049\n",
      "  0.04455939  0.0213189   0.00667923 -0.0525919   0.06822997 -0.09520472\n",
      " -0.00581364 -0.02451883 -0.00384985  0.02750736  0.06960268  0.24013738\n",
      " -0.01220023  0.05890927 -0.08468661  0.11379698 -0.03594772 -0.05652961\n",
      " -0.01621804  0.09546741]\n"
     ]
    }
   ],
   "source": [
    "# Single Text Embedding\n",
    "query = \"Sample query\"\n",
    "embedded_query = ste.embed(query,\n",
    "                           # optional\n",
    "                           processing_type='')\n",
    "print(embedded_query[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04973588  0.09520268 -0.01219508  0.09253875 -0.02301828 -0.02721018\n",
      "  0.05683955  0.09710979  0.10683873  0.05812287  0.13227554  0.01142833\n",
      " -0.06957259  0.06980736 -0.05259363 -0.05755996  0.0081618  -0.00836839\n",
      " -0.00861242  0.01442068  0.01188811 -0.09503674  0.07125735 -0.04827797\n",
      "  0.01473157  0.01084175 -0.10482486  0.07012529 -0.04720639  0.10030051\n",
      "  0.04455936  0.02131891  0.00667919 -0.05259192  0.06822997 -0.09520471\n",
      " -0.00581361 -0.02451885 -0.00384985  0.02750732  0.06960279  0.24013741\n",
      " -0.0122002   0.05890926 -0.08468664  0.11379691 -0.03594773 -0.05652963\n",
      " -0.01621806  0.09546743]\n",
      "---\n",
      "[-0.05087035  0.12317687 -0.0139253   0.10524721 -0.07614311 -0.02349636\n",
      "  0.05829769  0.15128353  0.181198    0.03745941  0.12174654  0.00639845\n",
      " -0.04045051  0.12758298 -0.06155458 -0.0673613   0.04713941 -0.04134275\n",
      " -0.12165944  0.04409872  0.01834138 -0.04796622  0.04922184 -0.00641214\n",
      "  0.01420629 -0.03602948 -0.01026758  0.09232265 -0.04927171  0.0398545\n",
      "  0.03566905  0.08338926  0.04922605 -0.09951876  0.05138123 -0.13344647\n",
      "  0.01626777 -0.01189728  0.00599212  0.05663404  0.04282088  0.26432776\n",
      " -0.01122816  0.07177623 -0.11822147  0.08731955 -0.04965367  0.03697514\n",
      "  0.08965278  0.03107026]\n"
     ]
    }
   ],
   "source": [
    "# Batch Text Embedding\n",
    "queries = [\"Sample query\", \"Sample query 2\"]\n",
    "embedded_query = ste.embed(queries,\n",
    "                           # optional\n",
    "                           processing_type='batch')\n",
    "print(embedded_query[0][0:50])\n",
    "print(\"---\")\n",
    "print(embedded_query[1][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Sample text 1'}, {'text': 'Sample text 2'}, {'text': 'Sample text 2'}]\n"
     ]
    }
   ],
   "source": [
    "# Search Database\n",
    "search_results = handler.search_database(query, return_keys_list=[\"text\"])\n",
    "\n",
    "# Display Results\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Advanced Filtering and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data 1\n",
      "Items left in the database 3\n"
     ]
    }
   ],
   "source": [
    "# Advanced Filtering\n",
    "filter_criteria = {\"text\": \"Sample text 1\"}\n",
    "handler.filter_database(filter_criteria)\n",
    "filtered_data = handler.filtered_data\n",
    "print(f\"Filtered data {len(filtered_data)}\")\n",
    "\n",
    "# Data Removal\n",
    "handler.remove_from_database(filter_criteria)\n",
    "print(f\"Items left in the database {len(handler.data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing the HNSW Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mss = MockerSimilaritySearch(\n",
    "    # optional\n",
    "    search_results_n = 3,\n",
    "    similarity_params = {'space':'cosine'},\n",
    "    similarity_search_type ='linear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [1.1920929e-07]\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings = [ste.embed(\"example1\"), ste.embed(\"example2\")]\n",
    "\n",
    "\n",
    "# Assuming embeddings are pre-calculated and stored in 'embeddings'\n",
    "data_with_embeddings = {\"record1\": {\"embedding\": embeddings[0]}, \"record2\": {\"embedding\": embeddings[1]}}\n",
    "handler.data = data_with_embeddings\n",
    "\n",
    "# HNSW Search\n",
    "query_embedding = embeddings[0]  # Example query embedding\n",
    "labels, distances = mss.hnsw_search(query_embedding, np.array(embeddings), k=1)\n",
    "print(labels, distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Simulating Database Connection and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the database 3\n"
     ]
    }
   ],
   "source": [
    "# Establish Connection\n",
    "handler.establish_connection()\n",
    "\n",
    "# Change and Persist Data\n",
    "handler.insert_values([{\"text\": \"New sample text\"}], \"text\")\n",
    "handler.save_data()\n",
    "\n",
    "# Reload Data\n",
    "handler.establish_connection()\n",
    "print(f\"Items in the database {len(handler.data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
