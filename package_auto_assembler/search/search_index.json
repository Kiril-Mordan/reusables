{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro","text":"<p><code>package-auto-assembler</code> is a tool that meant to streamline creation of <code>single module packages</code>. Its primary goal is to automate as many aspects of python package creation as possible, thereby shortening the development cycle of reusable components and maintaining a high standard of quality for reusable code. </p> <p>With <code>package-auto-assembler</code>, you can simplify the package creation process to the point where it can be seamlessly triggered within CI/CD pipelines, requiring minimal setup and preparation for new modules.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Set up new Python packaging repositories for Github and Azure DevOps.</li> <li>Create new packages dynamically, reducing manual effort.</li> <li>Check module dependencies for vulnerabilities and unexpected licenses.</li> <li>Run FastAPI and Streamlit apps directly from packages created with this tool.</li> <li>Extract artifacts and files packaged alongside code.</li> <li>Show detailed information about installed packages made with the tool.</li> <li>Automatically assemble release notes based on commit messages.</li> <li>Extract requirements automatically from <code>.py</code> files without maintaining separate <code>requirements.txt</code>.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install package-auto-assembler\n</code></pre>"},{"location":"cli_tools/","title":"Cli tools","text":""},{"location":"cli_tools/#about","title":"About","text":"<p>One of available interfaces to use PAA capabalities is cli tools. After installing <code>package-auto-assembler</code> one can view the list of available cli tools like shown below.</p> <pre><code>paa --help\n</code></pre> <pre><code>Usage: paa [OPTIONS] COMMAND [ARGS]...\n\n  Package Auto Assembler CLI tool.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  check-licenses               Check licenses of the module.\n  check-vulnerabilities        Check vulnerabilities of the module.\n  convert-drawio-to-png        Converts drawio file to .png\n  extract-module-artifacts     Extracts artifacts from packaged module.\n  extract-module-requirements  Extract module requirements.\n  extract-module-routes        Extracts routes for fastapi from packages...\n  extract-module-site          Extracts static mkdocs site from packaged...\n  extract-module-streamlit     Extracts streamlit from packages that have...\n  extract-tracking-version     Get latest package version.\n  init-config                  Initialize config file\n  init-paa                     Initialize paa tracking files and...\n  init-ppr                     Initialize ppr for a given workflows...\n  make-package                 Package with package-auto-assembler.\n  refresh-module-artifacts     Refreshes module artifact from links.\n  run-api-routes               Run fastapi with provided routes.\n  run-pylint-tests             Run pylint tests for a given module, file,...\n  run-streamlit                Run streamlit application from the package.\n  show-module-artifacts        Shows module artifacts.\n  show-module-artifacts-links  Shows module artifact links.\n  show-module-info             Shows module info.\n  show-module-licenses         Shows module licenses.\n  show-module-list             Shows module list.\n  show-module-requirements     Shows module requirements.\n  show-ref-local-deps          Shows paths to local dependencies...\n  test-install                 Test install module into local environment.\n  update-release-notes         Update release notes.\n</code></pre> <p>Available cli tools usually employ multiple internal components and range from relatively simple ones to more complex. </p> <p></p>"},{"location":"cli_tools/#description-of-tools","title":"Description of tools","text":""},{"location":"cli_tools/#initializing-paa","title":"Initializing PAA","text":"<p>Creating config file could be useful to avoid providing parameters manually. If no config file will be provided, by default values from <code>.paa.config</code> will be used.</p> <pre><code>paa init-config  --help\n</code></pre> <pre><code>Usage: paa init-config [OPTIONS]\n\n  Initialize config file\n\nOptions:\n  --full  If checked, dirs beyond essential would be mapped.\n  --help  Show this message and exit.\n</code></pre> <p>Packaging repository needs a place to keep some tracking files. Running it first time also initializes <code>.paa.config</code> and the second time will create directories specified there, if not already created.  </p> <pre><code>paa init-paa  --help\n</code></pre> <pre><code>Usage: paa init-paa [OPTIONS]\n\n  Initialize paa tracking files and directores from .paa.config\n\nOptions:\n  --full  If checked, dirs beyond essential would be mapped.\n  --help  Show this message and exit.\n</code></pre> <p>The package provides some templates for packaging repositories. Packaging repository after some additional preparations should allow to create and publish new packages with a use of ci/cd pipeline. </p> <pre><code>paa init-ppr --help\n</code></pre> <pre><code>Usage: paa init-ppr [OPTIONS]\n\n  Initialize ppr for a given workflows platform.\n\nOptions:\n  --github  If checked, git actions template would be set up.\n  --azure   If checked, azure devops pipelines template would be set up.\n  --full    If checked, dirs beyond essential would be mapped.\n  --help    Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#creating-packages","title":"Creating packages","text":"<p>Installing packages for a test in local environments could be a useful step to make sure everything works as expected before pushing changes to publishing repo. This creates an instance of the package in local environment with default version, with a greatly simplified building process that avoids making documentation, versioning and so on.</p> <pre><code>paa test-install [OPTIONS] MODULE_NAME\n</code></pre> <pre><code>Usage: paa test-install [OPTIONS] MODULE_NAME\n\n  Test install module into local environment.\n\nOptions:\n  --config TEXT                   Path to config file for paa.\n  --module-filepath TEXT          Path to .py file to be packaged.\n  --mapping-filepath TEXT         Path to .json file that maps import to\n                                  install dependecy names.\n  --cli-module-filepath TEXT      Path to .py file that contains cli logic.\n  --fastapi-routes-filepath TEXT  Path to .py file that routes for fastapi.\n  --dependencies-dir TEXT         Path to directory with local dependencies of\n                                  the module.\n  --default-version TEXT          Default version.\n  --check-vulnerabilities         If checked, checks module dependencies with\n                                  pip-audit for vulnerabilities.\n  --build-mkdocs                  If checked, builds mkdocs documentation.\n  --check-licenses                If checked, checks module dependencies\n                                  licenses.\n  --keep-temp-files               If checked, setup directory won't be removed\n                                  after setup is done.\n  --skip-deps-install             If checked, existing dependencies from env\n                                  will be reused.\n  --help                          Show this message and exit.\n</code></pre> <p>Making package based on provided parameters can be useful in ci/cd pipelines to streamline creation of packages before publishing from something that could be as simple as <code>.py</code> file.</p> <pre><code>paa make-package --help\n</code></pre> <pre><code>Usage: paa make-package [OPTIONS] MODULE_NAME\n\n  Package with package-auto-assembler.\n\nOptions:\n  --config TEXT                   Path to config file for paa.\n  --module-filepath TEXT          Path to .py file to be packaged.\n  --mapping-filepath TEXT         Path to .json file that maps import to\n                                  install dependecy names.\n  --cli-module-filepath TEXT      Path to .py file that contains cli logic.\n  --dependencies-dir TEXT         Path to directory with local dependencies of\n                                  the module.\n  --kernel-name TEXT              Kernel name.\n  --python-version TEXT           Python version.\n  --default-version TEXT          Default version.\n  --ignore-vulnerabilities-check  If checked, does not check module\n                                  dependencies with pip-audit for\n                                  vulnerabilities.\n  --example-notebook-path TEXT    Path to .ipynb file to be used as README.\n  --execute-notebook              If checked, executes notebook before turning\n                                  into README.\n  --log-filepath TEXT             Path to logfile to record version change.\n  --versions-filepath TEXT        Path to file where latest versions of the\n                                  packages are recorded.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#checking-dependencies","title":"Checking dependencies","text":"<p>Checking vulnerabilities with <code>pip-audit</code> is usefull. This checks vulnerabilities of .py files and its local dependencies with <code>pip-audit</code>.</p> <pre><code>paa check-vulnerabilities --help\n</code></pre> <pre><code>Usage: paa check-vulnerabilities [OPTIONS] MODULE_NAME\n\n  Check vulnerabilities of the module.\n\nOptions:\n  --config TEXT               Path to config file for paa.\n  --module-filepath TEXT      Path to .py file to be packaged.\n  --mapping-filepath TEXT     Path to .json file that maps import to install\n                              dependecy names.\n  --cli-module-filepath TEXT  Path to .py file that contains cli logic.\n  --dependencies-dir TEXT     Path to directory with local dependencies of the\n                              module.\n  --help                      Show this message and exit.\n</code></pre> <p>Checking license labels of module dependencies tree could be useful to prevent using some dependencies early on.</p> <pre><code>Usage: paa check-licenses [OPTIONS] MODULE_NAME\n\n  Check licenses of the module.\n\nOptions:\n  --config TEXT                   Path to config file for paa.\n  --module-filepath TEXT          Path to .py file to be packaged.\n  --mapping-filepath TEXT         Path to .json file that maps import to\n                                  install dependecy names.\n  --license-mapping-filepath TEXT\n                                  Path to .json file that maps license labels\n                                  to install dependecy names.\n  --cli-module-filepath TEXT      Path to .py file that contains cli logic.\n  --dependencies-dir TEXT         Path to directory with local dependencies of\n                                  the module.\n  --skip-normalize-labels         If checked, package license labels are not\n                                  normalized.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#running-apps-from-packages","title":"Running apps from packages","text":"<p>Packaging process could help building APIs as well. This package would call routes stored within other packages and routes stored in files to form one application, so that repeatable structure does not need to copied between projects, but instead built in one places and extended with some config files in many. Since routes are python code that can have its dependencies, it makes sense to store them within packages sometimes to take advantage of automated dependency handling and import code straight from the package, eliminating in turn situation when package release in no compatible anymore with routes based on them. </p> <p>Parameters for fastapi app description, middleware and run could be supplied via optional <code>.paa.api.config</code> file, with <code>DESCRIPTION</code> , <code>MIDDLEWARE</code> and <code>RUN</code> dictionary of parameters respectively. </p> <p>It could be beneficial to add a static page with documentation, so additional pages could be addded. First one would be accessible via <code>\\mkdocs</code> and the following ones via <code>\\mkdocs {i+1}</code>. Static package within package, that were packages by <code>package-auto-assemble&gt;0.5.1</code> would be accessible via <code>\\{package_name}\\docs</code> if available.</p> <pre><code>paa run-api-routes --help\n</code></pre> <pre><code>Usage: paa run-api-routes [OPTIONS]\n\n  Run fastapi with provided routes.\n\nOptions:\n  --api-config TEXT  Path to yml config file with app description, middleware\n                     parameters, run parameters, `.paa.api.config` is used by\n                     default.\n  --host TEXT        The host to bind to.\n  --port TEXT        The port to bind to.\n  --package TEXT     Package names from which routes will be added to the app.\n  --route TEXT       Paths to routes which will be added to the app.\n  --docs TEXT        Paths to static docs site which will be added to the app.\n  --help             Show this message and exit.\n</code></pre> <p>One of the convinient ways to access packaged code could be a streamlit application. This package allows for streamlit application to be stored within a package and then run with the following. Parameters that would be passed to <code>~/.streamlit/config.toml</code> can be provided via optional <code>.paa.streamlit.config</code> file, at which point it would copied to default location. The command can be used to run streamlit apps from a selected package, built with the tool, or from normal <code>.py</code> file with streamlit app.</p> <pre><code>paa run-streamlit --help\n</code></pre> <pre><code>Usage: paa run-streamlit [OPTIONS]\n\n  Run streamlit application from the package.\n\nOptions:\n  --app-config TEXT  Path to yml config for streamlit app.\n  --host TEXT        The host to bind to.\n  --port TEXT        The port to bind to.\n  --package TEXT     Package name from which streamlit app should be run.\n  --path TEXT        Path to streamlit app.\n  --help             Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#extracting-files-from-packages","title":"Extracting files from packages","text":"<p>Storing routes within package could be convinient, but extracting them from a package is not. To mitigate that, the following exists to extract <code>routes.py</code> from a package that contains it.</p> <pre><code>paa extract-module-routes --help\n</code></pre> <pre><code>Usage: paa extract-module-routes [OPTIONS] PACKAGE_NAME\n\n  Extracts routes for fastapi from packages that have them into a file.\n\nOptions:\n  --output-dir TEXT   Directory where routes extracted from the package will\n                      be copied to.\n  --output-path TEXT  Filepath to which routes extracted from the package will\n                      be copied to.\n  --help              Show this message and exit.\n</code></pre> <pre><code>paa extract-module-site --help\n</code></pre> <pre><code>Usage: paa extract-module-site [OPTIONS] PACKAGE_NAME\n\n  Extracts static mkdocs site from packaged module.\n\nOptions:\n  --output-dir TEXT   Directory where routes extracted from the package will\n                      be copied to.\n  --output-path TEXT  Filepath to which routes extracted from the package will\n                      be copied to.\n  --help              Show this message and exit.\n</code></pre> <p>Another option to access the artifacts is to copy them to a selected directory.</p> <pre><code>paa extract-module-artifacts --help\n</code></pre> <pre><code>Usage: paa extract-module-artifacts [OPTIONS] PACKAGE_NAME\n\n  Extracts artifacts from packaged module.\n\nOptions:\n  --artifact TEXT     Name of the artifact to be extracted.\n  --output-dir TEXT   Directory where artifacts extracted from the package\n                      will be copied to.\n  --output-path TEXT  Filepath to which artifact extracted from the package\n                      will be copied to.\n  --help              Show this message and exit.\n</code></pre> <p>Another option to access the packaged streamlit app is to copy it to a selected directory.</p> <pre><code>paa extract-module-streamlit --help\n</code></pre> <pre><code>Usage: paa extract-module-streamlit [OPTIONS] PACKAGE_NAME\n\n  Extracts streamlit from packages that have them into a file.\n\nOptions:\n  --output-dir TEXT   Directory where streamplit extracted from the package\n                      will be copied to.\n  --output-path TEXT  Filepath to which streamlit extracted from the package\n                      will be copied to.\n  --help              Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#show-modules-info","title":"Show modules info","text":"<p>Cli interface provides some additional tools to analyse locally installed packages if they were build with package-auto-assembler&gt;0.4.2. These include methods to list modules, show module info, extract requirements.</p> <pre><code>paa show-module-list --help\n</code></pre> <pre><code>Usage: paa show-module-list [OPTIONS]\n\n  Shows module list.\n\nOptions:\n  --tags TEXT  Keyword tag filters for the package.\n  --help       Show this message and exit.\n</code></pre> <pre><code>paa show-module-info --help\n</code></pre> <pre><code>Usage: paa show-module-info [OPTIONS] LABEL_NAME\n\n  Shows module info.\n\nOptions:\n  --keywords      If checked, returns keywords for the package.\n  --classifiers   If checked, returns classfiers for the package.\n  --docstring     If checked, returns docstring of the package.\n  --author        If checked, returns author of the package.\n  --author-email  If checked, returns author email of the package.\n  --version       If checked, returns installed version of the package.\n  --pip-version   If checked, returns pip latest version of the package.\n  --help          Show this message and exit.\n</code></pre> <pre><code>paa show-module-requirements --help\n</code></pre> <pre><code>Usage: paa show-module-requirements [OPTIONS] LABEL_NAME\n\n  Shows module requirements.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <pre><code>paa show-module-licenses --help\n</code></pre> <pre><code>Usage: paa show-module-licenses [OPTIONS] PACKAGE_NAME\n\n  Shows module licenses.\n\nOptions:\n  --normalize-labels  If checked, package license labels are normalized.\n  --help              Show this message and exit.\n</code></pre> <p>There is an option to package artifacts with the code. Packaged artifacts can be listed. </p> <pre><code>paa show-module-artifacts --help\n</code></pre> <pre><code>Usage: paa show-module-artifacts [OPTIONS] LABEL_NAME\n\n  Shows module artifacts.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>It might be useful to inspect which artifacts come from links, whether these links are available and refresh these artifacts within installed package.</p> <pre><code>paa show-module-artifacts-links --help\n</code></pre> <pre><code>Usage: paa show-module-artifacts-links [OPTIONS] LABEL_NAME\n\n  Shows module artifact links.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>A module can referance multiple other local dependencies. The following is meant to extract all of paths relates to the module within PPR.</p> <pre><code>paa show-ref-local-deps --help\n</code></pre> <pre><code>Usage: paa show-ref-local-deps [OPTIONS] LABEL_NAME\n\n  Shows paths to local dependencies referenced in the module.\n\nOptions:\n  --config TEXT            Path to config file for paa.\n  --module-dir TEXT        Path to folder with .py file to be packaged.\n  --dependencies-dir TEXT  Path to directory with local dependencies of\n                           the module.\n  --help                   Show this message and exit.\n</code></pre>"},{"location":"cli_tools/#other","title":"Other","text":"<p>Some artifacts can come from links and there might be a need to refresh or even download these files (depending on how a link was provided). </p> <pre><code>paa refresh-module-artifacts --help\n</code></pre> <pre><code>Usage: paa refresh-module-artifacts [OPTIONS] LABEL_NAME\n\n  Refreshes module artifact from links.\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>Core of paa automation is the ability to extract requirements from <code>.py</code> files. The tool shown below is a part of requirements extraction pipeline, designed to run within PPR, but could also work outside, if imports are handled in a specific way (more in description).</p> <pre><code>paa extract-module-requirements --help\n</code></pre> <pre><code>Usage: paa extract-module-requirements [OPTIONS] MODULE_NAME\n\n  Extract module requirements.\n\nOptions:\n  --config TEXT                   Path to config file for paa.\n  --module-dir TEXT               Path to folder where module is stored.\n  --mapping-filepath TEXT         Path to .json file that maps import to\n                                  install dependecy names.\n  --cli-module-filepath TEXT      Path to .py file that contains cli logic.\n  --routes-module-filepath TEXT   Path to .py file that contains fastapi\n                                  routes.\n  --streamlit-module-filepath TEXT\n                                  Path to .py file that contains streamlit\n                                  app.\n  --dependencies-dir TEXT         Path to directory with local dependencies of\n                                  the module.\n  --show-extra                    If checked, list will show which\n                                  requirements are extra.\n  --skip-extra                    If checked, list will not include extra.\n  --help                          Show this message and exit.\n</code></pre> <p>Maintaining release notes could be very useful, but also tedious task.  Since commit messages are rather standard practice, by taking advantage of them and constructing release notes based on them, each release could contain notes with appropriate version automatically, when itegrated into ci/cd pipeline, given that commit messages are written in a specific way. </p> <pre><code>paa update-release-notes --help\n</code></pre> <pre><code>Usage: paa update-release-notes [OPTIONS] LABEL_NAME\n\n  Update release notes.\n\nOptions:\n  --version TEXT           Version of new release.\n  --notes TEXT             Optional manually provided notes string, where each\n                           note is separated by ; and increment type is\n                           provide in accordance to paa documentation.\n  --notes-filepath TEXT    Path to .md wit release notes.\n  --max-search-depth TEXT  Max search depth in commit history.\n  --use-pip-latest         If checked, attempts to pull latest version from\n                           pip.\n  --help                   Show this message and exit.\n</code></pre> <p>Running pylint tests is useful and usually done in pull request to PPR. It could also be run locally for all the modules or select modules and their local dependencies to identify modules that need improvements to pass preset threshold. </p> <pre><code>paa run-pylint-tests --help\n</code></pre> <pre><code>Usage: paa run-pylint-tests [OPTIONS] [FILES]...\n\n  Run pylint tests for a given module, file, files or files in a directory.\n\nOptions:\n  --config TEXT      Path to config file for paa.\n  --label-name TEXT  Label name.\n  --module-dir TEXT  Path to a directory where .py files are stored.\n  --threshold TEXT   Pylint threshold.\n  --help             Show this message and exit.\n</code></pre> <p>It might be useful to know what is the last version a given module that was published from the PPR, mostly within ci/cd workflows.</p> <pre><code>paa extract-tracking-version --help\n</code></pre> <pre><code>Usage: paa extract-tracking-version [OPTIONS] MODULE_NAME\n\n  Get latest package version.\n\nOptions:\n  --config TEXT  Path to config file for paa.\n  --help         Show this message and exit.\n</code></pre> <p>Some pieces of documentation within PPR may come from drawio files. One of the steps in packaging process is to convert <code>.drawio</code> file for a package into <code>.png</code> files.  For this functionality to work, first some dependencies would need to be installed.</p> <pre><code>sudo apt-get update\nsudo apt-get install -y wget xvfb libnotify4 libxml2-utils\nwget https://github.com/jgraph/drawio-desktop/releases/download/v24.6.4/drawio-amd64-24.6.4.deb\nsudo dpkg -i drawio-amd64-24.6.4.deb\nsudo apt-get install -f\n</code></pre> <pre><code>paa convert-drawio-to-png --help\n</code></pre> <pre><code>Usage: paa convert-drawio-to-png [OPTIONS]\n\n  Converts drawio file to .png\n\nOptions:\n  --config TEXT      Path to config file for paa.\n  --label-name TEXT  Label name.\n  --drawio-dir TEXT  Path to a directory where drawio files are stored.\n  --docs-dir TEXT    Path to the output directory for .png file.\n  --help             Show this message and exit.\n</code></pre>"},{"location":"description/","title":"Description","text":"<p>The following includes additional details to how some features of the packages work with examples that involve internal components. Even though using the package this way is very much possible, cli interface is recomended. </p> <pre><code>from package_auto_assembler import (VersionHandler, \\\n    ImportMappingHandler, RequirementsHandler, MetadataHandler, \\\n        LocalDependaciesHandler, LongDocHandler, SetupDirHandler, \\\n            ReleaseNotesHandler, MkDocsHandler, PackageAutoAssembler, \\\n                DependenciesAnalyser)\n</code></pre>"},{"location":"description/#1-package-versioning","title":"1. Package versioning","text":"<p>Package versioning within paa is done based on semantic versioning.</p> <p><code>major.minor.patch</code></p> <p>By default, patch is updated, but the minor and major could also be update based on, for example, commit messages or manually from the log file. </p> <p>Package auto assembler does try to pull latest version from package storage, but in case of failure uses version logs stored in <code>.paa/tracking</code>.</p>"},{"location":"description/#initialize-versionhandler","title":"Initialize VersionHandler","text":"<pre><code>pv = VersionHandler(\n    # required\n    versions_filepath = '../tests/package_auto_assembler/other/lsts_package_versions.yml',\n    log_filepath = '../tests/package_auto_assembler/other/version_logs.csv',\n    # optional\n    default_version = \"0.0.1\")\n</code></pre>"},{"location":"description/#add-new-package","title":"Add new package","text":"<pre><code>pv.add_package(\n    package_name = \"new_package\",\n    # optional\n    version = \"0.0.1\"\n)\n</code></pre>"},{"location":"description/#update-package-version","title":"Update package version","text":"<pre><code>pv.increment_patch(\n    package_name = \"new_package\"\n)\n## for not tracked package\npv.increment_patch(\n    package_name = \"another_new_package\",\n    # optional\n    default_version = \"0.0.1\"\n)\n</code></pre> <pre><code>There are no known versions of 'another_new_package', 0.0.1 will be used!\n</code></pre>"},{"location":"description/#display-current-versions-and-logs","title":"Display current versions and logs","text":"<pre><code>pv.get_versions(\n    # optional\n    versions_filepath = '../tests/package_auto_assembler/other/lsts_package_versions.yml'\n)\n</code></pre> <pre><code>{'another_new_package': '0.0.1', 'new_package': '0.0.2'}\n</code></pre> <pre><code>pv.get_version(\n    package_name='new_package'\n)\n</code></pre> <pre><code>'0.0.2'\n</code></pre> <pre><code>pv.get_logs(\n    # optional\n    log_filepath = '../tests/package_auto_assembler/other/version_logs.csv'\n)\n</code></pre> Timestamp Package Version 0 2024-07-29 03:26:39 new_package 0.0.1 1 2024-07-29 03:26:40 new_package 0.0.2 2 2024-07-29 03:26:40 another_new_package 0.0.1"},{"location":"description/#flush-versions-and-logs","title":"Flush versions and logs","text":"<pre><code>pv.flush_versions()\npv.flush_logs()\n</code></pre>"},{"location":"description/#get-latest-available-version-with-pip","title":"Get latest available version with pip","text":"<pre><code>pv.get_latest_pip_version(package_name = 'package-auto-assembler')\n</code></pre> <pre><code>'0.3.1'\n</code></pre>"},{"location":"description/#2-import-mapping","title":"2. Import mapping","text":"<p>Install and import names of dependencies may vary. The mapping files maps import names to install names so that requirements extraction from <code>.py</code> files is possible. Some of the mapping are packaged and would not need to provided, but in case a dependency used within new package was not inluded, it is possible to augment default mapping through <code>.paa/package_mapping.json</code></p>"},{"location":"description/#initialize-importmappinghandler","title":"Initialize ImportMappingHandler","text":"<pre><code>im = ImportMappingHandler(\n    # required\n    mapping_filepath = \"../env_spec/package_mapping.json\"\n)\n</code></pre>"},{"location":"description/#load-package-mappings","title":"Load package mappings","text":"<pre><code>im.load_package_mappings(\n    # optional\n    mapping_filepath = \"../env_spec/package_mapping.json\"\n)\n</code></pre> <pre><code>{'PIL': 'Pillow',\n 'bs4': 'beautifulsoup4',\n 'fitz': 'PyMuPDF',\n 'attr': 'attrs',\n 'dotenv': 'python-dotenv',\n 'googleapiclient': 'google-api-python-client',\n 'google_auth_oauthlib': 'google-auth-oauthlib',\n 'sentence_transformers': 'sentence-transformers',\n 'flask': 'Flask',\n 'stdlib_list': 'stdlib-list',\n 'sklearn': 'scikit-learn',\n 'yaml': 'pyyaml',\n 'package_auto_assembler': 'package-auto-assembler',\n 'git': 'gitpython'}\n</code></pre>"},{"location":"description/#3-extracting-and-merging-requirements","title":"3. Extracting and merging requirements","text":"<p>Maintaining requirements is much simpler, when done automatically based on the <code>.py</code> files. </p> <p>The actual requirements files is still constructed. Standard libraries are not added, others are added with their versions, if specified. Local files are also used as dependencies, from which imports are extracted as well. </p> <p>For example:</p> <pre><code>import os\nimport pandas\nimport attr #&gt;=22.2.0\nfrom .components.local_dep import *\n</code></pre> <p>produces </p> <pre><code>pandas\nattrs &gt;=22.2.0\nyaml\n</code></pre> <p>as requirements file, where <code>yaml</code> is extracted from <code>local_dep.py</code> file.</p> <p>Checking dependecies for vulnerabilities is usefull and it is done with <code>pip audit</code> which is integrated into the paa package and is used by default.</p> <p>Optional requirements for <code>extras_require</code> could be probided the same way normal requirements are, but each like that contains an import like that should be commented out in a special way, starting with <code>#!</code>, for example:</p> <pre><code>import os\nimport pandas\nimport attr #&gt;=22.2.0\n#! import hnswlib #==0.8.0\n</code></pre> <p>produces</p> <pre><code>pandas\nattrs &gt;=22.2.0\nhnswlib==0.8.0; extra == \"hnswlib\"\n</code></pre> <p>Sometimes automatic translation of import names to install names via <code>package_mapping.json</code>, for packages where these names differ, may not be enough. A manual overwrite can be done with exlusion of some dependencies from automatic extraction pipeline with <code>#-</code> comment next to import and <code>#@</code> prefix before text that is intended to end up in an equivalent requirements file, for example:</p> <pre><code>import os\nimport pandas\nimport attr #&gt;=22.2.0\nimport tensorflow #-\n#@ tensorflow-gpu\n</code></pre> <p>produces</p> <pre><code>pandas\nattrs &gt;=22.2.0\ntensorflow-gpu\n</code></pre>"},{"location":"description/#initialize-requirementshandler","title":"Initialize RequirementsHandler","text":"<pre><code>rh = RequirementsHandler(\n    # optional/required later\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    package_mappings = {'PIL': 'Pillow',\n                        'bs4': 'beautifulsoup4',\n                        'fitz': 'PyMuPDF',\n                        'attr': 'attrs',\n                        'dotenv': 'python-dotenv',\n                        'googleapiclient': 'google-api-python-client',\n                        'sentence_transformers': 'sentence-transformers',\n                        'flask': 'Flask',\n                        'stdlib_list': 'stdlib-list',\n                        'sklearn': 'scikit-learn',\n                        'yaml': 'pyyaml'},\n    requirements_output_path = \"../tests/package_auto_assembler/other/\",\n    output_requirements_prefix = \"requirements_\",\n    custom_modules_filepath = \"../tests/package_auto_assembler/dependancies\",\n    python_version = '3.8',\n    add_header = True\n)\n</code></pre>"},{"location":"description/#list-custom-modules-for-a-given-directory","title":"List custom modules for a given directory","text":"<pre><code>rh.list_custom_modules(\n    # optional\n    custom_modules_filepath=\"../tests/package_auto_assembler/dependancies\"\n)\n</code></pre> <pre><code>['example_local_dependacy_1', 'example_local_dependacy_2']\n</code></pre>"},{"location":"description/#check-if-module-is-a-standard-python-library","title":"Check if module is a standard python library","text":"<pre><code>rh.is_standard_library(\n    # required\n    module_name = 'example_local_dependacy_1',\n    # optional\n    python_version = '3.8'\n)\n</code></pre> <pre><code>False\n</code></pre> <pre><code>rh.is_standard_library(\n    # required\n    module_name = 'logging',\n    # optional\n    python_version = '3.8'\n)\n</code></pre> <pre><code>True\n</code></pre>"},{"location":"description/#extract-requirements-from-the-module-file","title":"Extract requirements from the module file","text":"<pre><code>rh.extract_requirements(\n    # optional\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    custom_modules = ['example_local_dependacy_2', 'example_local_dependacy_1'],\n    package_mappings = {'PIL': 'Pillow',\n                        'bs4': 'beautifulsoup4',\n                        'fitz': 'PyMuPDF',\n                        'attr': 'attrs',\n                        'dotenv': 'python-dotenv',\n                        'googleapiclient': 'google-api-python-client',\n                        'sentence_transformers': 'sentence-transformers',\n                        'flask': 'Flask',\n                        'stdlib_list': 'stdlib-list',\n                        'sklearn': 'scikit-learn',\n                        'yaml': 'pyyaml'},\n    python_version = '3.8',\n    add_header=True\n)\n</code></pre> <pre><code>(['attrs&gt;=22.2.0'],\n ['torch&lt;=2.4.1', 'fastapi[all]', 'scikit-learn==1.5.1', 'numpy'])\n</code></pre> <pre><code>rh.requirements_list\n</code></pre> <pre><code>['attrs&gt;=22.2.0']\n</code></pre> <pre><code>rh.optional_requirements_list\n</code></pre> <pre><code>['torch&lt;=2.4.1', 'fastapi[all]', 'scikit-learn==1.5.1', 'numpy']\n</code></pre>"},{"location":"description/#audit-dependencies","title":"Audit dependencies","text":"<pre><code>rh.check_vulnerabilities(\n    # optional if ran extract_requirements() before\n    requirements_list = None,\n    raise_error = True\n)\n</code></pre> <pre><code>No known vulnerabilities found\n</code></pre> <pre><code>rh.vulnerabilities\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>try:\n    rh.check_vulnerabilities(\n        # optional if ran extract_requirements() before\n        requirements_list = ['attrs&gt;=22.2.0', 'pandas', 'hnswlib==0.7.0'],\n        raise_error = True\n    )\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre> <pre><code>Found 1 known vulnerability in 1 package\n\n\n\nName    Version ID                  Fix Versions\n------- ------- ------------------- ------------\nhnswlib 0.7.0   GHSA-xwc8-rf6m-xr86\n\nError: Found vulnerabilities, resolve them or ignore check to move forwards!\n</code></pre> <pre><code>rh.vulnerabilities\n</code></pre> <pre><code>[{'name': 'hnswlib',\n  'version': '0.7.0',\n  'id': 'GHSA-xwc8-rf6m-xr86',\n  'fix_versions': None}]\n</code></pre>"},{"location":"description/#save-requirements-to-a-file","title":"Save requirements to a file","text":"<pre><code>rh.write_requirements_file(\n    # optional/required later\n    module_name = 'example_module',\n    requirements = ['### example_module.py', 'attrs&gt;=22.2.0'],\n    output_path = \"../tests/package_auto_assembler/other/\",\n    prefix = \"requirements_\"\n)\n</code></pre>"},{"location":"description/#read-requirements","title":"Read requirements","text":"<pre><code>rh.read_requirements_file(\n    # required\n    requirements_filepath = \"../tests/package_auto_assembler/other/requirements_example_module.txt\"\n)\n</code></pre> <pre><code>['attrs&gt;=22.2.0']\n</code></pre>"},{"location":"description/#4-preparing-metadata","title":"4. Preparing metadata","text":"<p>Since all of the necessary information for building a package needs to be contained within main component <code>.py</code> file, basic metadata is provided with the use of <code>__package_metadata__</code> dictionary object, defined within that <code>.py</code> file. It is also used as a trigger for package building within paa pipeline. </p> <p>Even though some general information shared between packages could be provided through general config, but package specific info should be provided through <code>__package_metadata__</code>. It should support most text fields from setup file, but for others the following fields are available:</p> <ul> <li><code>classifiers</code>: adds classifiers to the general ones from config, unless it's <code>Development Status ::</code> then module level definition will overwrite the one from config</li> <li><code>extras_require</code>: a dictionary of optional package that wouldn't be installed during normal installation. The key could be used during installation and the value would be a list of dependencies.</li> <li><code>install_requires</code> : adds requirements to the list read from imports</li> </ul> <p>* Note that providing dependencies this way does not check them through pip-audit or translate them through package mapping</p>"},{"location":"description/#initializing-metadatahandler","title":"Initializing MetadataHandler","text":"<pre><code>mh = MetadataHandler(\n    # optional/required later\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\"\n)\n</code></pre>"},{"location":"description/#check-if-metadata-is-available","title":"Check if metadata is available","text":"<pre><code>mh.is_metadata_available(\n    # optional\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\"\n)\n</code></pre> <pre><code>True\n</code></pre>"},{"location":"description/#extract-metadata-from-module","title":"Extract metadata from module","text":"<pre><code>mh.get_package_metadata(\n    # optional\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\"\n)\n</code></pre> <pre><code>{'author': 'Kyrylo Mordan',\n 'author_email': 'parachute.repo@gmail.com',\n 'version': '0.0.1',\n 'description': 'A mock handler for simulating a vector database.',\n 'keywords': ['python', 'vector database', 'similarity search']}\n</code></pre>"},{"location":"description/#5-merging-local-dependacies-into-single-module","title":"5. Merging local dependacies into single module","text":"<p>Package auto assembler creates <code>single module packages</code>, meaning that once package is built all of the object are imported from a single place. The packaging tool does allow for <code>local dependecies</code> which are <code>.py</code> files imported from specified dependencies directory and its subfolders. Packaging structure may look like the following:</p> <pre><code>packaging repo/\n\u2514src/\n  \u251c &lt;package names&gt;.py\n  \u2514 components\n    \u251clocal_dependecy.py\n    \u2514subdir_1\n      \u2514local_dependency_2.py \n</code></pre> <p>During packaging process paa merges main module with its local dependies into a single file.</p>"},{"location":"description/#initializing-localdependacieshandler","title":"Initializing LocalDependaciesHandler","text":"<pre><code>ldh = LocalDependaciesHandler(\n    # required\n    main_module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    dependencies_dir = \"../tests/package_auto_assembler/dependancies/\",\n    # optional\n    save_filepath = \"./combined_example_module.py\"\n)\n</code></pre>"},{"location":"description/#combine-main-module-with-dependacies","title":"Combine main module with dependacies","text":"<pre><code>print(ldh.combine_modules(\n    # optional\n    main_module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    dependencies_dir = \"../tests/package_auto_assembler/dependancies/\",\n    add_empty_design_choices = False\n)[0:1000])\n</code></pre> <pre><code>\"\"\"\nMock Vector Db Handler\n\nThis class is a mock handler for simulating a vector database, designed primarily for testing and development scenarios.\nIt offers functionalities such as text embedding, hierarchical navigable small world (HNSW) search,\nand basic data management within a simulated environment resembling a vector database.\n\"\"\"\n\nimport logging\nimport json\nimport time\nimport attr #&gt;=22.2.0\nimport sklearn\n\n__design_choices__ = {}\n\n@attr.s\nclass Shouter:\n\n    \"\"\"\n    A class for managing and displaying formatted log messages.\n\n    This class uses the logging module to create and manage a logger\n    for displaying formatted messages. It provides a method to output\n    various types of lines and headers, with customizable message and\n    line lengths.\n    \"\"\"\n\n    # Formatting settings\n    dotline_length = attr.ib(default=50)\n\n    # Logger settings\n    logger = attr.ib(default=None)\n    logger_name = attr.ib(default='Shouter')\n    loggerLvl = attr.ib(default=logging.DEBUG)\n    log\n</code></pre> <pre><code>ldh.dependencies_names_list\n</code></pre> <pre><code>['example_local_dependacy_2', 'example_local_dependacy_1', 'dep_from_bundle_1']\n</code></pre>"},{"location":"description/#save-combined-module","title":"Save combined module","text":"<pre><code>ldh.save_combined_modules(\n    # optional\n    combined_module = ldh.combine_modules(),\n    save_filepath = \"./combined_example_module.py\"\n)\n</code></pre>"},{"location":"description/#6-prepare-readme","title":"6. Prepare README","text":"<p>Package description is based on <code>.ipynb</code> with same name as the <code>.py</code>. By default it is converted to markdown as is, but there is also an option to execute it.</p> <pre><code>import logging\nldh = LongDocHandler(\n    # optional/required later\n    notebook_path = \"../tests/package_auto_assembler/other/example_module.ipynb\",\n    markdown_filepath = \"../example_module.md\",\n    timeout = 600,\n    kernel_name = 'python3',\n    # logger\n    loggerLvl = logging.DEBUG\n)\n</code></pre>"},{"location":"description/#convert-notebook-to-md-without-executing","title":"Convert notebook to md without executing","text":"<pre><code>ldh.convert_notebook_to_md(\n    # optional\n    notebook_path = \"../tests/package_auto_assembler/other/example_module.ipynb\",\n    output_path = \"../example_module.md\"\n)\n</code></pre> <pre><code>Converted ../tests/package_auto_assembler/example_module.ipynb to ../example_module.md\n</code></pre>"},{"location":"description/#convert-notebook-to-md-with-executing","title":"Convert notebook to md with executing","text":"<pre><code>ldh.convert_and_execute_notebook_to_md(\n    # optional\n    notebook_path = \"../tests/package_auto_assembler/other/example_module.ipynb\",\n    output_path = \"../example_module.md\",\n    timeout = 600,\n    kernel_name = 'python3'\n)\n</code></pre> <pre><code>Converted and executed ../tests/package_auto_assembler/example_module.ipynb to ../example_module.md\n</code></pre>"},{"location":"description/#return-long-description","title":"Return long description","text":"<pre><code>long_description = ldh.return_long_description(\n    # optional\n    markdown_filepath = \"../example_module.md\"\n)\n</code></pre>"},{"location":"description/#7-assembling-setup-directory","title":"7. Assembling setup directory","text":"<p>Packages are created following rather simple sequence of steps. At some point of the process a temporary directory is created to store the following files:</p> <ul> <li><code>__init__.py</code> is a simple import from a single module</li> <li><code>&lt;package name&gt;.py</code> is a single module with all of the local dependecies</li> <li><code>cli.py</code> is optional packaged cli tool</li> <li><code>routes.py</code> is optional packaged file with fastapi routes</li> <li><code>streamlit.py</code> is optional packaged streamlit app</li> <li><code>setup.py</code> is a setup file for making a package</li> <li><code>README.md</code> is a package description file based on <code>.ipynb</code> file</li> <li><code>LICENSE</code> is optional license file</li> <li><code>MANIFEST.in</code> is a list of additional files to be included with the package</li> <li><code>mkdocs</code> is a folder with built mkdocs site based on optional <code>extra_docs</code> for the module, module docstring and <code>README.md</code></li> <li><code>artifacts</code> contains optional files that would be packaged with the module</li> <li><code>tests</code> contains files needed to run tests with <code>pytest</code></li> <li><code>.paa.tracking</code> contains tracking files from <code>.paa</code> dir to make each release of the package independent of PPR that released it</li> </ul>"},{"location":"description/#initializing-setupdirhandler","title":"Initializing SetupDirHandler","text":"<pre><code>sdh = SetupDirHandler(\n    # required\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    # optional/ required\n    module_name = \"example_module\",\n    metadata = {'author': 'Kyrylo Mordan',\n                'version': '0.0.1',\n                'description': 'Example module.',\n                'long_description' : long_description,\n                'keywords': ['python']},\n    license_path = \"../LICENSE\",\n    requirements = ['attrs&gt;=22.2.0'],\n    classifiers = ['Development Status :: 3 - Alpha',\n                   'Intended Audience :: Developers',\n                   'Intended Audience :: Science/Research',\n                   'Programming Language :: Python :: 3',\n                   'Programming Language :: Python :: 3.9',\n                   'Programming Language :: Python :: 3.10',\n                   'Programming Language :: Python :: 3.11',\n                   'License :: OSI Approved :: MIT License',\n                   'Topic :: Scientific/Engineering'],\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#create-empty-setup-dir","title":"Create empty setup dir","text":"<pre><code>sdh.flush_n_make_setup_dir(\n    # optional\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#copy-module-to-setup-dir","title":"Copy module to setup dir","text":"<pre><code>sdh.copy_module_to_setup_dir(\n    # optional\n    module_filepath = \"./combined_example_module.py\",\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#copy-license-to-setup-dir","title":"Copy license to setup dir","text":"<pre><code>sdh.copy_module_to_setup_dir(\n    # optional\n    license_path = \"../LICENSE\",\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#create-init-file","title":"Create init file","text":"<pre><code>sdh.create_init_file(\n    # optional\n    module_name = \"example_module\",\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#create-setup-file","title":"Create setup file","text":"<pre><code>sdh.write_setup_file(\n    # optional\n    module_name = \"example_module\",\n    metadata = {'author': 'Kyrylo Mordan',\n                'version': '0.0.1',\n                'description': 'Example Module',\n                'keywords': ['python']},\n    requirements = ['attrs&gt;=22.2.0'],\n    classifiers = ['Development Status :: 3 - Alpha',\n                   'Intended Audience :: Developers',\n                   'Intended Audience :: Science/Research',\n                   'Programming Language :: Python :: 3',\n                   'Programming Language :: Python :: 3.9',\n                   'Programming Language :: Python :: 3.10',\n                   'Programming Language :: Python :: 3.11',\n                   'License :: OSI Approved :: MIT License',\n                   'Topic :: Scientific/Engineering'],\n    setup_directory = \"./example_setup_dir\"\n)\n</code></pre>"},{"location":"description/#8-creating-release-notes-from-commit-messages","title":"8. Creating release notes from commit messages","text":"<p>Package versioning could be enhanced with release notes. Since the tool is mainly meant for ci/cd, it takes advantage of commit messages to construct a release note for every version. </p> <p>Commit history is analysed from the last merge, if nothiong found then the next and the next, until at least one of <code>[&lt;package name&gt;]</code> labels are found within commit messages. They are bundled together to for a note, where each commit message or messages deliminated with <code>;</code> are turned in a list element. Previos notes are used to establish which part of commit history to use as a starting point.</p> <p>Commit messages could also be used to increment version by something other then a default patch. </p> <ul> <li><code>[&lt;package name&gt;][..+]</code> increments patch (default behavior)</li> <li><code>[&lt;package name&gt;][.+.]</code> increments minor</li> <li><code>[&lt;package name&gt;][+..]</code> increments major</li> <li><code>[&lt;package name&gt;][0.1.2]</code> forces specific version <code>0.1.2</code></li> </ul> <p>* First release within new packaging repo may struggle to extract release note since commit messages are only analysed from merges in the commit history. </p> <pre><code>rnh = ReleaseNotesHandler(\n    # path to existing or new release notes file\n    filepath = '../tests/package_auto_assembler/other/release_notes.md',\n    # name of label in commit message [example_module] for filter\n    label_name = 'example_module',\n    # new version to be used in release notes\n    version = '0.0.1'\n)\n</code></pre> <pre><code>No relevant commit messages found!\n..trying depth 2 !\nNo relevant commit messages found!\nNo messages to clean were provided\n</code></pre>"},{"location":"description/#-overwritting-commit-messages-from-example","title":"- overwritting commit messages from example","text":"<pre><code># commit messages from last merge\nrnh.commit_messages\n</code></pre> <pre><code>['fixing paa tests',\n 'fixing paa tests',\n 'fixing paa tests',\n '[package_auto_assembler] increasing default max search depth for commit history to 5',\n 'fixing mocker-db release notes',\n 'Update package version tracking files',\n 'Update README',\n 'Update requirements']\n</code></pre> <pre><code>example_commit_messages = [\n    '[example_module] usage example for initial release notes; bugfixes for RNH',\n    '[BUGFIX] missing parameterframe usage example and reduntant png file',\n    '[example_module][0.1.2] initial release notes handler',\n    'Update README',\n    'Update requirements'\n]\nrnh.commit_messages = example_commit_messages\n</code></pre>"},{"location":"description/#-internal-methods-that-run-on-intialiazation-of-releasenoteshandler","title":"- internal methods that run on intialiazation of ReleaseNotesHandler","text":"<pre><code># get messages relevant only for label\nrnh._filter_commit_messages_by_package()\nprint(\"Example filtered_messaged:\")\nprint(rnh.filtered_messages)\n\n# clean messages\nrnh._clean_and_split_commit_messages()\nprint(\"Example processed_messages:\")\nprint(rnh.processed_messages)\n</code></pre> <pre><code>Example filtered_messaged:\n['[example_module] usage example for initial release notes; bugfixes for RNH', '[example_module][0.1.2] initial release notes handler']\nExample processed_messages:\n['usage example for initial release notes', 'bugfixes for RNH', 'initial release notes handler']\n</code></pre>"},{"location":"description/#-get-version-update-from-relevant-messages","title":"- get version update from relevant messages","text":"<pre><code>version_update = rnh.extract_latest_version()\nprint(f\"Example version_update: {version_update}\")\n</code></pre> <pre><code>Example version_update: 0.1.2\n</code></pre>"},{"location":"description/#-get-latest-version-from-relevant-release-notes","title":"- get latest version from relevant release notes","text":"<pre><code>latest_version = rnh.extract_latest_version()\nprint(f\"Example latest_version: {latest_version}\")\n</code></pre> <pre><code>Example latest_version: 0.1.2\n</code></pre>"},{"location":"description/#-augment-existing-release-note-with-new-entries-or-create-new","title":"- augment existing release note with new entries or create new","text":"<pre><code># augment existing release note with new entries or create new\nrnh.create_release_note_entry(\n    # optional\n    existing_contents=rnh.existing_contents,\n    version=rnh.version,\n    new_messages=rnh.processed_messages\n)\nprint(\"Example processed_note_entries:\")\nprint(rnh.processed_note_entries)\n</code></pre> <pre><code>Example processed_note_entries:\n['# Release notes\\n', '\\n', '### 0.1.2\\n', '\\n', '    - usage example for initial release notes\\n', '\\n', '    - bugfixes for RNH\\n', '\\n', '    - initial release notes handler\\n', '\\n', '### 0.0.1\\n', '\\n', '    - initial version of example_module\\n']\n</code></pre>"},{"location":"description/#-saving-updated-relese-notes","title":"- saving updated relese notes","text":"<pre><code>rnh.existing_contents\n</code></pre> <pre><code>['# Release notes\\n',\n '\\n',\n '### 0.1.2\\n',\n '\\n',\n '    - usage example for initial release notes\\n',\n '    - bugfixes for RNH\\n',\n '    - initial release notes handler\\n',\n '### 0.1.2\\n',\n '\\n',\n '    - usage example for initial release notes\\n',\n '\\n',\n '    - bugfixes for RNH\\n',\n '\\n',\n '    - initial release notes handler\\n',\n '\\n',\n '### 0.0.1\\n',\n '\\n',\n '    - initial version of example_module\\n']\n</code></pre> <pre><code>rnh.save_release_notes()\n</code></pre> <pre><code># updated content\nrnh.get_release_notes_content()\n</code></pre> <pre><code>['# Release notes\\n',\n '\\n',\n '### 0.1.2\\n',\n '\\n',\n '    - usage example for initial release notes\\n',\n '\\n',\n '    - bugfixes for RNH\\n',\n '\\n',\n '    - initial release notes handler\\n',\n '\\n',\n '### 0.0.1\\n',\n '\\n',\n '    - initial version of example_module\\n']\n</code></pre>"},{"location":"description/#9-analysing-package-dependencies","title":"9. Analysing package dependencies","text":"<p>Extracting info from installed dependencies can provide important insight into inner workings of a package and help avoid some of the licenses. </p> <p>Licenses are extracted from package metadata and normalized for analysis. Missing labels are marked with <code>-</code> and not recognized licenses with <code>unknown</code>.</p> <p>Information about unrecognized license labels could be provided through <code>.paa/package_licenses json</code> file that would contain install package name and corresponding license label.</p> <pre><code>da = DependenciesAnalyser(\n    # optional\n    package_name = 'mocker-db',\n    package_licenses_filepath = '../tests/package_auto_assembler/other/package_licenses.json',\n    allowed_licenses = ['mit', 'apache-2.0', 'lgpl-3.0', 'bsd-3-clause', 'bsd-2-clause', '-', 'mpl-2.0']\n)\n</code></pre>"},{"location":"description/#finding-installed-packages-with-a-list-of-tags","title":"Finding installed packages with a list of tags","text":"<pre><code>da.filter_packages_by_tags(tags=['aa-paa-tool'])\n</code></pre> <pre><code>[('comparisonframe', '0.0.0'),\n ('mocker-db', '0.0.1'),\n ('package-auto-assembler', '0.0.0'),\n ('proompter', '0.0.0')]\n</code></pre>"},{"location":"description/#extracting-some-metadata-from-the-installed-package","title":"Extracting some metadata from the installed package","text":"<pre><code>package_metadata = da.get_package_metadata(\n    package_name = 'mocker-db'\n)\npackage_metadata\n</code></pre> <pre><code>{'keywords': ['aa-paa-tool'],\n 'version': '0.0.1',\n 'author': 'Kyrylo Mordan',\n 'author_email': 'parachute.repo@gmail.com',\n 'classifiers': ['Development Status :: 3 - Alpha',\n  'Intended Audience :: Developers',\n  'Intended Audience :: Science/Research',\n  'Programming Language :: Python :: 3',\n  'Programming Language :: Python :: 3.9',\n  'Programming Language :: Python :: 3.10',\n  'Programming Language :: Python :: 3.11',\n  'License :: OSI Approved :: MIT License',\n  'Topic :: Scientific/Engineering',\n  'PAA-Version :: 0.4.3',\n  'PAA-CLI :: False'],\n 'paa_version': '0.4.3',\n 'paa_cli': 'False',\n 'license_label': 'MIT'}\n</code></pre>"},{"location":"description/#extracting-package-requirements","title":"Extracting package requirements","text":"<pre><code>package_requirements = da.get_package_requirements(\n    package_name = 'mocker-db'\n)\npackage_requirements\n</code></pre> <pre><code>['requests',\n 'attrs &gt;=22.2.0',\n 'httpx',\n 'hnswlib ==0.8.0',\n 'gridlooper ==0.0.1',\n 'dill ==0.3.7',\n 'numpy ==1.26.0',\n \"sentence-transformers ; extra == 'sentence_transformers'\"]\n</code></pre>"},{"location":"description/#extracting-tree-of-dependencies","title":"Extracting tree of dependencies","text":"<pre><code>extracted_dependencies_tree = da.extract_dependencies_tree(\n    package_name = 'mocker-db'\n)\nextracted_dependencies_tree\n</code></pre> <pre><code>{'requests': {'charset-normalizer': [],\n  'idna': [],\n  'urllib3': [],\n  'certifi': []},\n 'attrs': {'importlib-metadata': {'zipp': [], 'typing-extensions': []}},\n 'httpx': {'anyio': {'idna': [],\n   'sniffio': [],\n   'exceptiongroup': [],\n   'typing-extensions': []},\n  'certifi': [],\n  'httpcore': {'certifi': [], 'h11': {'typing-extensions': []}},\n  'idna': [],\n  'sniffio': []},\n 'hnswlib': {'numpy': []},\n 'gridlooper': {'dill': [],\n  'attrs': {'importlib-metadata': {'zipp': [], 'typing-extensions': []}},\n  'tqdm': {'colorama': []}},\n 'dill': [],\n 'numpy': []}\n</code></pre>"},{"location":"description/#addding-license-labels-to-tree-of-dependencies","title":"Addding license labels to tree of dependencies","text":"<pre><code>extracted_dependencies_tree_license = da.add_license_labels_to_dep_tree(\n    dependencies_tree = extracted_dependencies_tree\n)\nextracted_dependencies_tree_license\n</code></pre> <pre><code>{'requests': 'apache-2.0',\n 'requests.charset-normalizer': '-',\n 'requests.idna': '-',\n 'requests.urllib3': '-',\n 'requests.certifi': 'mpl-2.0',\n 'attrs': '-',\n 'attrs.importlib-metadata': '-',\n 'attrs.importlib-metadata.zipp': '-',\n 'attrs.importlib-metadata.typing-extensions': '-',\n 'httpx': '-',\n 'httpx.anyio': 'mit',\n 'httpx.anyio.idna': '-',\n 'httpx.anyio.sniffio': '-',\n 'httpx.anyio.exceptiongroup': '-',\n 'httpx.anyio.typing-extensions': '-',\n 'httpx.certifi': 'mpl-2.0',\n 'httpx.httpcore': '-',\n 'httpx.httpcore.certifi': 'mpl-2.0',\n 'httpx.httpcore.h11': 'mit',\n 'httpx.httpcore.h11.typing-extensions': '-',\n 'httpx.idna': '-',\n 'httpx.sniffio': '-',\n 'hnswlib': '-',\n 'hnswlib.numpy': 'bsd-3-clause',\n 'gridlooper': '-',\n 'gridlooper.dill': 'bsd-3-clause',\n 'gridlooper.attrs': '-',\n 'gridlooper.attrs.importlib-metadata': '-',\n 'gridlooper.attrs.importlib-metadata.zipp': '-',\n 'gridlooper.attrs.importlib-metadata.typing-extensions': '-',\n 'gridlooper.tqdm': '-',\n 'gridlooper.tqdm.colorama': '-',\n 'dill': 'bsd-3-clause',\n 'numpy': 'bsd-3-clause'}\n</code></pre>"},{"location":"description/#printing-extracted-tree-of-dependencies","title":"Printing extracted tree of dependencies","text":"<pre><code>da.print_flattened_tree(extracted_dependencies_tree_license)\n</code></pre> <pre><code>\u2514\u2500\u2500 requests : apache-2.0\n    \u251c\u2500\u2500 charset-normalizer : -\n    \u251c\u2500\u2500 idna : -\n    \u251c\u2500\u2500 urllib3 : -\n    \u2514\u2500\u2500 certifi : mpl-2.0\n\u2514\u2500\u2500 attrs : -\n    \u2514\u2500\u2500 importlib-metadata : -\n        \u251c\u2500\u2500 zipp : -\n        \u2514\u2500\u2500 typing-extensions : -\n\u2514\u2500\u2500 httpx : -\n    \u251c\u2500\u2500 anyio : mit\n        \u251c\u2500\u2500 idna : -\n        \u251c\u2500\u2500 sniffio : -\n        \u251c\u2500\u2500 exceptiongroup : -\n        \u2514\u2500\u2500 typing-extensions : -\n    \u251c\u2500\u2500 certifi : mpl-2.0\n    \u251c\u2500\u2500 httpcore : -\n        \u251c\u2500\u2500 certifi : mpl-2.0\n        \u2514\u2500\u2500 h11 : mit\n            \u2514\u2500\u2500 typing-extensions : -\n    \u251c\u2500\u2500 idna : -\n    \u2514\u2500\u2500 sniffio : -\n\u2514\u2500\u2500 hnswlib : -\n    \u2514\u2500\u2500 numpy : bsd-3-clause\n\u2514\u2500\u2500 gridlooper : -\n    \u251c\u2500\u2500 dill : bsd-3-clause\n    \u251c\u2500\u2500 attrs : -\n        \u2514\u2500\u2500 importlib-metadata : -\n            \u251c\u2500\u2500 zipp : -\n            \u2514\u2500\u2500 typing-extensions : -\n    \u2514\u2500\u2500 tqdm : -\n        \u2514\u2500\u2500 colorama : -\n\u2514\u2500\u2500 dill : bsd-3-clause\n\u2514\u2500\u2500 numpy : bsd-3-clause\n</code></pre>"},{"location":"description/#filtering-for-unexpected-licenses-in-tree-of-dependencies","title":"Filtering for unexpected licenses in tree of dependencies","text":"<pre><code>allowed_licenses = ['mit', 'apache-2.0', 'lgpl-3.0', 'mpl-2.0', '-']\n\nda.find_unexpected_licenses_in_deps_tree(\n    tree_dep_license = extracted_dependencies_tree_license,\n    # optional\n    allowed_licenses = allowed_licenses,\n    raise_error = True\n)\n</code></pre> <pre><code>{'hnswlib': '', 'gridlooper': ''}\n\u2514\u2500\u2500 dill : bsd-3-clause\n\u2514\u2500\u2500 numpy : bsd-3-clause\n\u2514\u2500\u2500 hnswlib : \n    \u2514\u2500\u2500 numpy : bsd-3-clause\n\u2514\u2500\u2500 gridlooper : \n    \u2514\u2500\u2500 dill : bsd-3-clause\n\n\n\n---------------------------------------------------------------------------\n\nException                                 Traceback (most recent call last)\n\nCell In[9], line 3\n      1 allowed_licenses = ['mit', 'apache-2.0', 'lgpl-3.0', 'mpl-2.0', '-']\n----&gt; 3 da.find_unexpected_licenses_in_deps_tree(\n      4     tree_dep_license = extracted_dependencies_tree_license,\n      5     # optional\n      6     allowed_licenses = allowed_licenses,\n      7     raise_error = True\n      8 )\n\n\nFile ~/miniforge3/envs/testenv/lib/python3.10/site-packages/package_auto_assembler/package_auto_assembler.py:2670, in DependenciesAnalyser.find_unexpected_licenses_in_deps_tree(self, tree_dep_license, allowed_licenses, raise_error)\n   2668 if raise_error and out != {}:\n   2669     self.print_flattened_tree(flattened_dict = out)\n-&gt; 2670     raise Exception(\"Found unexpected licenses!\")\n   2671 else:\n   2672     self.logger.info(\"No unexpected licenses found\")\n\n\nException: Found unexpected licenses!\n</code></pre>"},{"location":"description/#10-adding-cli-interfaces","title":"10. Adding cli interfaces","text":"<p>The tool allows to make a package with optional cli interfaces. These could be sometimes preferable when a package contains a standalone tool that would be called from script anyway.</p> <p>All of the cli logic would need to be included within a <code>.py</code> file which should be stored within <code>cli_dir</code> provided in <code>.paa.config</code>.  Dependencies from these files are extracted in the similar manner to the main module.</p> <p>Tools from main <code>.py</code> file could still be imported like the following:</p> <pre><code>from package_name.package_name import ToBeImported\n</code></pre> <p>The code is wired in <code>setup.py</code> via the following automatically assuming that appropriate file with the same name as the package exists within <code>cli_dir</code> location.</p> <pre><code>...,\nentry_points = {'console_scripts': [\n    '&lt;package_alias&gt; = package_name.cli:cli']} ,\n...\n</code></pre> <p>Alias for name could be provided via the following piece of code, defined after imports, otherwise package name would be used.</p> <pre><code>__cli_metadata__ = {\n    \"name\" : &lt;package_alias&gt;\n}\n</code></pre> <p>Package-auto-assembler tool itself uses <code>click</code> dependency to build that file, use its cli definition as example.</p>"},{"location":"description/#11-adding-routes-and-running-fastapi-application","title":"11. Adding routes and running FastAPI application","text":"<p>The tool allows to make a package with optional routes for FastAPI application and run them. Each packages can have one routes file where its logic should be defined. Package-auto-assembler itself can combine multiple routes from packages and filepaths into one application.</p> <p>A <code>.py</code>  file with the same name of the package should be stored within <code>api_routes_dir</code> provided in <code>.paa.config</code>.</p> <p>Dependencies from these files are extracted in the similar manner to the main module.</p> <p>Tools from main <code>.py</code> file could still be imported like the following:</p> <pre><code>from package_name.package_name import ToBeImported\n</code></pre> <p>Api description, middleware and run parameters could be provided via optional <code>.paa.api.config</code> file, which for example would look like:</p> <pre><code>DESCRIPTION : {\n    'version' : 0.0.0\n}\nMIDDLEWARE : {\n    allow_origins : ['*']\n}\nRUN : {\n host : 0.0.0.0\n}\n</code></pre> <p>where DESCRIPTION contains parameters for <code>FastAPI</code>, MIDDLEWARE for <code>CORSMiddleware</code> and RUN for <code>uvicorn.run</code></p>"},{"location":"description/#12-adding-ui-and-running-streamlit-application","title":"12. Adding ui and running streamlit application","text":"<p>The tools allows to make a package with optional <code>streamlit</code> application as interface to the packaged code.  Each package can have one streamlit file. Package-auto-assembler itself would then be used to run packaged applications from the package. </p> <p>A <code>.py</code>  file with the same name of the package should be stored within <code>streamlit_dir</code> provided in <code>.paa.config</code>.</p> <p>Dependencies from these files are extracted in the similar manner to the main module.</p> <p>Tools from main <code>.py</code> file could still be imported like the following:</p> <pre><code>from package_name.package_name import ToBeImported\n</code></pre> <p>Config file with server, theme and other settings can be provided via optional <code>.paa.streamlit.config</code>. </p>"},{"location":"description/#13-adding-artifacts-to-packages","title":"13 Adding artifacts to packages","text":"<p>The tool allows to add files to packages that could be accessed from the package or extracted into selected directory.</p> <p>There are different types of artifacts with a package like this: - <code>.paa.tracking</code> : includes some tracking files for the purposes of the tool, added to every package - <code>mkdocs</code> : optional static mkdocs site  - <code>artifacts</code> contains directories, files and links to files</p> <p>Tracking files are added automatically of artifacts adding was not turned off. At the moment contains: - <code>.paa.config</code> : config file that specifies how paa show work - <code>.paa.version</code>: version of <code>package-auto-assembler</code> that was used for packaging - <code>release_notes.md</code> : latest release notes for the package - <code>version_logs.csv</code> : logs for version updates for all packages in the packaging repo - <code>lsts_package_versions.yml</code> : latests versions of all packages in the packaging repo - <code>package_mapping.json</code> : additional user-provided remapping of package import names to install names - <code>package_licenses.json</code> : additional user-provided license labels to overwrite detected ones - <code>notebook.ipynb</code> : optional jupyter notebook that was used for package description</p> <p>User provided artifacts could be provided in two ways: - adding directory, file or link to the file under <code>artifacts/&lt;package_name&gt;</code></p> <p>These files would be packaged with the packages, and files from links would be downloaded and packaged as well.</p> <ul> <li>adding <code>artifact_urls</code> dictionary to <code>__package_metadata__</code> within module <code>.py</code> file</li> </ul> <p>Example of <code>__package_metadata__</code> with these additional dictionary would be:</p> <pre><code>__package_metadata__ = {\n    \"author\": \"Kyrylo Mordan\",\n    \"author_email\": \"parachute.repo@gmail.com\",\n    \"description\": \"A tool to automate package creation within ci based on just .py and optionally .ipynb file.\",\n    \"keywords\" : ['python', 'packaging'],\n    'license' : 'mit',\n    \"url\" : 'https://kiril-mordan.github.io/reusables/package_auto_assembler/',\n    \"artifact_urls\" : {\n        'downloaded.md' : 'https://raw.githubusercontent.com/Kiril-Mordan/reusables/refs/heads/main/docs/module_from_raw_file.md',\n        'downloaded.png' : 'https://raw.githubusercontent.com/Kiril-Mordan/reusables/refs/heads/main/docs/reuse_logo.png'\n    }\n}\n</code></pre> <p>where key would contain name of the artifact and value its link.</p> <p>These files would not be downloaded and only links would be packaged. After package installation both kinds of links could be refreshed/donwloaded using <code>cli interface</code> from <code>package-auto-assembler</code>.</p>"},{"location":"description/#14-making-a-package","title":"14. Making a package","text":"<p>Main wrapper for the package integrates described above components into a class that could be used to build package building pipelines within python scripts. </p> <p>To simplify usage cli interface is recomended instead. </p>"},{"location":"description/#initializing-packageautoassembler","title":"Initializing PackageAutoAssembler","text":"<pre><code>paa = PackageAutoAssembler(\n    # required\n    module_name = \"example_module\",\n    module_filepath  = \"../tests/package_auto_assembler/other/example_module.py\",\n    # optional\n    mapping_filepath = \"../env_spec/package_mapping.json\",\n    licenses_filepath = \"../tests/package_auto_assembler/other/package_licenses.json\",\n    allowed_licenses = ['mit', 'apache-2.0', 'lgpl-3.0', 'mpl-2.0', '-'],\n    dependencies_dir = \"../tests/package_auto_assembler/dependancies/\",\n    example_notebook_path = \"./mock_vector_database.ipynb\",\n    versions_filepath = '../tests/package_auto_assembler/other/lsts_package_versions.yml',\n    log_filepath = '../tests/package_auto_assembler/other/version_logs.csv',\n    setup_directory = \"./example_module\",\n    release_notes_filepath = \"../tests/package_auto_assembler/other/release_notes.md\",\n    license_path = \"../LICENSE\",\n    license_label = \"mit\",\n    classifiers = ['Development Status :: 3 - Alpha',\n                    'Intended Audience :: Developers',\n                    'Intended Audience :: Science/Research',\n                    'Programming Language :: Python :: 3',\n                    'Programming Language :: Python :: 3.9',\n                    'Programming Language :: Python :: 3.10',\n                    'Programming Language :: Python :: 3.11',\n                    'License :: OSI Approved :: MIT License',\n                    'Topic :: Scientific/Engineering'],\n    requirements_list = [],\n    execute_readme_notebook = True,\n    python_version = \"3.8\",\n    version_increment_type = \"patch\",\n    default_version = \"0.0.1\",\n    check_vulnerabilities = True,\n    check_dependencies_licenses = False,\n    add_requirements_header = True\n)\n</code></pre>"},{"location":"description/#add-metadata-from-module","title":"Add metadata from module","text":"<pre><code>paa.add_metadata_from_module(\n    # optional\n    module_filepath  = \"../tests/package_auto_assembler/other/example_module.py\"\n)\n</code></pre> <pre><code>Adding metadata ...\n</code></pre>"},{"location":"description/#add-or-update-version","title":"Add or update version","text":"<pre><code>paa.add_or_update_version(\n    # overwrites auto mode (not suggested)\n    version_increment_type = \"patch\",\n    version = \"1.2.6\",\n    # optional\n    module_name = \"example_module\",\n    versions_filepath = '../tests/package_auto_assembler/lsts_package_versions.yml',\n    log_filepath = '../tests/package_auto_assembler/version_logs.csv'\n)\n</code></pre> <pre><code>Incrementing version ...\nNo relevant commit messages found!\n..trying depth 2 !\nNo relevant commit messages found!\n..trying depth 3 !\nNo relevant commit messages found!\n..trying depth 4 !\nNo relevant commit messages found!\n..trying depth 5 !\nNo relevant commit messages found!\nNo messages to clean were provided\n</code></pre>"},{"location":"description/#add-release-notes-from-commit-messages","title":"Add release notes from commit messages","text":"<pre><code>paa.add_or_update_release_notes(\n    # optional\n    filepath=\"../tests/package_auto_assembler/release_notes.md\",\n    version=paa.metadata['version']\n)\n</code></pre> <pre><code>Updating release notes ...\n</code></pre>"},{"location":"description/#prepare-setup-directory","title":"Prepare setup directory","text":"<pre><code>paa.prep_setup_dir()\n</code></pre> <pre><code>Preparing setup directory ...\n</code></pre>"},{"location":"description/#merge-local-dependacies","title":"Merge local dependacies","text":"<pre><code>paa.merge_local_dependacies(\n    # optional\n    main_module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    dependencies_dir= \"../tests/package_auto_assembler/dependancies/\",\n    save_filepath = \"./example_module/example_module.py\"\n)\n</code></pre> <pre><code>Merging ../tests/package_auto_assembler/other/example_module.py with dependecies from ../tests/package_auto_assembler/dependancies/ into ./example_module/example_module.py\n</code></pre>"},{"location":"description/#add-requirements-from-module","title":"Add requirements from module","text":"<pre><code>paa.add_requirements_from_module(\n    # optional\n    module_filepath = \"../tests/package_auto_assembler/other/example_module.py\",\n    import_mappings = {'PIL': 'Pillow',\n                        'bs4': 'beautifulsoup4',\n                        'fitz': 'PyMuPDF',\n                        'attr': 'attrs',\n                        'dotenv': 'python-dotenv',\n                        'googleapiclient': 'google-api-python-client',\n                        'sentence_transformers': 'sentence-transformers',\n                        'flask': 'Flask',\n                        'stdlib_list': 'stdlib-list',\n                        'sklearn': 'scikit-learn',\n                        'yaml': 'pyyaml',\n                        'git' : 'gitpython'}\n)\n</code></pre> <pre><code>Adding requirements from ../tests/package_auto_assembler/other/example_module.py\nNo known vulnerabilities found\n</code></pre> <pre><code>paa.requirements_list\n</code></pre> <pre><code>['### example_module.py', 'attrs&gt;=22.2.0']\n</code></pre>"},{"location":"description/#make-readme-out-of-example-notebook","title":"Make README out of example notebook","text":"<pre><code>paa.add_readme(\n    # optional\n    example_notebook_path = \"../tests/package_auto_assembler/other/example_module.ipynb\",\n    output_path = \"./example_module/README.md\",\n    execute_notebook=False,\n)\n</code></pre> <pre><code>Adding README from ../tests/package_auto_assembler/other/example_module.ipynb to ./example_module/README.md\n</code></pre>"},{"location":"description/#prepare-setup-file","title":"Prepare setup file","text":"<pre><code>paa.prep_setup_file(\n    # optional\n    metadata = {'author': 'Kyrylo Mordan',\n                'version': '0.0.1',\n                'description': 'Example module',\n                'keywords': ['python'],\n                'license' : 'mit'},\n    requirements = ['### example_module.py',\n                    'attrs&gt;=22.2.0'],\n    classifiers = ['Development Status :: 3 - Alpha',\n                    'Intended Audience :: Developers',\n                    'Intended Audience :: Science/Research',\n                    'Programming Language :: Python :: 3',\n                    'Programming Language :: Python :: 3.9',\n                    'Programming Language :: Python :: 3.10',\n                    'Programming Language :: Python :: 3.11',\n                    'License :: OSI Approved :: MIT License',\n                    'Topic :: Scientific/Engineering'],\n    cli_module_filepath = \"../tests/package_auto_assembler/other/cli.py\"\n\n)\n</code></pre> <pre><code>Preparing setup file for example-module package ...\n</code></pre>"},{"location":"description/#make-package","title":"Make package","text":"<pre><code>paa.make_package(\n    # optional\n    setup_directory = \"./example_module\"\n)\n</code></pre> <pre><code>Making package from ./example_module ...\n\n\n\n\n\nCompletedProcess(args=['python', './example_module/setup.py', 'sdist', 'bdist_wheel'], returncode=0, stdout=\"running sdist\\nrunning egg_info\\nwriting example_module.egg-info/PKG-INFO\\nwriting dependency_links to example_module.egg-info/dependency_links.txt\\nwriting entry points to example_module.egg-info/entry_points.txt\\nwriting requirements to example_module.egg-info/requires.txt\\nwriting top-level names to example_module.egg-info/top_level.txt\\nreading manifest file 'example_module.egg-info/SOURCES.txt'\\nwriting manifest file 'example_module.egg-info/SOURCES.txt'\\nrunning check\\ncreating example_module-0.0.0\\ncreating example_module-0.0.0/example_module\\ncreating example_module-0.0.0/example_module.egg-info\\ncopying files to example_module-0.0.0...\\ncopying example_module/__init__.py -&gt; example_module-0.0.0/example_module\\ncopying example_module/cli.py -&gt; example_module-0.0.0/example_module\\ncopying example_module/example_module.py -&gt; example_module-0.0.0/example_module\\ncopying example_module/setup.py -&gt; example_module-0.0.0/example_module\\ncopying example_module.egg-info/PKG-INFO -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/SOURCES.txt -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/dependency_links.txt -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/entry_points.txt -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/requires.txt -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/top_level.txt -&gt; example_module-0.0.0/example_module.egg-info\\ncopying example_module.egg-info/SOURCES.txt -&gt; example_module-0.0.0/example_module.egg-info\\nWriting example_module-0.0.0/setup.cfg\\nCreating tar archive\\nremoving 'example_module-0.0.0' (and everything under it)\\nrunning bdist_wheel\\nrunning build\\nrunning build_py\\ncopying example_module/example_module.py -&gt; build/lib/example_module\\ncopying example_module/__init__.py -&gt; build/lib/example_module\\ncopying example_module/setup.py -&gt; build/lib/example_module\\ncopying example_module/cli.py -&gt; build/lib/example_module\\ninstalling to build/bdist.linux-x86_64/wheel\\nrunning install\\nrunning install_lib\\ncreating build/bdist.linux-x86_64/wheel\\ncreating build/bdist.linux-x86_64/wheel/example_module\\ncopying build/lib/example_module/example_module.py -&gt; build/bdist.linux-x86_64/wheel/example_module\\ncopying build/lib/example_module/__init__.py -&gt; build/bdist.linux-x86_64/wheel/example_module\\ncopying build/lib/example_module/setup.py -&gt; build/bdist.linux-x86_64/wheel/example_module\\ncopying build/lib/example_module/cli.py -&gt; build/bdist.linux-x86_64/wheel/example_module\\nrunning install_egg_info\\nCopying example_module.egg-info to build/bdist.linux-x86_64/wheel/example_module-0.0.0-py3.10.egg-info\\nrunning install_scripts\\ncreating build/bdist.linux-x86_64/wheel/example_module-0.0.0.dist-info/WHEEL\\ncreating 'dist/example_module-0.0.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\\nadding 'example_module/__init__.py'\\nadding 'example_module/cli.py'\\nadding 'example_module/example_module.py'\\nadding 'example_module/setup.py'\\nadding 'example_module-0.0.0.dist-info/METADATA'\\nadding 'example_module-0.0.0.dist-info/WHEEL'\\nadding 'example_module-0.0.0.dist-info/entry_points.txt'\\nadding 'example_module-0.0.0.dist-info/top_level.txt'\\nadding 'example_module-0.0.0.dist-info/RECORD'\\nremoving build/bdist.linux-x86_64/wheel\\n\", stderr='warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\\n\\n/home/kyriosskia/miniconda3/envs/testenv/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\\n!!\\n\\n        ********************************************************************************\\n        Please avoid running ``setup.py`` directly.\\n        Instead, use pypa/build, pypa/installer or other\\n        standards-based tools.\\n\\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\\n        ********************************************************************************\\n\\n!!\\n  self.initialize_options()\\n')\n</code></pre>"},{"location":"description/#15-making-simple-mkdocs-site","title":"15. Making simple MkDocs site","text":"<p>Package documentation can be presented in a form of mkdocs static site, which could be either served or deployed to something like github packages. </p> <p>Main module docstring is used as intro package that contains something like optional pypi and license badges. Package description and realease notes are turned into separate tabs. Png with diagrams for example could be provided and displayed as their own separate tabs as well.</p> <p>The one for this package can be seen here</p> <p>It can be packaged with the package and be displayed in webrowser like documentation for api via <code>{package_name}\\docs</code> when using included api handling capabilities.</p>"},{"location":"description/#-preparing-inputs","title":"- preparing inputs","text":"<pre><code>package_name = \"example_module\"\n\nmodule_content = LongDocHandler().read_module_content(filepath=f\"../tests/package_auto_assembler/{package_name}.py\")\n\ndocstring = LongDocHandler().extract_module_docstring(module_content=module_content)\npypi_link = LongDocHandler().get_pypi_badge(module_name=package_name)\n\n\ndocs_file_paths = {\n    \"../example_module.md\" : \"usage-examples.md\",\n    '../tests/package_auto_assembler/release_notes.md' : 'release_notes.md'\n}\n</code></pre> <pre><code>mdh = MkDocsHandler(\n    # required\n    ## name of the package to be displayed\n    package_name = package_name,\n    ## dictionary of markdown files, with path as keys\n    docs_file_paths = docs_file_paths,\n    # optional\n    ## module docstring to be displayed in the index\n    module_docstring = docstring,\n    ## pypi badge to be displayed in the index\n    pypi_badge = pypi_link,\n    ## license badge to be displayed in the index\n    license_badge=\"[![License](https://img.shields.io/github/license/Kiril-Mordan/reusables)](https://github.com/Kiril-Mordan/reusables/blob/main/LICENSE)\",\n    ## name of the project directory\n    project_name = \"temp_project\")\n</code></pre>"},{"location":"description/#-preparing-site","title":"- preparing site","text":"<pre><code>mdh.create_mkdocs_dir()\nmdh.move_files_to_docs()\nmdh.generate_markdown_for_images()\nmdh.create_index()\nmdh.create_mkdocs_yml()\nmdh.build_mkdocs_site()\n</code></pre> <pre><code>Created new MkDocs dir: temp_project\nCopied ../example_module.md to temp_project/docs/usage-examples.md\nCopied ../tests/package_auto_assembler/release_notes.md to temp_project/docs/release_notes.md\nindex.md has been created with site_name: example-module\nmkdocs.yml has been created with site_name: Example module\nCustom CSS created at temp_project/docs/css/extra.css\n\n\nINFO    -  Cleaning site directory\nINFO    -  Building documentation to directory: /home/kyriosskia/Documents/nlp/reusables/example_notebooks/temp_project/site\nINFO    -  Documentation built in 0.12 seconds\n</code></pre>"},{"location":"description/#-test-runing-site","title":"- test runing site","text":"<pre><code>mdh.serve_mkdocs_site()\n</code></pre>"},{"location":"package_structure/","title":"Package structure","text":""},{"location":"python_packaging_repo/","title":"Python packaging repo","text":""},{"location":"python_packaging_repo/#about","title":"About","text":"<p>A Python Packaging Repository (PPR) is a Git repository with a CI/CD pipeline designed to create and publish Python packages from code pushed to the repository. Using the <code>package-auto-assembler</code> tool, PPR can dynamically generate a packaging structure for <code>.py</code> files in a highly automated manner. This allows you to publish and maintain multiple packages from a single repository.</p> <p>In its simplest form, adding a new <code>.py</code> file (or modifying an existing one) triggers the CI/CD pipeline to automatically prepare and publish release of new or existing package. Packages can be published to PyPI or private storage solutions such as Azure Artifacts Storage.</p> <p></p> <p>Diagram: Automated flow for packaging and publishing Python packages using PPR.</p>"},{"location":"python_packaging_repo/#inputs-and-outputs-of-ppr","title":"Inputs and Outputs of PPR","text":"<p>PPR produces Python packages with the structure shown below when all optional files are present. You can find more details about these files here.</p> <p>Each package can include optional features:</p> <ul> <li>Store files - Include files or links to files within the package.</li> <li>CLI interface - Add command-line utilities to the package.</li> <li>FastAPI routes - Embed API routes to run FastAPI applications from packages.</li> <li>Streamlit apps - Include interactive UIs.</li> <li>MkDocs pages - Generate simple static documentation websites for each package.</li> </ul> <p></p> <p>Diagram: The structure includes core package files and additional optional components such as CLI interfaces, FastAPI routes, or documentation.</p>"},{"location":"python_packaging_repo/#setting-up-new-ppr","title":"Setting up new PPR","text":"<p>A Python Packaging Repository can be created for: - GitHub with PyPI - Azure DevOps with Azure Artifacts</p>"},{"location":"python_packaging_repo/#prerequisites","title":"Prerequisites","text":"<ul> <li>New Git Repository: A repository where the PPR will be set up.</li> <li>Pipeline Permissions: CI/CD pipelines must have read and write access to commit to the repository.</li> <li>Package Storage:<ul> <li>GitHub: A PyPI account.</li> <li>Azure DevOps: An Azure Artifacts Feed.</li> </ul> </li> </ul> <p>Only two templates are provided: - <code>github + pypi</code> - <code>azure devops + azure artifacts feed</code></p>"},{"location":"python_packaging_repo/#github","title":"Github","text":"<ol> <li> <p>Set Up GitHub Pages:</p> <ul> <li>Navigate to <code>Settings</code> -&gt; <code>Pages</code>.</li> <li>Select \"Deploy from a branch,\" choose the <code>gh-pages</code> branch (if it does not exist, create a new branch named <code>gh-pages</code>), and set the directory to <code>/root</code>. More details.</li> </ul> </li> <li> <p>Configure GitHub Actions:</p> <ul> <li>Navigate to <code>Settings</code> -&gt; <code>Actions</code> -&gt; <code>General</code>.</li> <li>Under \"Actions permissions,\" select \"Allow all actions and reusable workflows.\"</li> <li>Under \"Workflow permissions,\" select \"Read and write permissions.\" More details.</li> </ul> </li> <li> <p>Add PyPI Credentials:</p> <ul> <li>Go to <code>Settings</code> -&gt; <code>Secrets and variables</code> -&gt; <code>Actions</code>.</li> <li>Add <code>TWINE_USERNAME</code> and <code>TWINE_PASSWORD</code> as secrets. More details.</li> </ul> </li> <li> <p>Initialize the Template:</p> <ul> <li>Use <code>paa</code> to set up the PPR:  <code>bash  paa init-ppr --github</code></li> </ul> <p>Or include all optional directories:</p> <p><code>bash  paa init-ppr --github --full</code></p> <ul> <li>Edit <code>.paa.config</code> if needed</li> <li>Run <code>paa init-ppr --github</code> or <code>paa init-paa</code> a second time to initialize directories for storing packaging files based on <code>.paa.config</code>.</li> </ul> </li> <li> <p>Customize:</p> <ul> <li>Edit <code>.github/docs/README_base.md</code> and <code>.github/tools/update_README.sh</code> to modify the repository-level README.</li> </ul> </li> </ol> <p>Once setup is complete, pushing changes to the <code>main</code> will automatically trigger the pipeline to package and publish your Python packages.</p>"},{"location":"python_packaging_repo/#azure-devops","title":"Azure DevOps","text":"<ol> <li> <p>Repository Permissions:</p> <ul> <li>Navigate to <code>Project settings</code> -&gt; <code>Repositories</code> -&gt; <code>Your Repository</code>.</li> <li>Set <code>Contribute</code> and <code>Create tag</code> permissions for <code>Your project build service</code> to \"Allow\"</li> </ul> </li> <li> <p>Set Up Azure Artifacts Feed:</p> <ul> <li>Create an artifacts feed or use an existing one. More details.</li> </ul> </li> <li> <p>Add Credentials:</p> <ul> <li>Generate a Personal Access Token (<code>TWINE_USERNAME</code> and <code>TWINE_PASSWORD</code>) with \"Read &amp; write\" permissions for \"Packaging.\" More details.</li> </ul> </li> <li> <p>Initialize the Template:</p> <ul> <li>Use <code>paa</code> to set up the PPR:</li> </ul> <p><code>bash paa init-ppr --azure</code></p> <p>Or include all optional directories:</p> <p><code>bash paa init-ppr --azure --full</code></p> <ul> <li>Edit <code>.paa.config</code> if needed</li> <li>Run <code>paa init-ppr --azure</code> or <code>paa init-paa</code> a second time to initialize  directories for storing packaging files based on <code>.paa.config</code>.</li> <li>Create <code>.azure/feeds/YOUR_FEED_NAME.yml</code> files based on <code>.azure/feeds/example_feed.yml</code> and remove the example.</li> </ul> </li> <li> <p>Configure the Pipeline:</p> <ul> <li>Navigate to <code>Pipelines</code> -&gt; <code>New pipeline</code>.</li> <li>Choose <code>Azure Repos Git</code> -&gt; <code>Your Repository</code>.</li> <li>Select the <code>main</code> branch and <code>.azure/azure-pipelines.yml</code> to define the pipeline configuration for packaging and publishing.</li> <li>Add <code>TWINE_USERNAME</code> and <code>TWINE_PASSWORD</code> under \"Variables\"</li> </ul> </li> <li> <p>Customize:</p> <ul> <li>Edit <code>.azure/docs/README_base.md</code> and <code>.azure/tools/update_README.sh</code> to modify the repository-level README.</li> </ul> </li> </ol> <p>Note: Pushing changes to the <code>main</code> branch does not necessarily mean that a package will be published. Since multiple feeds can be published from this repository, a manual trigger is preferred.</p> <p>To trigger the workflow:</p> <ol> <li>Navigate to <code>Pipelines</code> -&gt; <code>your-packaging-repo-pipeline</code> -&gt; <code>Run pipeline</code>.</li> <li>Select one of the configured upload feeds in the <code>Upload Feed</code> dropdown.</li> <li>Specify the package name in the <code>Package Name</code> field (use underscores (<code>_</code>) instead of hyphens (<code>-</code>)).</li> </ol>"},{"location":"release-notes/","title":"Release notes","text":""},{"location":"release-notes/#0516","title":"0.5.16","text":"<pre><code>- default readme plus dynamic list of published packages with links to destination for github and azure templates\n\n- initial packaging repository setup instructions\n\n- azure pipelines template workflows for ppr\n\n- fixes for github template\n\n- flag to initialize all paa directories\n</code></pre>"},{"location":"release-notes/#0515","title":"0.5.15","text":"<pre><code>- github template workflows for ppr\n\n- init methods to setup ppr directories from template\n\n- additiona cli tools for pylint checks, extracting requirements and in general to handle ppr mostly from .paa.config\n\n- scripts to run pylint check and convert drawio to png accessible through ppr_handler\n</code></pre>"},{"location":"release-notes/#0514","title":"0.5.14","text":"<pre><code>- support for individually defined development status overwrites\n\n- support for extra docs from separate dir in a form of .ipynb .md .png\n\n- moving cli docs to new extra docs\n</code></pre>"},{"location":"release-notes/#0513","title":"0.5.13","text":"<pre><code>- initial support for streamlit app packaging\n\n- ability to package docs with referenced images from docs folder\n\n- minor fix for bug in run-api-routes that prevented usage of optional port flag\n\n- adding tests to packaging\n\n- adding drawio and unmerged .py files to tracking\n</code></pre>"},{"location":"release-notes/#0510","title":"0.5.10","text":"<pre><code>- initial cli method to extract requirements\n</code></pre>"},{"location":"release-notes/#059","title":"0.5.9","text":"<pre><code>- support for manual overwrite for dependencies extraction\n</code></pre>"},{"location":"release-notes/#058","title":"0.5.8","text":"<pre><code>- using module level metadata to pass links from which files are not downloaded during packaging\n\n- cli tools to show links and refresh artifacts from links\n\n- support for artifacts from links\n</code></pre>"},{"location":"release-notes/#057","title":"0.5.7","text":"<pre><code>- fixing a problem with missing package description from jupyter\n</code></pre>"},{"location":"release-notes/#056","title":"0.5.6","text":"<pre><code>- fixes to some problems caused by missing optional .paa.config parameters\n</code></pre>"},{"location":"release-notes/#055","title":"0.5.5","text":"<pre><code>- minor fixes to file imports from paa artifacts\n</code></pre>"},{"location":"release-notes/#054","title":"0.5.4","text":"<pre><code>- minor fix for packaging package without artifacts\n</code></pre>"},{"location":"release-notes/#053","title":"0.5.3","text":"<pre><code>- additional cli tools to show and extract packaged artifacts\n\n- additional cli tool to extract mkdocs site\n\n- adding .paa tracking files to each package\n\n- adding optional package artifacts from a select destination in packaging repo\n\n- removing pypi installation instruction if pypi version is not available\n\n- adding all md files that start with package name to mkdocs site\n</code></pre>"},{"location":"release-notes/#052","title":"0.5.2","text":"<pre><code>- integration of mkdocs into package building pipeline\n\n- packaging mkdocs static package and enabling displaying via run-module-routes functionality\n\n- initial ability to include docs for run-module-routes functionality\n\n- ability to package with artifacts\n</code></pre>"},{"location":"release-notes/#051","title":"0.5.1","text":"<pre><code>- minor fix for requirements extraction with extra_require labels\n\n- fixes for the problem when __package_metadata__ is empty and .ipynb is optional\n</code></pre>"},{"location":"release-notes/#050","title":"0.5.0","text":"<pre><code>- ability to add and run routes for fastapi applications\n\n- cli tools to run routes from multiple packages and filepaths\n\n- cli tool to extract routes from a package\n\n- cli and api support descriptions in docs\n\n- automatic extraction and processing of dependencies from api routes\n</code></pre>"},{"location":"release-notes/#045","title":"0.4.5","text":"<pre><code>- minor fixes to license check\n\n- extracting extra_require labels and filtering duplicates for requirements\n</code></pre>"},{"location":"release-notes/#044","title":"0.4.4","text":"<pre><code>- license checking integrated into packaging pipeline\n\n- additional cli tools to check dependencies tree and corresponding licenses\n\n- initial support for license labels analysis of package dependencies and their dependencies\n\n- initial DependenciesAnalyser for extracting info from dependencies\n\n- reading optional requirements from module and metadata\n\n- initial support for optional requirements in setup.py though extras_require\n</code></pre>"},{"location":"release-notes/#043","title":"0.4.3","text":"<pre><code>- tagging packages with additional metadata\n\n- cli method to show packages in local env built with paa\n\n- cli method to show extended package info for packages built with paa\n\n- cli method to show package requirements\n</code></pre>"},{"location":"release-notes/#042","title":"0.4.2","text":"<pre><code>- independent cli tool for updating release notes with automatic versioning\n\n- increasing default max search depth for commit history to 5\n</code></pre>"},{"location":"release-notes/#041","title":"0.4.1","text":"<pre><code>- additional descriptions for each component of the package\n\n- fix for potential missing lines problem with setup.py creation\n\n- --skip-dep-install flag for test-install to reuse installed dependencies\n</code></pre>"},{"location":"release-notes/#040","title":"0.4.0","text":"<pre><code>- getting latest version from pip and using local records as backup\n\n- minor fixes for version handling in release notes and empty merge history\n\n- support for components imports from bundles\n</code></pre>"},{"location":"release-notes/#031","title":"0.3.1","text":"<pre><code>- release notes integragration into version interation\n\n- optional labels to interate version from commit messages\n\n- fixes for initial release notes entry\n\n- check-vulnerabilities with cli\n</code></pre>"},{"location":"release-notes/#026","title":"0.2.6","text":"<pre><code>- fixes to requirements extraction from import .. as .. pattern\n</code></pre>"},{"location":"release-notes/#025","title":"0.2.5","text":"<pre><code>- minor fixes to local dependencies with cli\n</code></pre>"},{"location":"release-notes/#024","title":"0.2.4","text":"<pre><code>- cli handler depiction in flow diagram\n\n- cli name change to paa\n</code></pre>"},{"location":"release-notes/#023","title":"0.2.3","text":"<pre><code>- initial docs for cli intefrace\n\n- initial  metadata extraction from cli modules to change their cli usage names from default\n\n- splitting package into test-install and make-package\n\n- adding method to initialize config\n</code></pre>"},{"location":"release-notes/#022","title":"0.2.2","text":"<pre><code>- minor fixes for requirements extraction in preparations for cli packaging\n</code></pre>"},{"location":"release-notes/#021","title":"0.2.1","text":"<pre><code>- initial cli interface for packaging\n</code></pre>"},{"location":"release-notes/#017","title":"0.1.7","text":"<pre><code>- fix that skips cli packaging if cli file does not exist\n</code></pre>"},{"location":"release-notes/#016","title":"0.1.6","text":"<pre><code>- initial cli scripts support\n</code></pre>"},{"location":"release-notes/#015","title":"0.1.5","text":"<pre><code>- mkdocs handler to build package documentation\n</code></pre>"},{"location":"release-notes/#014","title":"0.1.4","text":"<pre><code>- test_install_package() method for local testing\n</code></pre>"},{"location":"release-notes/#013","title":"0.1.3","text":"<pre><code>- improved ReleaseNotesHandler with resistance to duplicate history\n</code></pre>"},{"location":"release-notes/#012","title":"0.1.2","text":"<pre><code>- integration of pip-audit to check vulnerabilities\n</code></pre>"},{"location":"release-notes/#011","title":"0.1.1","text":"<pre><code>- initial version with release notes handler\n</code></pre>"}]}